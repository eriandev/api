{"job_count":98,"total_pages":5,"jobs_per_page":20,"next":"https://eriandev.github.io/api/remotive/2","results":[{"id":1555089,"url":"https://remotive.com/remote-jobs/data/data-architect-1555089","title":"Data Architect","company_name":"Expression Networks","company_logo":"https://remotive.com/job/1555089/logo","category":"Data","tags":["big data","cloud","data science","education","elasticsearch","hadoop","java","javascript","machine learning","mongoDB","python","scrum","security","sql","growth","management","ai","design","programming","databases","agile","strategy","product strategy","research","Engineering","community","product","analytics","languages","knowledge","NoSQL","data","postgres","troubleshooting","Enterprise","spark","business","data engineering","culture","architect","release","database","development","engagement","writing","software engineering","learning","integrations","organization","networks","applications","computer science","data-driven","presentations","communication","Secret clearance","Fusion","architecture ","production","travel","insurance","software"],"job_type":"full_time","publication_date":"2023-01-14T05:39:27","candidate_required_location":"USA","salary":"","description":"<p>Expression Networks is looking to hire a Data Architect to add to the continued growth we are seeing with our Data Science division. This position will be responsible for designing and implementing enterprise-level data management frameworks and high-impact data architecture and engineering solutions to customers across multiple domains and use cases.<br></p>\n<p><strong>Location:</strong></p>\n<ul style=\"\"><li style=\"\">Remote with the ability to travel if needed</li></ul>\n<p><strong>Security Clearance:</strong></p>\n<ul style=\"\"><li style=\"\">US Citizenship required</li><li style=\"\">Ability to obtain Secret Clearance or higher</li></ul>\n<p><strong>Primary Responsibilities:</strong></p>\n<ul style=\"\"><li style=\"\">Translate business requirements into data and system requirements and specifications, including databases, data warehouses, transformations, integrations, and analytics</li><li style=\"\">Create database solutions, evaluate requirements, and prepare design reports and diagrams</li><li style=\"\">Define data standards, principles, and policies</li><li style=\"\">Detect and analyze patterns in data usage and growth to improve performance and ensure future scalability </li><li style=\"\">Meet rigorous security and information assurance requirements for data collection, storage, and management</li><li style=\"\">Oversee the migration of data from legacy systems to new solutions</li><li style=\"\">Lead end-to-end architectural design and development lifecycle for new data services/products, and make them operate at scale</li><li style=\"\">Partner with Program Managers, Subject Matter Experts, Engineers, and Data Scientists across the organization where appropriate to understand customer requirements, design prototypes, and optimize existing data services/products</li><li style=\"\">Set the standard for Data Science excellence in the teams you work with across the organization, and mentor junior members in the Data Science division</li></ul>\n<p><strong>Additional Responsibilities:</strong></p>\n<ul style=\"\"><li style=\"\">Participate in technical development of white papers and proposals to win new business opportunities</li><li style=\"\">Analyze and provide feedback on product strategy</li><li style=\"\">Participate in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged</li><li style=\"\">Monitor system performance by performing regular tests, troubleshooting, and integrating new features</li><li style=\"\">Work in a consultative fashion to improve communication, collaboration, and alignment amongst teams inside the Data Science division and across the organization</li><li style=\"\">Help recruit, nurture, and retain top data engineering talent</li></ul>\n<p><strong>Required Experience:</strong></p>\n<ul style=\"\"><li style=\"\">Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant data-driven discipline</li><li style=\"\">4+ years of experience designing data architectures for enterprise-level applications</li><li style=\"\">6+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree (or 4+ years of experience with a Ph.D./MS degree)</li><li style=\"\">Proficiency in developing software code in one or more programming languages (Python, JavaScript, Java, etc.)</li><li style=\"\">Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)</li><li style=\"\">Experience with cloud computing technologies and platforms</li><li style=\"\">Knowledgeable in machine learning/AI methodologies</li><li style=\"\">Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences</li></ul>\n<p><strong>Preferred Experience:</strong></p>\n<ul style=\"\"><li style=\"\">MS degree in Computer Science/Data Science/Data Engineering or relevant data-driven discipline</li><li style=\"\">Experience using Databricks, ElasticSearch, MongoDB, Postgres, and Neo4j</li><li style=\"\">Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)</li><li style=\"\">Experience in short-release cycles and the full software lifecycle</li><li style=\"\">Experience with Agile development methodology (e.g., Scrum)</li></ul>\n<p><strong>Benefits:</strong></p>\n<p>Expression Networks offers competitive salaries and benefits, such as:</p>\n<ul style=\"\"><li style=\"\">401k matching</li><li style=\"\">PPO and HDHP medical/dental/vision insurance</li><li style=\"\">Education reimbursement</li><li style=\"\">Complimentary life insurance</li><li style=\"\">Generous PTO and holiday leave</li><li style=\"\">Onsite office gym access</li><li style=\"\">Commuter Benefits Plan</li></ul>\n<p><strong>About Expression Networks </strong></p><p>Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via Agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.</p>\n<p>Equal Opportunity Employer/Veterans/Disabled</p>\n<p></p>\n<img src=\"https://remotive.com/job/track/1555089/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1549505,"url":"https://remotive.com/remote-jobs/data/senior-data-analytics-consultant-1549505","title":"Senior Data & Analytics Consultant","company_name":"Cocomore AG","company_logo":"https://remotive.com/job/1549505/logo","category":"Data","tags":["business intelligence","data science","finance","html","javascript","magento","marketing","mobile","php","python","sales","sql","growth","management","design","email","programming","project management","Engineering","CRM","analytics","languages","data analysis","digital marketing","knowledge","google analytics","business development","data","JS","creative","web","German","English","tableau","business","ETL","websites","data engineering","recruitment","onboarding","development","startup","IT","R","digital analytics","applications","customer-focused","computer science","communication","agency","architecture ","training"],"job_type":"full_time","publication_date":"2023-01-14T01:40:04","candidate_required_location":"Germany","salary":"","description":"<p>Cocomore is not only a digital agency providing products and communication services for international clients like Nestlé, Procter &amp; Gamble, Rabobank, Samsung or Sanofi. Cocomore is also an incubator for digital start-ups, so far sold to Deutsche Telekom, Axel Springer and Pro7Sat1.</p>\n<p>We are 200 professionals from all over Europe, mostly located in and around Berlin, Cologne, Frankfurt, Hamburg, Seville, Poznan and Warsaw. And while we all have different skills and talents, we share a common spirit: we are human, entrepreneurial and creative. This is our way of working together with colleagues, partners and clients.</p>\n<p>Currently, we are looking for you as<strong> Senior Data &amp; Analytics Consultant</strong> - whether in one of our offices or remotely.</p>\n<p>Our dynamic Data &amp; Analytics team, consisting of specialists and generalists, advises clients from a wide range of sectors with diverse requirements and wishes. This gives you the opportunity for personal development based on your individual preferences. </p>\n<p>As a team, we develop strategies, concepts, services and campaigns for our global clients and lead them to success in digital marketing. We always base our recommendations on data insights, especially customer insights, and constantly measure and optimise our activities. To do this, we use digital dashboards and state-of-the-art tools. </p>\n<p><strong><u>Your skills:</u></strong></p>\n<ul style=\"\">\n<li style=\"\">A suitable university degree with a mathematical, statistical and/or analytical focus. Degrees in economics, finance, computer science, mathematics, logistics are preferred</li>\n<li style=\"\">High data literacy</li>\n<li style=\"\">Conceptual and practical experience with data analysis, data engineering &amp; business intelligence</li>\n<li style=\"\">Project management experience in working with internal and external stakeholders</li>\n<li style=\"\">Experience working with data architecture, data modeling, project planning and effort estimation</li>\n<li style=\"\">Business Development abilities in the areas of added-value recognition, service offering preparation, sales, and client management</li>\n<li style=\"\">Confident and strong communication skills, also in dealing with customers</li>\n<li style=\"\">You have very strong analytical skills and a customer-focused mindset</li>\n<li style=\"\">Experience in analyzing and interpreting digital analytics, E-commerce, and CRM data, ideally experience with Magento.</li>\n<li style=\"\">Experience with statistical, programming, querying languages as well as BI, ETL and development tools and frameworks. Examples:\n<ul style=\"\">\n<li style=\"\">SQL, different versions.</li>\n<li style=\"\">Dashboard solutions such as Klipfolio, Tableau, PowerBi, Qlik.</li>\n<li style=\"\">Knowledge of Google Analytics, Google Tag Manager and/or Google Optimize is also desirable.</li>\n<li style=\"\">Knowledge of Javascript, HTML, PHP, R and/or Python is also an advantage</li>\n</ul>\n</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">You are fluent in English and German</li>\n</ul>\n<p><strong><u>Your job:</u></strong></p>\n<ul style=\"\">\n<li style=\"\">You are a key member of our Data &amp; Analytics team</li>\n<li style=\"\">With your expertise, you will implement exciting analytics and tracking projects together with our external and international customers from a wide range of industries</li>\n<li style=\"\">You perform onsite analysis of websites and optimize the online customer journey of our customers</li>\n<li style=\"\">You analyze the user/purchasing behavior of the users on the websites and derive recommendations for action from it</li>\n<li style=\"\">You are responsible for the conception and creation of performance-oriented key figure analyses of the websites, online channels as well as online and newsletter campaigns of our customers</li>\n<li style=\"\">Actively participate in Team Development – opportunity generation, team efficiency improvement, sustainable business growth</li>\n<li style=\"\">Client &amp; Project Management – work on pitching, estimating, requirements gathering, feasibility assessment, project plan formulation</li>\n<li style=\"\">You create analytics/tracking concepts for web and mobile applications as well as for multichannel campaigns</li>\n<li style=\"\">Solution design – using client's existing systems or suggesting new ones and proposal how they would work.</li>\n<li style=\"\">Work with programming &amp; query languages (Python, JS, PHP, SQL, HTML)</li>\n<li style=\"\">Work with ETL tools</li>\n<li style=\"\">Work with BI Tools (Tableau,  PowerBI &amp; DataStudio)</li>\n</ul>\n<p><strong><u>What you can expect from Cocomore:</u></strong></p>\n<ul style=\"\">\n<li style=\"\">Exciting and varied projects with large, international customers</li>\n<li style=\"\">Opportunities for further training in the direction of Data Science</li>\n<li style=\"\">Your work-life balance is important to us, so we offer you flexible working hours and home office options</li>\n<li style=\"\">You benefit from employee discounts and other benefits at partner companies</li>\n<li style=\"\">Team spirit in a startup atmosphere and working at eye level in an experienced and interdisciplinary team</li>\n<li style=\"\">You have the opportunity to help shape and drive forward cross-departmental topics</li>\n<li style=\"\">Our onboarding program will help you get your bearings in the first few days, and you will also have a personal buddy at your side</li>\n<li style=\"\">Formal training measures are available</li>\n</ul>\n<p><strong><u>What will happen next?</u></strong></p>\n<ul style=\"\">\n<li style=\"\">You will receive the email confirming that we received your documents.</li>\n<li style=\"\">Afterwards our recruitment team will inform you if your experience matches our requirements.</li>\n<li style=\"\">If yes, you will be invited to the online interviews.</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1549505/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1550614,"url":"https://remotive.com/remote-jobs/data/senior-data-researcher-1550614","title":"Senior Data Researcher","company_name":"Opencorporates","company_logo":"https://remotive.com/job/1550614/logo","category":"Data","tags":["AWS","cloud","legal","mySQL","strategy","research","documentation","product","knowledge","compliance","data","business","infrastructure","culture","events","database","APIs","reporting","IT","Postman","learning","SQLite","communication","diversity","risk"],"job_type":"full_time","publication_date":"2023-01-13T11:39:51","candidate_required_location":"UK","salary":"","description":"<p dir=\"ltr\"><strong>Senior Data Researcher</strong></p>\n<p dir=\"ltr\"><em>We’re building a more open society. Want to help?</em></p>\n<p dir=\"ltr\"><a href=\"https://opencorporates.com/\" rel=\"nofollow\">OpenCorporates</a> is the largest source of open company data in the world with over 200 million companies in our database. We firmly believe delivering genuine corporate transparency benefits both business and society. Our vision to become the world’s foundational and definitive source of company data.</p>\n<p dir=\"ltr\">Corporate transparency enables citizens, companies and governments to make clearer choices about who they do business with. It throttles crime, helps protect workers and our environment. It oils the wheels of prosperity, fairness and sustainability.</p>\n<p dir=\"ltr\">OpenCorporates was conceived to drive that change. We’ve worked with bodies like <a href=\"https://www.worldbank.org/en/home\" rel=\"nofollow\">the World Bank</a> and <a href=\"https://www.g20.org/\" rel=\"nofollow\">the G20</a> to spearhead initiatives such as the <a href=\"http://registries.opencorporates.com/\" rel=\"nofollow\">Open Company Data Index</a> and the creation of the <a href=\"https://www.gleif.org/en\" rel=\"nofollow\">Global Legal Entity Identifier Foundation</a>. Our expertise has shaped how the US Federal Government procures services; we have advised the European Commission on <a href=\"https://digital-strategy.ec.europa.eu/en/policies/legislation-open-data\" rel=\"nofollow\">the EU Open Data Directive</a>; and we were instrumental in the UK Companies House opening access to their company data.</p>\n<p dir=\"ltr\">Our platform dynamically captures and curates the records of over 200 million companies from 140 jurisdictions around the world — openly available information that is the foundation to sourcing, risk, compliance, and investigations processes for organisations around the world — large and small, public and private.<br><br>To help our rapidly growing user base derive greater insights from our data, we’re solving hard-core ‘big-data’ challenges: modelling, linking, profiling, cleaning and presenting actionable results from billions of data entities. We’re also establishing a globally scalable cloud infrastructure that can run these processes efficiently and reliably at scale; and serve our global audience via an ecosystem to rival AWS for ease of use and integration.</p>\n<p dir=\"ltr\"> </p>\n<p dir=\"ltr\">Our four company <a href=\"https://opencorporates.com/info/careers/\" rel=\"nofollow\">values</a> outline the shared principles that define our culture and drive our success: we are <strong>bold</strong>, we are <strong>one team</strong>, we <strong>learn &amp; adapt</strong> and we put our <strong>users first</strong>. Whether through day-to-day decision making, teamwork, supporting our clients or evaluating performance, the values are the lens we look through to help us achieve great things.</p>\n<p dir=\"ltr\">OpenCorporates operates an informal hybrid model around our London workspace. Working from home is the norm and in-person touchpoints are expected to become more frequent.</p>\n<p dir=\"ltr\"> </p>\n<p dir=\"ltr\"> </p>\n<p><strong>The Role</strong></p>\n<p dir=\"ltr\">Reporting to the Head of Product &amp; Data, you will be responsible for researching publicly available data sources for company entity data. You’ll build relationships with official public company registries globally and help develop our data sourcing strategy. <strong><br></strong><strong><br></strong></p>\n<p dir=\"ltr\"><strong>Responsibilities</strong></p>\n<ul style=\"\">\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Develop and maintain detailed knowledge of how publicly available company data is collected from various jurisdictions</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Understanding of how to research data sources for publicly available company data</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Build relationships with official public registries for company information all over the world</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Ensure that any relevant fees for data collection are paid on time</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Lead data investigations for internal stakeholders, customers and prospects</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Create external facing documentation collateral so that internal stakeholders and clients can help themselves and understand our data</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Understand the real world context of OpenCorporates’ data e.g. how it behaves in the real world and bring clarity to the complex use cases that our clients have</p>\n</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Experience with APIs and MySQL/SQLite - using tools like Postman to work on APIs</li>\n<li dir=\"ltr\" style=\"\">\n<p>Data research experience involving large datasets (Company registry data is a bonus)</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p>Excellent communication skills, able to explain and simplify complex research and solutions</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p>Accuracy and attention to detail</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p>Research experience in one of the following industries is ideal - KYC, AML, professional services consultancy, compliance information user, data</p>\n</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul style=\"\">\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Competitive salary</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Share options scheme for all new joiners</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Remote-first within the UK</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">£1000 learning and wellness allowance, plus quarterly learning days</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">28 days holiday plus bank hols</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">1 additional days’ holiday each year</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Time off for life events</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">£500 home office budget</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Cycle to work scheme</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Quarterly socials</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Wellbeing Pledge</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Life assurance</p>\n</li>\n<li dir=\"ltr\" style=\"\">\n<p dir=\"ltr\">Flexible, autonomous working</p>\n</li>\n</ul>\n<p><strong>Diversity Matters</strong></p>\n<p dir=\"ltr\">Don’t meet every single requirement? At OpenCorporates we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply regardless. You may be just the right candidate for this or other roles.</p>\n<img src=\"https://remotive.com/job/track/1550614/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1551990,"url":"https://remotive.com/remote-jobs/data/senior-data-engineer-m-f-x-1551990","title":"(Senior) Data Engineer (m/f/x)","company_name":"Scalable","company_logo":"https://remotive.com/job/1551990/logo","category":"Data","tags":["AWS","backend","cloud","crypto","education","finance","java","machine learning","marketing","python","sales","scrum","sql","kotlin","management","ai","programming","agile","B2B","research","product","analytics","knowledge","data","hardware","German","English","infrastructure","terraform","warehouse","people","culture","data pipelines","release","development","reporting","streaming","investment","learning","fintech","financial services","computer science","backbone","data-driven","communication","support"],"job_type":"full_time","publication_date":"2023-01-13T03:39:55","candidate_required_location":"Germany","salary":"","description":"<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>Scalable Capital is a leading digital investment platform in Europe.<br>Since our foundation in 2014, we pursue the mission to empower everyone to become an investor. With the Scalable Broker, Scalable Wealth, Scalable Crypto and our solutions for B2B partners we offer easy and cost efficient investing for everyone.<br>Today, Scalable Capital is a FinTech unicorn - we have more than 600,000 customers and more than 10 billion Euros on our platform.<br><br>Visit our <a href=\"https://de.scalable.capital/blog\" rel=\"nofollow\">finance blog</a> or tune in to our <a href=\"https://de.scalable.capital/money-market-and-machines?utm_medium=email&amp;utm_source=personalmail&amp;utm_campaign=email&amp;utm_content=max_ooo\" rel=\"nofollow\">podcast</a> (both in German) to find out what our Expert Teams have to say.<br><br>Our Company Values guide us every day in how we work and collaborate. To learn more about them, you can find our values <a href=\"https://de.scalable.capital/values-principles\" rel=\"nofollow\">here</a> (English).</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<ul style=\"\">\n<li style=\"\">Develop our scalable cloud-based data backbone which drives our data-driven company using the most up-to-date technologies in the data space</li>\n<li style=\"\">Shape an AWS based streaming and batch data processing solution, ingesting data from 3rd party as well as our internal backend services</li>\n<li style=\"\">Create a financial data warehouse combining latest technologies with features required by regulatory requirements</li>\n<li style=\"\">Prepare and clean structured and unstructured data and develop high-quality data models for advanced analytics, machine learning and AI use cases</li>\n<li style=\"\">Work with highly ambitious and skilled people in our growing data department</li>\n<li style=\"\">Work closely together with our data scientists, product &amp; development colleagues to release smart features for our product</li>\n<li style=\"\">Build interactive dashboards and reporting solutions to support stakeholders, such as management, marketing, sales and quantitative research</li>\n<li style=\"\">Share your expert knowledge about data best practices within the company</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<ul style=\"\">\n<li style=\"\">Excellent University degree in computer science, mathematics, natural sciences, or similar field and relevant working experience</li>\n<li style=\"\">Experience designing and operating data pipelines in AWS</li>\n<li style=\"\">Excellent SQL Skills, including advanced concepts such as window functions, experience with dbt is a plus</li>\n<li style=\"\">Very good programming skills in Python, including frameworks like PySpark</li>\n<li style=\"\">Knowledge of Java and Kotlin is a plus</li>\n<li style=\"\">Experience with AWS Services like S3, Athena, Redshift and Glue</li>\n<li style=\"\">Experience using infrastructure-as-code tools such as terraform</li>\n<li style=\"\">A passion for everything-as-code and code that is well architected, testable and documented</li>\n<li style=\"\">Data-driven and good with numbers whilst being able to explain complex concepts in simple terms</li>\n<li style=\"\">Experience using agile frameworks like Scrum</li>\n<li style=\"\">Interest in financial services and markets</li>\n<li style=\"\">Fluent English communication and presentation skills</li>\n</ul>\n<p> </p>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<ul style=\"\">\n<li style=\"\">Be part of one of the fastest-growing and most visible Fintech startups in Europe, creating innovative services that have a substantial impact on the lives of our customers</li>\n<li style=\"\">Work with an international, diverse, inclusive, and ever-growing team that loves creating the best products for our clients</li>\n<li style=\"\">Enjoy an office in a great location in the middle of Munich or Prenzlauer Berg, one of the hippest neighbourhoods of Berlin or choose to work remotely within Germany (if eligible for the job)</li>\n<li style=\"\">Be productive with the latest hardware and tools</li>\n<li style=\"\">Learn and grow by joining our in-house knowledge sharing sessions and spending your individual Education Budget </li>\n<li style=\"\">Learn and experience German culture first hand by joining our free German language classes</li>\n<li style=\"\">(International) relocation support</li>\n<li style=\"\">Enjoy your free time with 30 paid vacation days and take the opportunity to work from abroad</li>\n<li style=\"\">Benefit from an attractive compensation package and from the company pension scheme</li>\n<li style=\"\">Say goodbye to order commissions and say hello to your complimentary subscription of Scalable Capital's PRIME Broker</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1551990/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1552215,"url":"https://remotive.com/remote-jobs/data/data-engineer-1552215","title":"Data Engineer","company_name":"MURAL","company_logo":"https://remotive.com/job/1552215/logo","category":"Data","tags":["data science","education","golang","microsoft","postgresql","python","scala","sql","design","programming","databases","agile","Engineering","product","analytics","knowledge","NoSQL","rest","data","troubleshooting","creative","web","English","software development","business","ETL","warehousing","people","data engineering","culture","engineering manager","gitlab","data warehousing","development","APIs","IT","writing","learning","testing","REST APIs","computer science","data-driven","support","architecture ","relational databases","insurance","software"],"job_type":"full_time","publication_date":"2023-01-12T21:39:35","candidate_required_location":"LATAM","salary":"","description":"<div class='\"content-intro\"'>\n<div class=\"h2\"><img alt='\"\"' height='\"120\"' src=\"%22https:/i.imgur.com/CoZ3lG4.png%22\" width='\"700\"'></div>\n<div class=\"h2\"><img alt='\"\"' src=\"%22https:/lh3.googleusercontent.com/HriprGR3FAioZViOVXRWhGDePcYStKXAHAMjHGGeZaLY-ba0goQJtmdx_q46vFVur0mPxXGofGZ939o2P6S25Jrloe-ZlIQi--gttlEl%22\"><strong>Mural’s mission is to inspire teams to connect and innovate, while bringing purpose and intention to the craft of collaboration</strong>.</div>\n<p>Mural created the Collaborative Intelligence System™ to power cultures of effective collaboration where everyone is connected, contributing, and empowered to deliver business-driving outcomes.</p>\n<p>Founded in 2011, Mural is a leading innovator in visual collaboration for hybrid, remote, and distributed teams. We believe in what we build, and our team of more than 700 “MURistas” around the world collaborate in the Mural® app. Our values guide our intentionally inclusive product and culture, which includes collaboration design education and a flexible monthly stipend for learning, wellness, and coworking.<br><br>Mural has raised $200M to date and is growing rapidly to fulfill our mission. The company is trusted by 95% of the Fortune 100, including innovative teams at IBM, Intuit, GitLab, Microsoft, and Atlassian.</p>\n</div>\n<div class=\"h4\"><strong>YOUR MISSION</strong></div>\n<p>As a Data Engineer, you will grow our business by applying your knowledge of data architectures, APIs, and the delivery and transformation of data in a reliable way and help us expand globally. </p>\n<p>You’re responsible for building and maintaining the data pipeline architecture of Mural, creating internal data tools, as well as writing APIs and tools to help other teams work with data. You will collaborate closely with Product, Analytics and Data Science teams to help them achieve their goals. You will report directly to the Data Engineering Manager.</p>\n<p>In this role, you will:</p>\n<ul style=\"\">\n<li style=\"\">Help build the platform, tools and APIs vital to enable other teams to work with data.</li>\n<li style=\"\">Improve the existing data platform and propose solutions.</li>\n<li style=\"\">Work closely with Product teams to help them explore the feasibility of experimental data-driven features, helping them narrow down preliminary or unclear requirements, and building the tools and APIs vital to support those features. A strong analytical attitude is a must.</li>\n<li style=\"\">Efficiently handle vast amounts of data from multiple sources and destinations, including relational and NoSQL databases as well as external systems, both in batch processing and real-time delivery.</li>\n<li style=\"\">Follow modern development standards and methodologies such as code reviews, unit testing, continuous integration, and agile methodology</li>\n<li style=\"\">Work as part of a team. We value teammates who share their knowledge and like collaborating with others.</li>\n<li style=\"\">Show initiative, completing your tasks and providing timely status updates to both the rest of your team and all of the customers, collaborators and partners.</li>\n<li style=\"\">Take full ownership of the solutions you build. This means analyzing requirements, building, tracking and monitoring them, and troubleshooting them if problems arise.</li>\n</ul>\n<div class=\"h4\"><strong>YOUR PROFILE</strong></div>\n<p>The top candidate will have the following skills: </p>\n<ul style=\"\">\n<li style=\"\">2+ years of relevant experience in software development</li>\n<li style=\"\">A Bachelor’s degree in Computer Science or related field</li>\n<li style=\"\">Strong Python skills in a professional working environment</li>\n<li style=\"\">Familiar with Golang or Scala as a secondary programming language</li>\n<li style=\"\">Code an application from scratch following standard methodologies such as writing clean code with unit tests, and using continuous integration</li>\n<li style=\"\">Experience in designing and developing web services and REST APIs</li>\n<li style=\"\">Sophisticated knowledge of relational databases such as PostgreSQL, and ability to write non-trivial SQL</li>\n<li style=\"\">Experience processing Real Time Data</li>\n<li style=\"\">Proven experience in data modeling, ETL/ELT development, and data warehousing</li>\n</ul>\n<p>Please submit your resume in English. #LI-Remote #LI-ABW1</p>\n<div class='\"content-conclusion\"'>\n<div class=\"h3\">WHAT WE OFFER</div>\n<p>In addition to being part of our quest to help people empower their imagination, we offer:</p>\n<ul class='\"p-rich_text_list' style=\"\">\n<li style=\"\">Competitive salary</li>\n<li style=\"\">401K (US only)</li>\n<li style=\"\">Company equity</li>\n<li style=\"\">Health insurance</li>\n<li style=\"\">Fertility benefits</li>\n<li style=\"\">Muralvida stipend (for fitness, wellness, learning and coworking)</li>\n<li style=\"\">Fully remote team</li>\n<li style=\"\">Parental leave</li>\n<li style=\"\">End of year closure</li>\n<li style=\"\">Design thinking trainings</li>\n<li style=\"\">Mural free forever plan</li>\n</ul>\n<div class=\"h3\">OUR VALUES</div>\n<p>We bring people to our team that care about our mission to inspire and connect creative people globally, and who feel aligned with our values:</p>\n<ul style=\"\">\n<li style=\"\">Make others successful</li>\n<li style=\"\">Adapt to thrive</li>\n<li style=\"\">Play to wow</li>\n<li style=\"\">Think global</li>\n<li style=\"\">Experiment like an owner</li>\n</ul>\n<div class=\"h3\">Practicing equality through imagination work.</div>\n<p>Mural is committed to creating diverse and inclusive workspaces where people can make a positive impact on the world and share their vision of how they achieve it. We are dedicated to working alongside multiple communities to help build this dream and bring it to life. </p>\n<p>We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.</p>\n</div>\n<img src=\"https://remotive.com/job/track/1552215/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1552199,"url":"https://remotive.com/remote-jobs/data/data-engineer-ii-infrastructure-1552199","title":"Data Engineer II-Infrastructure","company_name":"Slickdeals","company_logo":"https://remotive.com/job/1552199/logo","category":"Data","tags":["apache","AWS","azure","big data","cloud","developer","education","hadoop","java","kafka","looker","python","sql","design","databases","jira","Engineering","documentation","analytics","data","troubleshooting","spark","web","tableau","business","infrastructure","warehouse","Snowflake","jenkins","metrics","data pipelines","development","reporting","startup","learning","media","organization","applications","problem-solving","computer science","detail-oriented","communication","statistics","support","architecture ","production","insurance","performance optimization"],"job_type":"full_time","publication_date":"2023-01-12T09:39:46","candidate_required_location":"USA","salary":"","description":"<div class='\"c-message_kit__blocks'>\n<div class='\"c-message__message_blocks'>\n<div class='\"p-block_kit_renderer\"'>\n<div class='\"p-block_kit_renderer__block_wrapper'>\n<div class='\"p-rich_text_block\"'>\n<div class='\"p-rich_text_section\"'>\n<p><strong>THE PURPOSE</strong><strong>:</strong></p>\n<p>The Data Engineer works within the Data Solutions organization on critical reporting, visualization, and analysis initiatives. Reporting spans from custom ad-hoc requests to scheduled jobs to supporting our growing data warehouse, and building our future cloud analytics platform. The developer must be able to communicate to business users the exact scope of metrics as well as the confidence and quality of the data in reports.</p>\n<p><strong>THE ROLE</strong><strong>:</strong></p>\n<ul style=\"\">\n<li style=\"\">Work directly with the business users to understand the reporting needs and lead business users to practical solutions</li>\n<li style=\"\">Help translate business requirements into specification documents to track and perform analysis of new and existing site features</li>\n<li style=\"\">Understand the necessity of data quality and requirement for confidence of accuracy of any reports</li>\n<li style=\"\">Develop/monitor/maintain new reports, dashboards, visualizations, procedures, data structures and databases</li>\n<li style=\"\">Design data pipelines and maintain data pipelines in cloud or on-premise environments</li>\n<li style=\"\">Design data schema, perform data transformations, enrichments, and manipulations with efficiency and reusability in mind</li>\n<li style=\"\">Planning, conducting and directing the analysis of complex business problems and projects</li>\n</ul>\n<p><strong>THE CANDIDATE</strong><strong>:</strong>· </p>\n<ul style=\"\">\n<li style=\"\">Understand data structures and algorithms. Understanding of basic statistics (confidence intervals, statistical significance, etc)</li>\n<li style=\"\">Experience in working with large size data sets (Billions of rows/Petabytes of data)</li>\n<li style=\"\">Experience in working with various data sources (ODBC, flat files, etc)</li>\n<li style=\"\">Experience working with and designing complex data schemas</li>\n<li style=\"\">Strong skills in SQL</li>\n<li style=\"\">Development experience in Java and/or Python</li>\n<li style=\"\">Experience with SQL query performance optimization</li>\n<li style=\"\">Strong skills Experience with Apache Big Data Frameworks (Hadoop/EMR/Databricks, Spark, Hive)</li>\n<li style=\"\">Strong experience with Spark performance optimization and troubleshooting</li>\n<li style=\"\">Experience with Kafka and event driven architectures</li>\n<li style=\"\">Familiarity with workflow scheduling/orchestration tools (Airflow, Jenkins)</li>\n<li style=\"\">Experience with AWS</li>\n<li style=\"\">Experience with Tableau, Looker, Power BI and or other Self Service Analytical tools.</li>\n<li style=\"\">Experience with OLAP Cubing technologies like SSAS or AtScale</li>\n<li style=\"\">Implemented Redshift, Snowflake, Azure Data Warehouse, ADLS, S3, Kafka, Presto, EMR, Databricks, or Data Lake Architecture in one or more public clouds in a Production Large Scale environment.</li>\n</ul>\n<p><strong>TO BE SUCCESSFUL YOU WILL BE:</strong></p>\n<ul style=\"\">\n<li style=\"\">Highly motivated with a great attitude and desire to dive into raw data to understand trends in behavior to find insights</li>\n<li style=\"\">Curious and passionate about data and data insights that relate to our business needs.</li>\n<li style=\"\">Excellent at multitasking who can execute multiple requests and reports under tight timelines</li>\n<li style=\"\">Inquisitive, self-starter, able to work autonomously</li>\n<li style=\"\">Able to work in a fast-paced dynamic startup like environment</li>\n<li style=\"\">Detail-oriented tactician who strives for perfection</li>\n<li style=\"\">Strong verbal and written communication (and listening) skills</li>\n<li style=\"\">Excellent reading comprehension and attention to detail.</li>\n<li style=\"\">Strong problem-solving skills</li>\n<li style=\"\">Strong documentation skills as you code (Jira, Confluence)d</li>\n</ul>\n<p><strong>As a Data Engineer, your day-to-day tasks will include</strong><strong>:</strong></p>\n<ul style=\"\">\n<li style=\"\">Helping us leverage large-scale data stores and data infrastructure by building out data pipelines, streams, and utilities in Spark and other technologies for feedback to our business systems, partners, or users</li>\n<li style=\"\">Developing robust, low latency and fault tolerant pipelines to support business critical systems</li>\n<li style=\"\">Aggregating key metrics for business partners to inform key decisions</li>\n<li style=\"\">Working with cloud technologies to build and deploy your applications</li>\n</ul>\n<p><strong>Environment</strong></p>\n<p>Can work effectively on a small and nimble team, no trouble context-switching</p>\n<p><strong>Education</strong></p>\n<p>B.S./M.S. in Computer Science or Computer Engineering or 3+ years of equivalent experience</p>\n</div>\n<div class='\"p-rich_text_section\"'><strong>LOCATION</strong><strong>: </strong>Las Vegas, Los Angeles, Flex/Hybrid, or Fully Remote</div>\n<div class='\"p-rich_text_section\"'>\n<p><em>Remote work is available in: Alabama, Arizona, California, Connecticut, Florida, Hawaii, Illinois, Iowa, Kentucky, Louisiana, Maryland, Massachusetts, Michigan, Minnesota, North Carolina, New Jersey, Nevada, Ohio, Oregon, Pennsylvania, Rhode Island, South Carolina,Tennessee, Texas, or Utah.</em></p>\n</div>\n<div class='\"p-rich_text_section\"'><strong>Slickdeals Compensation, Benefits, Perks</strong><strong>:</strong></div>\n<ul class='\"p-rich_text_list' style=\"\">\n<li style=\"\">Competitive salary based on your experience</li>\n<li style=\"\">Equity, become a Slickdeals stakeholder</li>\n<li style=\"\">Platinum level medical benefits</li>\n<li style=\"\">Dental, Vision, &amp; Life Insurance</li>\n<li style=\"\">401K matching above the industry standard</li>\n<li style=\"\">10 vacation days, 10 paid holidays, &amp; 48 hours of sick leave</li>\n<li style=\"\">Professional Development Reimbursement Program, and LinkedIn Learning Membership</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><strong><u>Work Authorization<br><br></u></strong>Candidates must be eligible to work in the United States.<br><br>Slickdeals is an Equal Opportunity Employer; employment is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender (including pregnancy, childbirth, or related medical conditions), national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other protected status. Slickdeals will consider qualified applicants with criminal histories consistent with the \"Ban the Box\" legislation. We may access publicly available information as part of your application.</p>\n<p>Slickdeals participates in E-Verify. For more information, please refer to <a href=\"%22https:/e-verify.uscis.gov/web/media/resourcesContents/E-Verify_Participation_Poster_ES.pdf%22\" rel=\"nofollow\" target='\"_blank\"'>E-Verify Participation</a> and <a href=\"%22https:/www.e-verify.gov/sites/default/files/everify/posters/IER_RightToWorkPoster Eng_Es.pdf%22\" rel=\"nofollow\" target='\"_blank\"'>Right to Work</a>.</p>\n<p><strong><em>Slickdeals does not accept unsolicited resumes from agencies and is not responsible for related fees.</em></strong></p>\n<img src=\"https://remotive.com/job/track/1552199/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1553362,"url":"https://remotive.com/remote-jobs/data/data-visualization-consultant-1553362","title":"Data Visualization Consultant","company_name":"Prominence Advisors","company_logo":"https://remotive.com/job/1553362/logo","category":"Data","tags":["C","C#","consulting","python","sql","teaching","ui","design","strategy","research","documentation","product","analytics","languages","healthcare","communications","knowledge","data","troubleshooting","coaching","creative","tableau","business","data visualization","hiring","partnerships","culture","development","IT","implementation","learning","law","coding","applications","communication","QlikSense","support","insurance","training"],"job_type":"full_time","publication_date":"2023-01-12T01:40:00","candidate_required_location":"USA","salary":"","description":"<p>Prominence is looking for the best data visualization specialists in healthcare to join our Analytics team.  </p><p><br></p><div class=\"h3\">Who We Are</div><p>Prominence is a healthcare technology strategy and implementation firm, focused on helping the nation’s leading healthcare organizations to do more with their data. Founded by former Epic managers, we understand the technology landscape in healthcare and provide IT staffing, advisory services, and analytics solutions to create robust data ecosystems that support clinical workflows, automate operational processes, and expedite research. Whether it’s guiding a technology implementation, establishing governance principles, or developing leading edge analytics, we help our customers make sense out of the mountain of data at their fingertips in order to deliver higher quality care at a lower cost.</p><p>Ranked as a best place to work over 27 times (and counting!), Prominence’s culture provides consultants with a supportive environment that allows you to innovate and grow your career in healthcare IT. Additional information is available <a class=\"external\" href=\"https://prominenceadvisors.com/careers/\" rel=\"nofollow\" target=\"_blank\">on our website</a>.</p><div class=\"h3\"><br></div><div class=\"h3\">Your Role</div><p>Our consultants guide our customers through complex technology requirements to summit the challenge at hand. You will need to be able to create order out of chaos, and compile ambiguous information into tactical action plans. </p><p>Our ideal team members are humble, smart, and driven to ensure our customer’s success. This includes a passion to deliver high-quality results, while teaching our counterparts how to fish and grow the skills needed to support and expand upon the deliverables of our projects. </p><p>If this sounds like you, and you meet the requirements below, we encourage you to apply. If you know of someone else how would be a great fit, let us know.</p><p><strong>Requirements</strong></p><div class=\"h3\"></div><p>As a user interface designer you will design and develop analytics applications in one of our BI platforms, creating informative visualizations designed to solve unique customer problems. Ideal candidates will have a creative and analytic mindset and a demonstrated desire and ability to tackle new and unfamiliar challenges.</p><p>This position is a full-time, salaried position with benefits. There is no relocation required. Candidates are required to have a suitable home office to operate from.</p><p><br></p><div class=\"h3\">Key Responsibilities</div><p>A visualization specialist’s primary responsibility includes designing and developing analytics applications in our BI platforms, including Tableau, QlikSense, Qlik View, and PowerBI. Expectations include:</p><ul style=\"\"> <li style=\"\">Working closely with our healthcare customers to understand visualization requirements and provide best practice recommendations</li> <li style=\"\">Interpreting dashboard requirements and goals and translating into charts and dashboards that tell a cohesive story and solve complex problems</li> <li style=\"\">Designing and producing mockups for new dashboards to gather early feedback from end users</li> <li style=\"\">Coaching healthcare organizations on visualization build and UI best practices </li> <li style=\"\">Troubleshooting and resolving technical visualization build issues</li> <li style=\"\">Developing and refining visualization best practices, standard processes, and documentation</li> <li style=\"\">Learning new BI visualization tools and refining standards as the healthcare analytics industry evolves</li> </ul><ul style=\"\"> <li style=\"\">Experience developing in one or more of the following BI platforms: Tableau, QlikView, Qlik Sense, or Power BI (Data preparation experience not required)</li> <li style=\"\">Ability to learn and master new BI platforms quickly</li> <li style=\"\">Knowledge of data visualization best practices</li> <li style=\"\">Ability to interpret business and visualization requirements and translate into a tangible deliverable</li> <li style=\"\">Strong communication skills; ability to lead visualization scoping sessions and demos with stakeholders at various levels</li> <li style=\"\">Experience in successfully balancing and prioritizing work across multiple customers and teams simultaneously</li> </ul><p><br></p><div class=\"h3\">Minimum Qualifications</div><ul style=\"\"> <li style=\"\">Experience developing in one or more of the following BI platforms: Tableau, QlikView, Qlik Sense, or Power BI (Data preparation experience not required)</li> <li style=\"\">Ability to learn and master new BI platforms quickly</li> <li style=\"\">Knowledge of data visualization best practices</li> <li style=\"\">Ability to interpret business and visualization requirements and translate into a tangible deliverable</li> <li style=\"\">Strong communication skills; ability to lead visualization scoping sessions and demos with stakeholders at various levels</li> <li style=\"\">Experience in successfully balancing and prioritizing work across multiple customers and teams simultaneously</li> </ul><div class=\"h3\"><br></div><div class=\"h3\">Desired Qualifications</div><ul style=\"\"> <li style=\"\">Healthcare industry knowledge and experience</li> <li style=\"\">Entry level exposure to or experience in one or more coding languages (SQL, Cache, Python, C#, etc.)</li> </ul><p><br></p><div class=\"h3\">Success Criteria</div><p>Successful team members at Prominence display the following:</p><ul style=\"\"> <li style=\"\">High degree of professionalism; treats others with respect, keeps commitments, builds trust within a team, works with integrity, and upholds organizational values. </li> <li style=\"\">Highly organized; able to manage multi-faceted workstreams.</li> <li style=\"\">Self-motivated; able to maintain schedule, meet deadlines, and monitor your personal work product.</li> <li style=\"\">Highly adaptable; able to acclimate quickly to new project assignments and work environments. </li> <li style=\"\">Creative; not paralyzed by problems and able to work collaboratively to find novel solutions.</li> <li style=\"\">Clear communication skills; ability to clearly convey messaging that resonates with your audience, in clear and concise written and verbal communications.</li> <li style=\"\">Can smell smoke and anticipate issues before they arise, ability to escalate effectively.</li> <li style=\"\">Passion to mentor and guide others.</li> </ul><p><strong>Benefits</strong></p><p>Prominence is dedicated to hiring the best and brightest minds in healthcare and maintaining a culture that rewards our employees for following their passion. We are excited to offer the following benefits for this position:</p><ul style=\"\"> <li style=\"\">Competitive Salaried and Hybrid Compensation Plans</li> <li style=\"\">Health Care Plan (Medical, HSAs, Dental &amp; Vision)</li> <li style=\"\">Retirement Plan (401k)</li> <li style=\"\">Life Insurance (Basic, Voluntary &amp; AD&amp;D)</li> <li style=\"\">Dependent &amp; Health Savings Accounts</li> <li style=\"\">Short Term &amp; Long Term Disability</li> <li style=\"\">Paid Time Off (Vacation/Sick &amp; Public Holidays)</li> <li style=\"\">Training &amp; Development Fund</li> <li style=\"\">Technology Stipends (for Qualifying Roles)</li> <li style=\"\">Work From Home</li> <li style=\"\">Charitable Giving to Causes You Believe In</li> </ul><div class=\"h3\"><br></div><div class=\"h3\">Employment Eligibility</div><p>Must be legally authorized to work in the United States without sponsorship.</p><div class=\"h3\"><br></div><div class=\"h3\">Commitment to Equal Opportunity</div><p>The world’s most talented professionals come from every background. All applicants will be considered for employment without attention to age, race, color, religion, gender identity and/or expression, sexual orientation, national origin, marital status, veteran or disability status, or any other characteristic protected by law. In addition, Prominence will provide reasonable accommodations for qualified individuals with disabilities.</p><p>If you are smart and good at what you do, come as you are. All qualified candidates are encouraged to apply.</p><div class=\"h3\"><br></div><div class=\"h3\">Partnership Eligibility</div><p>Our partnerships are extremely important to us. This online application is not intended for anyone who is currently under a non-compete agreement or has an arrangement that precludes employment at Prominence. We appreciate your help in respecting our partners.</p><p>Interested in learning more? Apply below to connect with our Talent team about immediate openings and future consulting projects.</p><img src=\"https://remotive.com/job/track/1553362/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1543112,"url":"https://remotive.com/remote-jobs/data/data-engineer-1543112","title":"Data Engineer","company_name":"Bankuish","company_logo":"https://remotive.com/job/1543112/logo","category":"Data","tags":["python","security","sql","design","programming","analytics","knowledge","data","business","infrastructure","ETL","warehouse","people","SOLID","startup","streaming","financial services","data-driven","support","information technology","architecture "],"job_type":"full_time","publication_date":"2023-01-11T11:39:44","candidate_required_location":"Brazil","salary":"","description":"<div class=\"h2\">About us</div>\n<p>Bankuish is a startup that helps millions of entrepreneurs and freelancers in Latin America access financial services. Our app connects gig workers with personalized loans and offers from the largest banks and institutions in the region. Together, we are helping banks better serve this niche and simultaneously helping gig workers improve their financial security.</p>\n<div class=\"h2\">The role</div>\n<p>The ideal candidate for this role has a solid foundation in creating data pipelines, ETL and analytical data warehouse. She/He will be responsible for our data and data pipeline architecture, as well as optimizing data systems and building them from the ground up.</p>\n<p>This role will support Data Scientists and Data Analysts by providing infrastructure and tools that can be used to deliver end-to-end solutions to business problems.</p>\n<div class=\"h2\">What you will do</div>\n<ul style=\"\">\n<li style=\"\">Build and automate data systems, processes, and models to help us scale our ability to evaluate gig workers, and to make financial services more accessible to millions of individuals around the world.</li>\n<li style=\"\">Evaluate, design, and implement analytics tools to facilitate data-driven decisions across the company.</li>\n<li style=\"\">Contribute to designing and building our data infrastructure. Influence the technical architecture, and help make decisions that shape the foundation of our data products.</li>\n<li style=\"\">Build reliable data services and robust ingestion pipelines for both structured and unstructured data sources.</li>\n<li style=\"\">Design and ship ETL/ELT pipelines that transform, aggregate, normalize, and master messy data.</li>\n<li style=\"\">Develop and automate large scale, high-performance data processing systems (batch and/or streaming).</li>\n<li style=\"\">Define data models for optimal storage</li>\n</ul>\n<div class=\"h2\">Responsibilities</div>\n<ul style=\"\">\n<li style=\"\">Build and optimize ETL.</li>\n<li style=\"\">Build dashboards.</li>\n<li style=\"\">Develop solutions to process a large volume of data.</li>\n<li style=\"\">Ensure data preparation, flow, and integrity.</li>\n<li style=\"\">Create data models and business indicators.</li>\n</ul>\n<div class=\"h2\">Desired Skills</div>\n<ul style=\"\">\n<li style=\"\">Knowledge in SQL.</li>\n<li style=\"\">Experience with streaming and batch pipelines.</li>\n<li style=\"\">Experience with python programming language.</li>\n<li style=\"\">Experience with ETL.</li>\n<li style=\"\">Knowledge in DW, dimensional modeling and data integration.</li>\n<li style=\"\">Degree in Information Technology desired</li>\n</ul>\n<div class=\"h2\">What Makes a Great Fit?</div>\n<p>We believe that people do their best work when they are aligned with the mission and company goals. We're looking for an experienced professional who is self-motivated, dynamic, and great working closely with small teams. The ideal candidate believes in doing hard things by doing them together. We're looking for someone who is excited to apply their personal superpowers to serve millions of gig workers – someone who is passionate about addressing issues of financial inclusion and democratizing access to financial services.</p>\n<div class=\"h2\">How we Work</div>\n<p>At Bankuish we are fully remote and widely dispersed, working from our own homes and neighborhoods across the world. We still prefer to collaborate and communicate in real-time.</p>\n<img src=\"https://remotive.com/job/track/1543112/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1544830,"url":"https://remotive.com/remote-jobs/data/edi-data-analyst-1544830","title":"EDI Data Analyst","company_name":"Reveleer","company_logo":"https://remotive.com/job/1544830/logo","category":"Data","tags":["analyst","sql","operations","healthcare","data analysis","data","troubleshooting","software development","business","inbound","development","communication","support","risk","CMS","software","outbound"],"job_type":"full_time","publication_date":"2023-01-10T23:40:23","candidate_required_location":"USA","salary":"","description":"<p><strong>EDI Data Analyst</strong></p>\n<p>Dynamic Healthcare Systems, a wholly owned subsidiary of Reveleer, is looking for an individual with Medicare EDI experience to join our team.  The EDI Data Analyst will support new and current EDI risk adjustment customers.  The Data Analyst will work directly with clients to assure timely, accurate, consistent, and complete submissions of encounter data.  Additionally, you will assist clients in mapping encounter data files to Dynamic standard formats, track inbound/outbound files sent by clients and processed in our proprietary software (Voyager), review errors received and document the errors with business friendly explanations, and assure optimal data integrity.  You will identify data issues or discrepancies between CMS rules and Voyager rules and report to the appropriate parties.  In this role, you will thoroughly analyze issues, identify the root cause, and work with the Integration team and Software Development team to correct the problems.  Every person at Dynamic has a hand in exceeding our clients' expectations, and you will play a key role in assuring our clients are fully utilizing the EDI risk adjustment module, and enjoying the full value of the solution.  Your daily work is likely to consist of:</p>\n<ul style=\"\"><li style=\"\">Performing audits on data imported and data exported</li><li style=\"\">Performing reconciliation on submitted records vs. received responses</li><li style=\"\">Providing analysis for root cause and correction actions for risk adjustment customers' Voyager errors</li><li style=\"\">Tracking and following up on risk adjustment files received, processed and submitted</li><li style=\"\">Documenting all mapping changes or issues</li><li style=\"\">Documenting weekly statuses, meeting minutes and clients' concerns</li><li style=\"\">Keeping up to date on CMS changes and assisting with development of new business requirements and functional specifications as they relate to risk adjustment </li></ul>\n<p> <strong>The Ideal Candidate will bring:</strong></p>\n<ul style=\"\"><li style=\"\">Medicare Advantage experience at the plan level in a systems operations capacity, interfacing with both the plan and CMS</li><li style=\"\">Three or more years of experience in Medicare risk adjustment and ANSI X12, working with Palmetto, CSSC, and CMS</li><li style=\"\">Experience processing 5010 and 837 files</li><li style=\"\">Advanced Data analysis in SQL</li><li style=\"\">Interfacing with clients to gather requirements and review operational statuses</li><li style=\"\">Excellent application troubleshooting based on data analysis</li><li style=\"\">Strong communication skills, both verbal and written</li><li style=\"\">Bachelor's degree or equivalent experience is required </li></ul>\n<img src=\"https://remotive.com/job/track/1544830/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1542975,"url":"https://remotive.com/remote-jobs/data/data-scientist-1542975","title":"Data Scientist","company_name":"Super Dispatch","company_logo":"https://remotive.com/job/1542975/logo","category":"Data","tags":["AWS","data science","machine learning","python","saas","sql","growth","operations","strategy","Engineering","product","TensorFlow","data","business","GCP","leadership","IT","marketplace","learning","organization","applications","support","Pytorch","insurance","software"],"job_type":"full_time","publication_date":"2023-01-10T09:40:22","candidate_required_location":"USA","salary":"","description":"<p>Super Dispatch is looking for an experienced Data Scientist<strong> </strong>to support the Product, Engineering, and Marketplace Operations teams by building reliable prediction solutions that can help Super Dispatch customers move cars faster. You will analyze and understand customer data, collaborate with other teams and departments, and improve existing recommendation and prediction engines. This is an exciting opportunity for an experienced data scientist to work on innovative solutions for our SaaS enabled marketplace.</p>\n<p><strong>What We Do:</strong></p>\n<p>Super Dispatch is one of the fastest growing tech startups in Kansas City, and we're transforming the world of vehicle shipping. The Super Dispatch platform is a one-stop-shop for everything Carriers and Shippers need to move cars faster, smarter, and easier. Backed by cutting edge technology and best-in-class software, Super Dispatch is the advanced auto transport experience taking carriers and shippers into the future.</p>\n<p><strong>Who We Are:</strong></p>\n<p>Our diverse team is comprised of highly motivated professionals with a passion for solving big problems with technology. Our core values are built around learning, growing, evolving, and continuous experimentation. We believe and practice taking bold risks. We embrace failure as a lesson. We put our team first. We are committed to supporting each other and helping each other grow on this journey.<br></p>\n<p><strong>Responsibilities:</strong></p>\n<ul style=\"\">\n<li style=\"\">Build and evolve transformative, real-time marketplace pricing engines based on machine learning and reflective of dynamic market conditions</li>\n<li style=\"\">Improve existing recommendation or prediction engines by collaborating with key stakeholders (internal and external)</li>\n<li style=\"\">Develop a deep understanding of the overall business of Super Dispatch and the Auto Transport industry</li>\n<li style=\"\">Improve machine learning models to deliver reliable and scalable solutions</li>\n<li style=\"\">Collaborate with other departments and teams to improve data collection, process and error handling, and data normalization</li>\n<li style=\"\">Provide thought leadership on data science to Product and Engineering Teams with best practices</li>\n<li style=\"\">Collaborate with Marketplace Operations and Data Teams to identify and resolve issues using data science and machine learning methodologies</li></ul>\n<ul style=\"\">\n</ul>\n<p><strong>Candidate Profile:</strong></p>\n<ul style=\"\">\n<li style=\"\">Curious  - you ask questions and are eager to learn.</li>\n<li style=\"\">Analytical mindset -  you are able to structure and process data and draw insightful conclusions from it.</li>\n<li style=\"\">Systematic thinker - you can balance big picture strategy with details, you have strong execution and delivery.</li>\n<li style=\"\">Problem solver - you have solved complex problems and have the aptitude to navigate uncharted waters.</li>\n<li style=\"\">Team player - you have a collaborative mindset, the ability to work with cross-functional teams, and build positive relationships with individuals across the organization.</li>\n<li style=\"\">Growth driven - you are willing to learn new tools and technologies to work effectively in a rapid growth environment with changing needs and requirements.</li>\n<li style=\"\">Self motivated - you work independently and take initiative.</li>\n</ul>\n<p><strong>Candidate Experience:</strong></p>\n<ul style=\"\">\n<li style=\"\">2+ years experience in a data scientist role, preferably working on a recommender system</li>\n<li style=\"\">2+ years of professional experience synthesizing insights from data using Python and SQL</li>\n<li style=\"\">2+ years experience with Machine Learning Frameworks (Tensorflow and/or PyTorch) and their real world applications</li>\n<li style=\"\">Experience working with AWS or GCP preferred</li></ul>\n<ul style=\"\">\n</ul>\n<p><strong>Summary of Benefits:</strong></p>\n<ul style=\"\">\n<li style=\"\">Stock options</li>\n<li style=\"\">Unlimited Vacation (PTO)</li>\n<li style=\"\">401k with company match</li>\n<li style=\"\">Health, dental, vision, and life insurance</li>\n<li style=\"\">12 weeks of paid parental leave</li>\n<li style=\"\">Fully remote/work from home role</li>\n<li style=\"\">Growth opportunities</li>\n<li style=\"\">Gym membership/wellness stipend</li>\n<li style=\"\">Equipment provided</li>\n</ul>\n<p>The salary range for this position is $100k - $120k annually.</p>\n<img src=\"https://remotive.com/job/track/1542975/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1545056,"url":"https://remotive.com/remote-jobs/data/data-engineer-1545056","title":"Data Engineer","company_name":"Viable Data Ltd","company_logo":"https://remotive.com/job/1545056/logo","category":"Data","tags":["consulting","looker","python","security","sql","ux","growth","management","design","agile","windows","analytics","data analysis","mentoring","NoSQL","data","Enterprise","tableau","business","ETL","warehousing","people","SDLC","culture","data warehousing","R","streaming","learning","data management","communication","statistics","time management","diversity","travel","digital products","training"],"job_type":"full_time","publication_date":"2023-01-10T07:39:45","candidate_required_location":"UK","salary":"","description":"<p><strong>About us</strong></p>\n<p>Viable Data is an innovative technology, data and UX consultancy, delivering excellence through our projects and providing our people with a supportive culture and opportunities for growth and continuous learning.</p>\n<p>We thrive on the challenge of working across different projects, user needs and technologies and our teams and people live this every day. Our people-first approach and culture is central to our growing success as a consultancy.</p>\n<p>We are an all-inclusive equal opportunities employer and proudly celebrate diversity. If you thrive on challenge, have a passion to learn and make a difference, and enjoy being part of a growing multidisciplinary team, look no further and start your Viable career, now.</p>\n<p><strong>About the role</strong></p>\n<p>As a Data Engineer at Viable Data, you will be at the forefront to ensure that data is in the right state and format, ready to implement data schemas and models, making sure that the data is ready and available for data mining purposes.</p>\n<p>You will be someone who can adapt quickly and easily to the flexible needs of our Central Government customers. You will join one of our high-performing consulting teams where you will play a pivotal role in designing &amp; delivering exceptional digital products and services that directly contribute to the delivery of UK policy, economic growth and security.</p>\n<p><strong>This role is largely remote with occasional business essential travel.</strong></p>\n<p><strong>Requirements</strong></p>\n<p><strong>Key responsibilities</strong></p>\n<ul style=\"\">\n<li style=\"\">Experience of pragmatic, hands-on analysis of enterprise-scale data projects across the full SDLC from design to migration, integration and live service in an Agile environment • Experience of analysis and design of solutions using one or more from: SQL and noSQL technologies, data streaming, logging and monitoring tools, BI and Data Warehousing solutions and ETL and migration technologies</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">A thorough understanding of one or more from: Master Data Management, Data Lineage analysis, Metadata Management, Data Quality assessment and management, Data Transformation and migration</li>\n<li style=\"\">Ability to apply advanced analytics and statistics techniques to business problems</li>\n<li style=\"\">Proven experience of working with large volumes of data, applying tools such as SAS, R, Python, SQL, PowerBI, Tableau, Looker</li>\n<li style=\"\">Excellent communication skills and ability to tell stories / influence with data</li>\n</ul>\n<p><strong>Skills and experience needed</strong></p>\n<ul style=\"\">\n<li style=\"\">Proven relevant industry experience.</li>\n<li style=\"\">Excellent written and verbal communication abilities - presenting findings and related design/business recommendations and insights clearly that stakeholders can understand and use. Able to communicate with stakeholders at all levels.</li>\n<li style=\"\">Proven analysis skills - experience of various data analysis methods at enterprise scale</li>\n<li style=\"\">People skills – empathetic, great listener and have a natural curiosity to understand people, their motivations and thought processes.</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Experience and understanding of a range of User Centred Design practices</li>\n<li style=\"\">Organisation, time management and collaboration skills</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p><strong>Why work with us?</strong></p>\n<p>As well as providing a great place to work that has an amazing culture and the opportunity to work on excellent projects where you will really make a difference, we have a whole host of additional employee benefits.</p>\n<p>Our benefits package includes:</p>\n<ul style=\"\">\n<li style=\"\">25 days leave</li>\n<li style=\"\">5 days dedicated training allowance, with individual budget</li>\n<li style=\"\">Mentoring system, with 6-month review cycles</li>\n<li style=\"\">Flexible hours and supportive of remote working</li>\n<li style=\"\">5% pension company contributions</li>\n<li style=\"\">Annual bonus based on company performance</li>\n<li style=\"\">Choice of company laptop (Macbook, Windows) </li>\n</ul>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1545056/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546497,"url":"https://remotive.com/remote-jobs/data/data-collection-management-1546497","title":"Data collection/Management","company_name":"Jumanji Studio","company_logo":"https://remotive.com/job/1546497/logo","category":"Data","tags":["big data","finance","management","design","strategy","mentoring","data","people","startup","IT","themes","support","architecture "],"job_type":"internship","publication_date":"2023-01-09T21:39:54","candidate_required_location":"Europe","salary":"","description":"<p><a class=\"external\" href=\"https://www.jumanji.studio/\" rel=\"nofollow\">Jumanji Studio</a>, one of the first startup studios focusing solely on positive impact, is looking for <strong>t</strong><strong>alented fellows</strong> to support its partners in developing the studio and its startups.</p>\n<p><strong>The company </strong></p>\n<p>Jumanji Studio is a startup studio founded by experienced entrepreneurs and investors in the impact space with the goal to bring the best of entrepreneurship against environmental issues.</p>\n<p>We believe that the ecological transition needs to happen with new players and solutions.</p>\n<p>We empower driven entrepreneurs in a synergic way to build and grow businesses with strong impact potential in the fields of circular economy and impact ecosystems.</p>\n<p>As a startup studio we design solutions from scratch, finance and grow them into independent startups with their own team that we carefully build with extraordinary entrepreneurs.</p>\n<p>Since 2019, we’ve launched 7 startups, brought in 10 entrepreneurs and 70 experts, sold our 1st startup, and raised a cumulative EUR 4m across our studio startups.</p>\n<p><strong>The Jumanji Fellowship</strong> is an opportunity we have specifically designed for driven, eco-conscious individuals starting out their career, starting afresh in this field, or who want to contribute but do not know in what way.</p>\n<p><strong>What we have to offer in a 2-3 month (or less) relationship</strong></p>\n<p>An extremely rich and dynamic environment with an opportunity to witness how a startup is launched. The chance to weigh on the strategy of the studio or one of our startups. The time to deep dive into one or two sustainability-related issues and themes.</p>\n<p><strong>What we will expect from you</strong></p>\n<p>A two-three months mission is rich if it is focused. We will agree with you on one or two missions based on your experience, your interest, and our needs prior to the time you start the program. If you only have some hours a week available that's fine.</p>\n<p>We have 2 new startup projects:</p>\n<p>Gaia connect : Mentoring \"impact digital platform\"</p>\n<p>Nozama : Decarbonize the goods delivery market</p>\n<p><strong>So we have new missions for Fellows</strong></p>\n<ul style=\"\">\n<li style=\"\">Gaia Connect -&gt; Can you suggest us a data/tech architecture for:</li>\n</ul>\n<p>1) Token Economy - how to create/set it up <br>2) Matching people (via algorithm and big data)</p>\n<ul style=\"\">\n<li style=\"\">Nozama :</li>\n</ul>\n<p>1) Carbon footprint : Can you suggest data and algorithm</p>\n<p>2) How data makes home appliances more circular ?</p>\n<p><strong>Requirements</strong></p>\n<p><strong>Jumanji is looking for two things in the people we work with </strong></p>\n<p>You need to come with sheer optimism, a positive energy, a persevering courage, and an open mindset.</p>\n<p>We want to work with people who have a real ambition for the planet. If you see yourself as dedicating all your skills for a positive change, then we’ll show you it’s possible.</p>\n<p><strong>What we’ll expect from you</strong></p>\n<p>A two/three-month mission is rich if it’s focused. We’ll agree with you on 1 or 2 missions that make sense based on your experience, your interest, and our needs closer to the time you start. You’ll be your own boss from there.</p>\n<p><strong>Benefits</strong></p>\n<p>You work when you want:</p>\n<p>- Full-time = for 2 months or more</p>\n<p>- Part-time = if you want to work some hours per week, that's possible</p>\n<p>Location = Flexible, part of our team is fully remote in Europe. We don’t care, you work from anywhere.</p>\n<p>Unpaid internship</p>\n<p>Free access to The Spaceship Academy : <a class=\"external\" href=\"https://www.thespaceship.org/\" rel=\"nofollow\">https://www.thespaceship.org/</a></p>\n<p>Coworking space available in Paris or Biarritz</p>\n<img src=\"https://remotive.com/job/track/1546497/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546120,"url":"https://remotive.com/remote-jobs/data/head-of-data-operations-1546120","title":"Head of Data Operations","company_name":"Viridios","company_logo":"https://remotive.com/job/1546120/logo","category":"Data","tags":["data science","excel","finance","python","sql","management","operations","ai","project management","Engineering","product","NoSQL","data","recruiting","creative","English","business","warehouse","leadership","metrics","events","development","domain","reporting","IT","problem-solving","themes","computer science","communication","support","equities","risk","software"],"job_type":"full_time","publication_date":"2023-01-08T19:39:54","candidate_required_location":"UK","salary":"","description":"<p><strong>Head of Data Operations</strong></p>\n<p>Viridios AI is at the forefront of solutions for the climate and sustainability markets. We have developed AI-based fair valuation and risk management models that solves a major problem in value transparency and is quickly becoming the market reference for fair prices of carbon credits (offsets), from forestry and agriculture to renewable energy and energy efficiency activities worldwide. Our company and product have recently been recognized as <a href=\"https://www.environmental-finance.com/content/awards/voluntary-carbon-market-rankings-2022/\" rel=\"nofollow\">Best Market Innovation</a> by Environmental Finance, one of the major publications in the fast growing carbon markets space.</p>\n<p>There is much to do when it comes to applying technology in doing right by the planet and its inhabitants, and we are always looking for highly talented individuals to join us in this journey.</p>\n<p>We are now recruiting for a Head of Data Operations to join a highly qualified team with domain expertise and years of experience in markets and technology. The typical candidate works with a major market data provider, a bank or an asset manager dealing with market data in various asset classes (equities, fixed income, commodities, etc) as well as various other datasets such as reference data, etc. This is your opportunity to grow into and contribute to some of the most prominent and important themes of our age: climate, sustainability and technology.</p>\n<ul style=\"\">\n<li style=\"\">This is a permanent position</li>\n<li style=\"\">You will report to the CEO</li>\n<li style=\"\">Candidates based in the UK or Continental Europe</li>\n<li style=\"\">You will be working remote</li>\n</ul>\n<p><strong>What We Offer</strong></p>\n<ul style=\"\">\n<li style=\"\">Competitive base compensation</li>\n<li style=\"\">Annual cash bonus</li>\n<li style=\"\">Employee stock allocated upfront with tremendous upside</li>\n<li style=\"\">A vibrant and creative work environment</li>\n<li style=\"\">Exposure to one of the most exciting sectors today</li>\n</ul>\n<p><strong>Responsibilities</strong></p>\n<ul style=\"\">\n<li style=\"\">Lead the data operations team (5 currently, 8 budgeted) comprising of market data and carbon project data operations</li>\n<li style=\"\">Maintain and build all data sourcing, validation and publication processes</li>\n<li style=\"\">Ensure that all data operations delivery processes are fully operational and reliable</li>\n<li style=\"\">Expand data sourcing operations in the carbon markets through the establishment of new commercial relationships with partners</li>\n<li style=\"\">Represent the company at events and conferences</li>\n<li style=\"\">Contribute to the company's credibility through thought leadership on carbon markets data</li>\n<li style=\"\">Contribute to regular publication of newsletters on carbon markets</li>\n<li style=\"\">Perform daily market data and weekly carbon project data publication sign off</li>\n<li style=\"\">Work closely with market data team on daily data preparation, validation and calibration for Golden Source data warehouse</li>\n<li style=\"\">Work closely with carbon project data team on weekly data preparation, validation and calibration for Golden Source data warehouse</li>\n<li style=\"\">Monitor and maintain the integrity and validity of the data being sourced, processed and published</li>\n<li style=\"\">Work alongside the data science team on datasets preparation to be used in model development</li>\n<li style=\"\">Work closely with market data team on maintaining and calibrating model data inputs and parameters</li>\n<li style=\"\">Lead the designing, building and maintenance of reports and data dashboards used to derive insights from data</li>\n<li style=\"\">Validate and support data models, data-mining methodologies, and reporting of metrics to stakeholders</li>\n</ul>\n<p><strong>Required</strong></p>\n<ul style=\"\">\n<li style=\"\">Bachelor's degree in business, finance or in a technical area (e.g., computer science, engineering, physics, mathematics, etc)</li>\n<li style=\"\">Deep understanding and hands-on experience with data operations in financial markets (market data, reference data, etc)</li>\n<li style=\"\">Experience working with data products and financial data platforms (Bloomberg, ICE, etc)</li>\n<li style=\"\">Professional experience in financial markets with banks, asset managers, market data providers and platforms, etc</li>\n<li style=\"\">Excellent attention to detail and organizational skills</li>\n<li style=\"\">Strong time and project management skills</li>\n<li style=\"\">Fast learner, capable of quickly gaining domain expertise in the highly complex climate and sustainability markets</li>\n<li style=\"\">Clear analytical and problem-solving skills with the ability to envision and propose new and creative ways to solutions</li>\n<li style=\"\">Passion for technology and data, and issues related to climate and sustainability markets</li>\n<li style=\"\">Ability to work well with teams in a collaborative way</li>\n<li style=\"\">Exceptional business and technical communication in English, verbal and written</li>\n<li style=\"\">Proficiency in Excel and other data business tools</li>\n</ul>\n<p><strong>Desired</strong></p>\n<ul style=\"\">\n<li style=\"\">Ability to run Python code (not necessarily build Python software)</li>\n<li style=\"\">Ability to run in SQL and NoSQL (Mongo) queries</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1546120/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546353,"url":"https://remotive.com/remote-jobs/data/senior-data-engineer-1546353","title":"Senior Data Engineer","company_name":"yoldacom","company_logo":"https://remotive.com/job/1546353/logo","category":"Data","tags":["apache","api","AWS","backend","cloud","data science","docker","git","java","kubernetes","python","scala","sql","management","operations","design","programming","B2B","research","Engineering","product","languages","NoSQL","data","JS","spark","English","software development","business","infrastructure","node","ETL","google cloud","data engineering","culture","SOLID","events","data pipelines","database","development","IT","streaming","math","serverless","applications","Apache Spark","communication","support","architecture ","insurance","programs","webinars","software","BigQuery","training"],"job_type":"full_time","publication_date":"2023-01-08T03:39:15","candidate_required_location":"Turkey","salary":"","description":"<p>As a “Digital Freight Forwarder”, Yolda.com aims to improve and optimize logistics operations, increase transparency during the logistics process and lead digitalization efforts in the sector with the technologies and solutions developed in-house. Our mission is to become the leading B2B freight forwarding company in the region with smart management of our large carrier network of logistics companies and freelance truck drivers.</p>\n<p>Yolda.com, founded in March 2020, has raised 8m USD funding in total so far from reputable local and international investors such as Speedinvest and Collective Spark as well as from global prominent angel investors. Yolda.com is currently looking for motivated talents who are passionate to disrupt the logistics sector which has been delivered in the same conventional way for centuries.</p>\n<p>As a Senior Data Engineer, you will be developing data-intensive pipelines and applications and you will design all development cycles of services for data products.</p>\n<p><strong><u>Responsibilities</u></strong></p>\n<ul style=\"\">\n<li style=\"\">Understanding logistics business and the data at massive scale behind it.</li>\n<li style=\"\">You will help to build a data platform to enable other teams to self service high quality data while performing data operations to support their day-to-day actions.</li>\n<li style=\"\">You'll support designing and creating all aspects of our ever-growing set of external and internal data pipelines, understand the problems, and tie them back to data engineering solutions</li>\n<li style=\"\">You will not only develop a pipeline but also you develop end to end services (like api,backend) as a data product</li>\n<li style=\"\">You will support to develop secure, reliable, scalable, sustainable ML/DL based data products and build infrastructure and development services for Dataops and MLops processes</li>\n<li style=\"\">Work closely with Platform, Data Science and Backend teams, as well as product and tech teams.</li>\n</ul>\n<p><strong><u> </u></strong></p>\n<p><strong><u>Qualifications</u></strong></p>\n<ul style=\"\">\n<li style=\"\">At least 3 years of professional experience as a Software/Data Engineer, and hold a degree in a quantitative field (CS, Engineer, Math, Physics, … ),</li>\n<li style=\"\">Hands-on experience with data technologies on cloud providers AWS or other cloud providers like Google Cloud etc.</li>\n<li style=\"\">Good communication in English,</li>\n<li style=\"\">Strong object-oriented design and software development skills like( clean code, solid, design patterns, etc),</li>\n<li style=\"\">Experience with Python is a must, also other programming languages like java, node js, and scala are also considerable,</li>\n<li style=\"\">Experience with ETL/ELT, batch, and streaming data processing pipelines,</li>\n<li style=\"\">Strong SQL experience and tuning/optimize query to optimize data load, materialization, and transformation times,</li>\n<li style=\"\">Experience with containerization technologies like Docker. Understanding orchestration tools for container like Kubernetes is a plus,</li>\n<li style=\"\">Experience SQL and NoSQL database/datastore technologies and know the differences and architectures behind them,</li>\n<li style=\"\">Experience and understanding of distributed data warehouses like Redshift and Google Bigquery,</li>\n<li style=\"\">Experience and understanding of distributed data processing frameworks like Apache spark, Apache Flink</li>\n<li style=\"\">Experience and understanding of data workflow orchestration frameworks like Apache airflow, dagster, prefect etc.</li>\n<li style=\"\">Experience and understanding of data file/storage format like parquet, avro etc.</li>\n<li style=\"\">Experience and ability to design data model on OLAP systems and real-time analytic system,</li>\n<li style=\"\">Experience code version systems like Git,</li>\n<li style=\"\">Open to new technologies and do POC. Willingness to do research and able to gather information to find out and apply best practices</li>\n</ul>\n<p> </p>\n<p><strong><u>Why You'll Love Working at Yolda.com</u></strong></p>\n<p>Join our team, join our dream: logistics and technology!</p>\n<p>Yolda.com is growing fast and allows our team members to share their unique perspectives, solve new challenges, and own their careers.</p>\n<p>Our company culture and work environment continue to flourish digitally with business updates, well-being programs, hackathons, virtual coffee catch-ups, webinars, and more.</p>\n<ul style=\"\">\n<li style=\"\">Working with modern tech stack and serverless cloud architecture</li>\n<li style=\"\">Chance to take responsibility from the first day, grow your skills and learn continuously</li>\n<li style=\"\">Competitive private health insurance coverage</li>\n<li style=\"\">Training and development opportunities</li>\n<li style=\"\">Work from home, office, or hybrid model</li>\n<li style=\"\">Best equipment for tech geniuses: MacBook, monitor and more</li>\n<li style=\"\">Team Events &amp; happy hours</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1546353/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547306,"url":"https://remotive.com/remote-jobs/data/01-gett-data-engineer-1547306","title":"01 Gett: Data Engineer","company_name":"Adaptiq","company_logo":"https://remotive.com/job/1547306/logo","category":"Data","tags":["AWS","big data","business intelligence","devops","docker","excel","golang","kubernetes","mobile","python","management","automation","b2c","Engineering","mobility","product","CI/CD","analytics","knowledge","data","spark","software development","business","infrastructure","terraform","ETL","warehouse","warehousing","data engineering","data pipelines","data warehousing","development","reporting","IT","marketplace","organization","applications","data-driven","microservices","support","production","server","software"],"job_type":"full_time","publication_date":"2023-01-07T01:39:57","candidate_required_location":"Poland","salary":"","description":"<p>Gett was established 12 years ago, as a ride-hailing solution, and since then has expanded its activity globally, across Europe and the United States.<br>Nowadays, Gett is a Ground Transportation Solution with the mission to organize all the best mobility providers in one global platform - optimizing the entire experience from booking and riding to invoicing and analytics, to save businesses time and money. We work with a third of the Fortune 500 companies and have over 17K active business customers across the world. </p>\n<p>The GTM - the Ground transportation management,  is a worldwide 1.4 trillion market involving Drivers, Riders, Suppliers, and Businesses, and a secured product platform and the marketplace are crucial for successful operation.</p>\n<p>Gett RnD is a top-notch engineering organization that develops a microservices-based system, high-scale ready, fulfilling strict availability and reliability requirements (as a B2C and a B2B2C platform) and managing significant traffic load.<br>Our system is developed mostly using Golang, runs in AWS, and involves ML at the applicable areas, to provide the best transportation solution for our customers, and maximizes Gett's performance.</p>\n<p><strong>Background: </strong></p>\n<p>Gett is a Ground Transportation Solution with the mission to organize all the best mobility providers in one global platform - optimizing the entire experience from booking and riding to invoicing and analytics, to save businesses time and money. We work with a third of the Fortune 500 companies and have over 17K active business customers across the world. </p>\n<p>We are looking for an<strong> Automation Engineer</strong> who will excel in our RnD team.</p>\n<p>We work in a fast-paced environment. Our systems are composed of 2 mobile applications and 180+ microservices that are deployed to production dozens of times a day, live in production with a high standard of system availability 99.99%. Therefore we need to keep very high automation coverage in our systems.</p>\n<p><strong>Gett </strong>is the place where you come to when you need to be on the move with confidence, regardless if you are a member of the general public, a business customer, a driver or a partner. We provide the best possible service our customers can get, where it matters the most. And you can make our team stronger than ever!</p>\n<p>Gett's Data team is looking for a talented Data Engineer to join us.</p>\n<p>The Data Engineer will be a key member of the data team, at the core of a data-driven company, developing scalable, robust data pipelines, data models, and to provide business intelligence.</p>\n<p>Come and work in an evolving, challenging environment with a variety of data sources, technologies, and stakeholders, to deliver the best solutions to support the business and provide operational excellence.</p>\n<p><strong>Responsibilities:</strong></p>\n<ul style=\"\">\n<li style=\"\">Building the next generation of the Data Warehouse, moving from old and legacy models into more robust.</li>\n<li style=\"\">Building new ETL pipelines and bugfix old one.</li>\n<li style=\"\"> Improve data quality and ingestion; identify root cause of data issues and provide resolution ensuring accuracy and trust in everything we build.</li>\n<li style=\"\">Ensure that the local data needs are taken into account by the global BI team.</li>\n<li style=\"\">Debug reports or automatic Python scripts and ensure the reporting server infrastructure is connecting correctly to our main data sources.</li>\n<li style=\"\">Contribute to pieces of analysis to inform business decisions.</li>\n</ul>\n<p><strong>Requirements:</strong></p>\n<ul style=\"\">\n<li style=\"\">Minimum 2 years of experience in software development/data engineering/business intelligence - <strong>A must</strong>.</li>\n<li style=\"\">Strong experience in data modeling, ETL development, and data warehousing - <strong>A must</strong>.</li>\n<li style=\"\">Experience with Python - <strong>A must</strong>.</li>\n<li style=\"\">Big data technologies (Spark , Hive, Spark, Presto, Airflow) - <strong>An advantage</strong>.</li>\n<li style=\"\">Experience working with AWS big data technologies (S3, EC2, EKS) - <strong>An advantage</strong>.</li>\n<li style=\"\">Knowledge in containerized environments (Docker, Kubernetes) - <strong>An advantage</strong>.</li>\n<li style=\"\">Knowledge of infrastructure and DevOps (CI/CD, Terraform) - <strong>An advantage</strong>.</li>\n</ul>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1547306/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547478,"url":"https://remotive.com/remote-jobs/data/data-test-engineer-1547478","title":"Data & Test Engineer","company_name":"HiveMind Network","company_logo":"https://remotive.com/job/1547478/logo","category":"Data","tags":["azure","devops","git","go","python","scrum","sql","agile","product","analytics","languages","data","English","business","selenium","ETL","warehouse","leadership","domain","reporting","kanban","testing","Azure Devops","travel","insurance","server","data migration"],"job_type":"contract","publication_date":"2023-01-06T17:39:28","candidate_required_location":"Europe","salary":"","description":"<p><strong>JOB Title:  </strong>                           <strong>Data Engineer in Test</strong></p>\n<p><strong>Department/Business Unit: </strong>    <strong>Test to join our Data &amp; Analytics team</strong></p>\n<p><u><strong>ORGANISATION AND SCOPE</strong></u></p>\n<p>Our client, provides liability insurance for around 9% of world shipping, with premium income of almost $300m.</p>\n<p><strong><u>Role Purpose</u></strong></p>\n<p>The new leadership team is investing in a product centric, agile business model. We have three domain aligned Product teams, who deliver technology products for the benefit of internal users, our members and brokers. This role will be part of our Claims product team, they work hand in hand with our global claims function to ensure we provide excellent service to our members when they need us the most. The team is a cross-functional agile delivery team, all members of the team are expected to be T-shaped working to deliver value for our club and members as fast as possible.</p>\n<p><strong>This role is focused on testing but we are looking for</strong></p>\n<p><strong>Role: Data Engineer in Test</strong></p>\n<p><strong><u>Main Tasks/Key Accountabilities/Responsibilities:</u></strong></p>\n<p><strong>Required</strong></p>\n<p>·         Data focused test engineer with strong SQL skills / capabilities.</p>\n<p>·         Experience working with SQL Server, Power BI, SSRS.</p>\n<p>·         Will be responsible for testing peers code changes &amp; reconciliation of data.</p>\n<p>·         Test planning / preparation, execution and reporting of results.</p>\n<p><strong>Desirable</strong></p>\n<p>·         Experience with automated testing frameworks e.g. Selenium.</p>\n<p>·         Experience with source control versioning systems e.g. GIT.</p>\n<p>·         Experience working on large ETL / data warehouse projects.</p>\n<p>·         Azure DevOps.</p>\n<p>·         Python.</p>\n<p>·         Working to agile methodologies e.g. Scrum/Kanban.</p>\n<p>·         Experience in the insurance sector, also highly desirable.</p>\n<p>SQL, data reconciliations, Python, reasonable technical but with background in testing. Data reconciliation is what they will predominantly be doing (as a result of data migration work). Potentially digging in reports (most will go back to devs)</p>\n<p>This role is a fully remote opportunity, with occasional travel to client site/s </p>\n<p>Applicants <u><strong>must have the Right to Work</strong></u> in the UK or EU to be considered </p>\n<p>Excellent English verbal &amp; written skills is a Must</p>\n<p>Any additional European  languages is an advantage</p>\n<img src=\"https://remotive.com/job/track/1547478/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546201,"url":"https://remotive.com/remote-jobs/data/data-warehouse-engineer-1546201","title":"Data Warehouse Engineer","company_name":"In All Media Inc","company_logo":"https://remotive.com/job/1546201/logo","category":"Data","tags":["AWS","python","sql","data","English","software development","ETL","warehouse","hiring","Snowflake","database","development","media","communication","software"],"job_type":"full_time","publication_date":"2023-01-05T23:39:41","candidate_required_location":"Argentina","salary":"","description":"<p>We are hiring!</p>\n<p>Here at In All Media, a Software Development Company based in Austin, TX, we are looking for the best talent to join our company and at this time we are currently looking for a Sr. Data Warehouse Engineer to join our team.</p>\n<p> </p>\n<p>The candidate must be proficient in:</p>\n<p>● Strong experience with SQL.<br>● Experience with AWS ETL.<br>● Experience with ETL methodologies.<br>● Preferred Snowflake Database.<br>● Excellent oral and written communication skills in English.<br><br>Nice to Have:<br><br>- Python</p>\n<p>Are you up for this challenge?</p>\n<p><br>This is a Full-time, 100% remote position with payments in USD.</p>\n<p>If you find this information interesting please let me know.</p>\n<p> </p>\n<p>Apply now!</p>\n<img src=\"https://remotive.com/job/track/1546201/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547136,"url":"https://remotive.com/remote-jobs/data/senior-data-analyst-1547136","title":"Senior Data Analyst","company_name":"api.video","company_logo":"https://remotive.com/job/1547136/logo","category":"Data","tags":["analyst","api","developer","finance","linux","looker","microsoft","sql","video","growth","email","Engineering","product","CRM","data analysis","knowledge","data","creative","English","business","Snowflake","KPIs","metrics","events","development","streaming","kibana","grafana","communication","support","stripe"],"job_type":"full_time","publication_date":"2023-01-05T23:39:39","candidate_required_location":"CET (UTC+1)","salary":"","description":"<p><a href=\"http://api.video/\" rel=\"nofollow\">api.video</a> is an API-first platform that enables developers to build, scale and operate on-demand and live video streaming in their own apps and platforms in minutes, with just a few lines of code. The service handles the end-to-end workflow, from video ingestion to worldwide video delivery.Just like Stripe for payments, Twilio for text/VOIP, and Sendgrid for email; we're making video accessible to every client and developer via our api, the world over.</p>\n<p>You will join our brand new Data team. As the very first Data Analyst, you will be the main point of contact to support the Product, Finance, Customer Success and Engineering teams in their needs of Insights, Monitoring and more at strategic and operational level. Below some examples:</p>\n<ul style=\"\">\n<li style=\"\">Correlate cohorts and usages to determine behaviour patterns</li>\n<li style=\"\">Monitor performances of funnels like SignUps → Subscriptions</li>\n<li style=\"\">Write tracking-plans at the foundation of upcoming analyses <em>(e.g. app-events for User Journey)</em></li>\n</ul>\n<p><strong>What will you be doing? 🛠️</strong></p>\n<ul style=\"\">\n<li style=\"\">Proactively initiating processes to collect Business and Product needs in order to translate them into operational tasks.</li>\n<li style=\"\">Helping identify KPIs/local metrics and make sure we are able to track, monitor them and measure impact of any project we drive.</li>\n<li style=\"\">Building long-term analytical assets <em>(dashboards and reportings)</em> to help teams take data driven decisions.</li>\n<li style=\"\">Providing appropriate and clear recommendations based on qualitative analysis outcomes.</li>\n<li style=\"\">Defining Data Modeling guidelines to guarantee a consistent, smooth and performent query experience.</li>\n</ul>\n<p><strong>What can you expect at <a href=\"http://api.video/\" rel=\"nofollow\">api.video</a>?🏆</strong></p>\n<ul style=\"\">\n<li style=\"\">Global presence with an international working environment.</li>\n<li style=\"\">100% Remote possible <em>(we have an HQ in Bordeaux, and we rely on many coworking spaces, CET timezones).</em></li>\n<li style=\"\">We offer competitive salaries.</li>\n<li style=\"\">Flexible timetable - we value results over presence.</li>\n<li style=\"\">Work in your preferred System and OS <em>(Mac, Linux, Microsoft).</em></li>\n<li style=\"\">Your voice is valued and will count in our decision making.</li>\n<li style=\"\">Personal Growth. We invest in your career development; do you need books or to attend conferences? We got you covered!</li>\n</ul>\n<p><strong>What are we looking for?</strong></p>\n<ul style=\"\">\n<li style=\"\">4/5+ years of experience in Data analysis. Proficiency in SQL.</li>\n<li style=\"\">Significant experience with Looker <em>(or similar)</em> for explorations.</li>\n<li style=\"\">Creative team player, autonomous, eager to learn every day and continually suggesting innovative ideas.</li>\n<li style=\"\">Ease to switch from projects of different natures <em>(business, product or technical)</em>.</li>\n<li style=\"\">Excellent verbal and written communication in English.</li>\n</ul>\n<p><strong>Nice to have :</strong></p>\n<ul style=\"\">\n<li style=\"\">Snowflake knowledge is a plus.</li>\n<li style=\"\">Observability through Kibana and/or Grafana.</li>\n<li style=\"\">CRM tools.</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1547136/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546455,"url":"https://remotive.com/remote-jobs/data/senior-data-scientist-1546455","title":"Senior Data Scientist","company_name":"Degreed","company_logo":"https://remotive.com/job/1546455/logo","category":"Data","tags":["amazon","analyst","AWS","azure","cloud","data science","docker","education","elasticsearch","git","kubernetes","machine learning","microsoft","python","sql","growth","management","email","databases","content","Engineering","product","analytics","languages","knowledge","NoSQL","data","recruiting","business","infrastructure","NLP","hiring","people","database","development","IT","R","software engineering","RDF","learning","law","natural language processing","micro-services","math","coding","networks","testing","computer science","search","communication","support","architecture ","production","insurance","software","training"],"job_type":"full_time","publication_date":"2023-01-04T23:39:23","candidate_required_location":"USA","salary":"","description":"<div class='\"content-intro\"'>\n<div>Degreed is the upskilling platform that connects learning to opportunities. We integrate everything people use to learn and build their careers—skill insights, LMSs, courses, videos, articles, and projects—and match everyone to growth opportunities that fit their unique skills, roles, and goals. Degreed exists to discover, empower and recognize the next generation of the world's expertise. </div>\n</div>\n<p>Degreed is the upskilling platform that connects learning to opportunities. We integrate everything people use to learn and build their careers—skill insights, LMSs, courses, videos, articles, and projects—and<br>match everyone to growth opportunities that fit their unique skills, roles, and goals.</p>\n<p>The Data Science team at Degreed works with large structured and unstructured datasets to understand how people develop the skills that they need to advance their careers. To do this, we use a diverse set of<br>tools and approaches, including feature engineering, clustering, classification and recommendation models, word embeddings, and neural networks. Degreed is looking for a capable, qualified and versatile. Data Scientist to help with the development and delivery of high-quality, data-driven, machine learning and predictive modeling solutions.</p>\n<p><strong>Position can be located in US, Brazil, or India.</strong></p>\n<div class=\"h3\">Day in the Life</div>\n<p>Lead multiple end-to-end ML projects</p>\n<ul style=\"\">\n<li style=\"\">Discover and translate business challenges to data problems, data-pipelines and model framework</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Mine structured and unstructured data (company internal data and public data)</li>\n<li style=\"\">Engineer features, build models, and evaluate model performance</li>\n<li style=\"\">Collaborate with product and engineering teams to deploy models to support production</li>\n<li style=\"\">Deliver fast while continually adjusting models according to real-time feedback</li>\n<li style=\"\">Communicate about data science with a diverse set of stakeholders and development partners</li>\n<li style=\"\">This is not a data analyst role</li>\n<li style=\"\">This description reflects management's assignment of essential functions; it does not prescribe or restrict other tasks as assigned and is subject to change at any time.</li>\n</ul>\n<div class=\"h3\">Who You Are</div>\n<ul style=\"\">\n<li style=\"\">4+ year hands-on experience in one of the following areas: applied machine learning, machine learning infrastructure, large-scale recommendation systems, market-facing machine learning production software. Including 2+ years focusing on developing knowledge graphs, or NLP models or content recommendation systems</li>\n<li style=\"\">Strong coding skills in Python, or R</li>\n<li style=\"\">Advanced skills in database querying (SQL, noSQL) and search techniques</li>\n<li style=\"\">Experience building prototypes and experiments to validate technical ideas</li>\n<li style=\"\">Familiarity in developing cloud-based solutions using micro-services architecture, docker containers and Kubernetes</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Ability to work in different coding environments (local, notebooks, containers) and familiar with software engineering workflows (testing, code management/Git)</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Ability to blend together diverse data sources to create training data for specific problems</li>\n<li style=\"\">Excellent written and verbal communication skills. We’re a distributed team and rely on good communication to perform at a high level</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Experience working remotely - It takes a self-motivated individual to thrive on a distributed team</li>\n</ul>\n<p> </p>\n<ul style=\"\">\n<li style=\"\">You are a lifelong learner and passionate about learning new things and taking on new challenges</li>\n</ul>\n<div class=\"h3\">What Sets You Apart</div>\n<ul style=\"\">\n<li style=\"\">\n<p>Experience working with graph data models (RDF, Property), graph query languages (Gremlin,</p>\n<p>SPARQL, Cypher), or graph databases (Azure CosmosDB, Amazon Neptune, Neo4J,</p>\n<p>TigerGraph)</p>\n<ul style=\"\">\n<li style=\"\">Experience in Natural Language Processing techniques for entity resolution, disambiguation, and</li>\n</ul>\n<p>linking</p>\n<ul style=\"\">\n<li style=\"\">Experience with tools and platforms like ElasticSearch, Microsoft Azure, AWS, BERT, GPT,</li>\n</ul>\n<p>Word2Vec (w2v), Databricks</p>\n<ul style=\"\">\n<li style=\"\">A proven track record leading successful applied data science projects</li>\n</ul>\n<p>Educational/Certification Requirements</p>\n<ul style=\"\">\n<li style=\"\">Master or PhD degree in a quantitative field like Computer Science, Applied Math, Physics, Data</li>\n</ul>\n<p>Science, Analytics, etc</p>\n</li>\n</ul>\n<p><strong>Additional Information</strong><br>This position requires the successful candidate to work in <strong>US, Brazil or India</strong>. <strong>Prior to commencing work,</strong><br><strong>applicants must have and provide Degreed with proof of authorization to work in US, Brazil or India.</strong><br>Degreed provides equal employment opportunities to all employees and applicants for employment and<br>prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex,<br>national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or<br>expression, or any other characteristic protected by federal, state or local laws. This policy applies to all<br>terms and conditions of employment, including recruiting, hiring, placement, promotion, termination,<br>layoff, recall, transfer, leaves of absence, compensation, and training.<br>We are committed to the full inclusion of all qualified individuals. As part of this commitment, Degreed will<br>provide reasonable accommodations to all qualified individuals with disabilities to participate in the job.</p>\n<div class=\"h3\"><strong>Total Rewards at Degreed</strong></div>\n<div>We believe your best work happens when you have a complete life balance, and Degreed gives you the support and flexibility to make that happen. Degreed is committed to delivering a comprehensive benefits program that provides the support you need. At the time of this posting, this role is eligible to participate in the following benefits:</div>\n<ul style=\"\">\n<li style=\"\">Comprehensive health insurance for you and your family (both PPO and HDHP plans available)</li>\n<li style=\"\">Dental and vision plans for you and your family</li>\n<li style=\"\">Employer-paid life insurance, AD&amp;D, short-term disability, and long-term disability</li>\n<li style=\"\">Company equity</li>\n<li style=\"\">401(k) Retirement Savings Plan with up to 4% match</li>\n<li style=\"\">Company funded HSA and dependent care FSA (pending eligibility)</li>\n<li style=\"\">Generous Parental Leave</li>\n<li style=\"\">Unlimited Paid Time Off and 5 sick days per year</li>\n<li style=\"\">Education benefit: Up to $1,200 per year for anything you want to learn (and we mean anything)!</li>\n<li style=\"\">One-time Home Office Stipend to make your workspace more comfortable</li>\n<li style=\"\">Monthly internet and phone stipend</li>\n<li style=\"\">Monthly wellness stipend through Forma</li>\n</ul>\n<div>*Degreed reserves the right to modify these benefits at any time, for any reason in accordance with applicable law. Please note the offerings vary based on location.</div>\n<div class='\"content-conclusion\"'>\n<div class=\"h3\"><strong>Work Environment &amp; Physical Demands</strong></div>\n<div>Degreed is a remote-first company, however our roles are open to in-office or flex work if you live in a city with a physical office location (when it is safe to return to the office). This role has the opportunity to operate 100% virtually from your home office. We primarily collaborate with our US and International colleagues through virtual meetings (Zoom), email, and Slack. In this role, you will be required to operate a laptop computer (PC or Mac available), computer software platforms, and other office productivity machinery as necessary.  Due to the nature of this role, you must be able to remain stationary for extended periods, and must be able to observe and interpret written and/or verbal communication. </div>\n<div class=\"h3\"><strong>Additional Information </strong></div>\n<div>Degreed provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. </div>\n<div> </div>\n<div>We are committed to the full inclusion of all qualified individuals. As part of this commitment, Degreed will provide reasonable accommodations to all qualified individuals with disabilities to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment. </div>\n<div> </div>\n<div>Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.</div>\n<div> </div>\n<div>Degreed uses the E-Verify employment verification program.  </div>\n</div>\n<img src=\"https://remotive.com/job/track/1546455/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547219,"url":"https://remotive.com/remote-jobs/data/data-analyst-1547219","title":"Data Analyst","company_name":"Avint","company_logo":"https://remotive.com/job/1547219/logo","category":"Data","tags":["analyst","azure","elasticsearch","excel","javascript","microsoft","mySQL","security","sql","management","operations","ai","design","programming","databases","agile","jira","documentation","analytics","data analysis","knowledge","data","Enterprise","business","conference","ETL","leadership","hiring","cybersecurity","database","development","reporting","IT","risk management","technical documentation","writing","kibana","applications","computer science","xml","communication","statistics","Secret clearance","support","agency","risk","programs","server"],"job_type":"full_time","publication_date":"2023-01-04T21:40:05","candidate_required_location":"USA","salary":"","description":"<p>Avint LLC is seeking a motivated, career, and customer-oriented Data Analyst to join our team in the Herndon, VA area to provide unparalleled support to multiple federal agencies through the Continuous Diagnostics &amp; Mitigation (CDM) Program. The CDM Program is a high-profile, high-visibility, cybersecurity modernization and risk management program where you can contribute innovative solutions and consult with multiple federal agencies to enhance their Information Assurance (IA) programs and continuous monitoring capabilities.</p> <p>This position also requires developing analysis and reporting of Data, including identifying data gaps. The successful candidate will bring a consultative approach to data analysis in solving our clients’ cyber security problems, coupled with demonstrated experience designing and developing enterprise data solutions for Federal government clients. This is not a database administrator role, but a hands-on Data Analyst position.</p><p><strong>Position Responsibilities:</strong><br></p><ul style=\"\"> <li style=\"\">Review, Identify, Analyze data from multiple source Cyber Security tools at multiple agencies. </li> <li style=\"\">Interpret data, analyze results using statistical techniques and provide ongoing reports based on the customer needs. </li> <li style=\"\">Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality</li> <li style=\"\">Acquire data from primary and other data sources and maintain databases/data systems</li> <li style=\"\">Run ad-hoc reports from source systems and work with Tool SMEs, integration developers in identifying data defects. </li> <li style=\"\">Identify, analyze, and interpret trends or patterns in complex data sets</li> <li style=\"\">Analyze source data and types, identify data requirements for destination systems. </li> <li style=\"\">Analyze, interpret, and report on data based on Data Dictionary &amp; Logical Data Models guidance. </li> <li style=\"\">Work with Agency and Agency representatives in resolving data quality, completeness, and accuracy issues. </li> <li style=\"\">Locate and define new process improvement opportunities</li> <li style=\"\">Ensure mapping of data elements provided by COTS products to the Logical Data Model</li> <li style=\"\">Other duties as assigned      </li> </ul><p><strong>Requirements</strong></p><p><em>Able to obtain and maintain a DHS Suitability/Entry on Duty (EOD) Active Secret or Top-Secret clearance desired.</em></p><p><strong>Technical Areas of Expertise</strong></p><ul style=\"\"> <li style=\"\">Excellent communication and relationship skills to articulate given analysis and build consensus among clients and technical stakeholders</li> <li style=\"\">Demonstrated ability to present to senior leadership and client audiences</li> <li style=\"\">Strong interpersonal and collaborations skills working in a team-oriented environment</li> <li style=\"\">Ability to effectively prioritize and handle multiple agencies simultaneously</li> <li style=\"\">Microsoft Applications (Word, PowerPoint, Excel)</li> <li style=\"\">Experience with JIRA and Agile development practices</li> <li style=\"\">Certification: Security+CE plus</li> </ul><p><strong>Qualifications</strong></p><ul style=\"\"> <li style=\"\">Proven working experience with large Data set from multiple systems including machine data, cyber security tool data and other relevant data that is used within an enterprise for security posture.</li> <li style=\"\">Proficient at querying data in MS/Azure SQL server and Elasticsearch/Kibana for data issues, gaps, and trend</li> <li style=\"\">Writing reports and presenting findings</li> <li style=\"\">Technical expertise regarding data models, database design development, data mining and segmentation techniques</li> <li style=\"\">Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL, MySql etc.), programming (XML, Javascript, or ETL frameworks)</li> <li style=\"\">Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)</li> <li style=\"\">Experience in translating derived requirements by analyzing Logical Data Models and Data Dictionary to provide data mapping from source systems. </li> <li style=\"\">Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy</li> <li style=\"\">Experience with collaborating with other roles, such as solution architects, data engineers, data scientists, AI engineers, database administrators, and developers.</li> </ul> <ul style=\"\"> <li style=\"\">Minimum of 5 years of experience in Data      Analytic work for mission critical systems within Fed/CIV, DOD, or Intel</li> <li style=\"\">Minimum of 5 years of experience performing or assisting in the analysis      of enterprise IT logs, data, and/or information preferably in Security      Operations</li> <li style=\"\">Experience collaborating with Federal clients to mature operational      processes, reduce redundancies, and develop innovative solutions</li> <li style=\"\">Experience understanding organizational needs, proposing solutions,      and managing project execution efforts designed to deliver overall program      benefits for Government Agencies</li> <li style=\"\">Experience collaborating with US Government Agencies, state or      local governments, or commercial entities to develop IT service program      maturity in accordance with Federal IT mandates and best practices</li> <li style=\"\">Experience in conducting assessments of an Enterprise by reviewing      technical documentation, conducting interviews and workshops to identify      gaps and develop a tailored solution is highly desired</li> <li style=\"\">Demonstrated experience in security solution design using existing      as well as emerging technologies to deliver enterprise solutions</li> <li style=\"\">BS in Mathematics, Economics, Computer Science, Information      Management or Statistics</li> </ul><p><strong>Physical Requirements</strong></p><p></p><ul style=\"\"><li style=\"\">Office work, typically sedentary with some movement around the office</li></ul><p></p><p><strong>Benefits</strong></p><p>Joining Avint is a win-win proposition! You will feel the personal touch of a small business and receive BIG business benefits. From competitive salaries, full health, and generous PTO and Federal Holidays. Additionally, we encourage every Avint employee to further their professional development. To assist you in achieving your goals, we offer reimbursement for courses, exams, and tuition. Interested in a class, conference, program, or degree? Avint will invest in YOU and your professional development!</p><p><em>Avint is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity and Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.</em></p><img src=\"https://remotive.com/job/track/1547219/blank.gif?source=public_api\" alt=\"\"/>"}]}