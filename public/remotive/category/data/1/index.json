{"job_count":100,"total_pages":10,"jobs_per_page":10,"next":"https://eriandev.github.io/api/remotive/2","results":[{"id":1543112,"url":"https://remotive.com/remote-jobs/data/data-engineer-1543112","title":"Data Engineer","company_name":"Bankuish","company_logo":"https://remotive.com/job/1543112/logo","category":"Data","tags":["python","security","sql","design","programming","analytics","knowledge","data","business","infrastructure","ETL","warehouse","people","SOLID","startup","streaming","financial services","data-driven","support","information technology","architecture "],"job_type":"full_time","publication_date":"2023-01-11T11:39:44","candidate_required_location":"Brazil","salary":"","description":"<div class=\"h2\">About us</div>\n<p>Bankuish is a startup that helps millions of entrepreneurs and freelancers in Latin America access financial services. Our app connects gig workers with personalized loans and offers from the largest banks and institutions in the region. Together, we are helping banks better serve this niche and simultaneously helping gig workers improve their financial security.</p>\n<div class=\"h2\">The role</div>\n<p>The ideal candidate for this role has a solid foundation in creating data pipelines, ETL and analytical data warehouse. She/He will be responsible for our data and data pipeline architecture, as well as optimizing data systems and building them from the ground up.</p>\n<p>This role will support Data Scientists and Data Analysts by providing infrastructure and tools that can be used to deliver end-to-end solutions to business problems.</p>\n<div class=\"h2\">What you will do</div>\n<ul style=\"\">\n<li style=\"\">Build and automate data systems, processes, and models to help us scale our ability to evaluate gig workers, and to make financial services more accessible to millions of individuals around the world.</li>\n<li style=\"\">Evaluate, design, and implement analytics tools to facilitate data-driven decisions across the company.</li>\n<li style=\"\">Contribute to designing and building our data infrastructure. Influence the technical architecture, and help make decisions that shape the foundation of our data products.</li>\n<li style=\"\">Build reliable data services and robust ingestion pipelines for both structured and unstructured data sources.</li>\n<li style=\"\">Design and ship ETL/ELT pipelines that transform, aggregate, normalize, and master messy data.</li>\n<li style=\"\">Develop and automate large scale, high-performance data processing systems (batch and/or streaming).</li>\n<li style=\"\">Define data models for optimal storage</li>\n</ul>\n<div class=\"h2\">Responsibilities</div>\n<ul style=\"\">\n<li style=\"\">Build and optimize ETL.</li>\n<li style=\"\">Build dashboards.</li>\n<li style=\"\">Develop solutions to process a large volume of data.</li>\n<li style=\"\">Ensure data preparation, flow, and integrity.</li>\n<li style=\"\">Create data models and business indicators.</li>\n</ul>\n<div class=\"h2\">Desired Skills</div>\n<ul style=\"\">\n<li style=\"\">Knowledge in SQL.</li>\n<li style=\"\">Experience with streaming and batch pipelines.</li>\n<li style=\"\">Experience with python programming language.</li>\n<li style=\"\">Experience with ETL.</li>\n<li style=\"\">Knowledge in DW, dimensional modeling and data integration.</li>\n<li style=\"\">Degree in Information Technology desired</li>\n</ul>\n<div class=\"h2\">What Makes a Great Fit?</div>\n<p>We believe that people do their best work when they are aligned with the mission and company goals. We're looking for an experienced professional who is self-motivated, dynamic, and great working closely with small teams. The ideal candidate believes in doing hard things by doing them together. We're looking for someone who is excited to apply their personal superpowers to serve millions of gig workers – someone who is passionate about addressing issues of financial inclusion and democratizing access to financial services.</p>\n<div class=\"h2\">How we Work</div>\n<p>At Bankuish we are fully remote and widely dispersed, working from our own homes and neighborhoods across the world. We still prefer to collaborate and communicate in real-time.</p>\n<img src=\"https://remotive.com/job/track/1543112/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1544830,"url":"https://remotive.com/remote-jobs/data/edi-data-analyst-1544830","title":"EDI Data Analyst","company_name":"Reveleer","company_logo":"https://remotive.com/job/1544830/logo","category":"Data","tags":["analyst","sql","operations","healthcare","data analysis","data","troubleshooting","software development","business","inbound","development","communication","support","risk","CMS","software","outbound"],"job_type":"full_time","publication_date":"2023-01-10T23:40:23","candidate_required_location":"USA","salary":"","description":"<p><strong>EDI Data Analyst</strong></p>\n<p>Dynamic Healthcare Systems, a wholly owned subsidiary of Reveleer, is looking for an individual with Medicare EDI experience to join our team.  The EDI Data Analyst will support new and current EDI risk adjustment customers.  The Data Analyst will work directly with clients to assure timely, accurate, consistent, and complete submissions of encounter data.  Additionally, you will assist clients in mapping encounter data files to Dynamic standard formats, track inbound/outbound files sent by clients and processed in our proprietary software (Voyager), review errors received and document the errors with business friendly explanations, and assure optimal data integrity.  You will identify data issues or discrepancies between CMS rules and Voyager rules and report to the appropriate parties.  In this role, you will thoroughly analyze issues, identify the root cause, and work with the Integration team and Software Development team to correct the problems.  Every person at Dynamic has a hand in exceeding our clients' expectations, and you will play a key role in assuring our clients are fully utilizing the EDI risk adjustment module, and enjoying the full value of the solution.  Your daily work is likely to consist of:</p>\n<ul style=\"\"><li style=\"\">Performing audits on data imported and data exported</li><li style=\"\">Performing reconciliation on submitted records vs. received responses</li><li style=\"\">Providing analysis for root cause and correction actions for risk adjustment customers' Voyager errors</li><li style=\"\">Tracking and following up on risk adjustment files received, processed and submitted</li><li style=\"\">Documenting all mapping changes or issues</li><li style=\"\">Documenting weekly statuses, meeting minutes and clients' concerns</li><li style=\"\">Keeping up to date on CMS changes and assisting with development of new business requirements and functional specifications as they relate to risk adjustment </li></ul>\n<p> <strong>The Ideal Candidate will bring:</strong></p>\n<ul style=\"\"><li style=\"\">Medicare Advantage experience at the plan level in a systems operations capacity, interfacing with both the plan and CMS</li><li style=\"\">Three or more years of experience in Medicare risk adjustment and ANSI X12, working with Palmetto, CSSC, and CMS</li><li style=\"\">Experience processing 5010 and 837 files</li><li style=\"\">Advanced Data analysis in SQL</li><li style=\"\">Interfacing with clients to gather requirements and review operational statuses</li><li style=\"\">Excellent application troubleshooting based on data analysis</li><li style=\"\">Strong communication skills, both verbal and written</li><li style=\"\">Bachelor's degree or equivalent experience is required </li></ul>\n<img src=\"https://remotive.com/job/track/1544830/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1542975,"url":"https://remotive.com/remote-jobs/data/data-scientist-1542975","title":"Data Scientist","company_name":"Super Dispatch","company_logo":"https://remotive.com/job/1542975/logo","category":"Data","tags":["AWS","data science","machine learning","python","saas","sql","growth","operations","strategy","Engineering","product","TensorFlow","data","business","GCP","leadership","IT","marketplace","learning","organization","applications","support","Pytorch","insurance","software"],"job_type":"full_time","publication_date":"2023-01-10T09:40:22","candidate_required_location":"USA","salary":"","description":"<p>Super Dispatch is looking for an experienced Data Scientist<strong> </strong>to support the Product, Engineering, and Marketplace Operations teams by building reliable prediction solutions that can help Super Dispatch customers move cars faster. You will analyze and understand customer data, collaborate with other teams and departments, and improve existing recommendation and prediction engines. This is an exciting opportunity for an experienced data scientist to work on innovative solutions for our SaaS enabled marketplace.</p>\n<p><strong>What We Do:</strong></p>\n<p>Super Dispatch is one of the fastest growing tech startups in Kansas City, and we're transforming the world of vehicle shipping. The Super Dispatch platform is a one-stop-shop for everything Carriers and Shippers need to move cars faster, smarter, and easier. Backed by cutting edge technology and best-in-class software, Super Dispatch is the advanced auto transport experience taking carriers and shippers into the future.</p>\n<p><strong>Who We Are:</strong></p>\n<p>Our diverse team is comprised of highly motivated professionals with a passion for solving big problems with technology. Our core values are built around learning, growing, evolving, and continuous experimentation. We believe and practice taking bold risks. We embrace failure as a lesson. We put our team first. We are committed to supporting each other and helping each other grow on this journey.<br></p>\n<p><strong>Responsibilities:</strong></p>\n<ul style=\"\">\n<li style=\"\">Build and evolve transformative, real-time marketplace pricing engines based on machine learning and reflective of dynamic market conditions</li>\n<li style=\"\">Improve existing recommendation or prediction engines by collaborating with key stakeholders (internal and external)</li>\n<li style=\"\">Develop a deep understanding of the overall business of Super Dispatch and the Auto Transport industry</li>\n<li style=\"\">Improve machine learning models to deliver reliable and scalable solutions</li>\n<li style=\"\">Collaborate with other departments and teams to improve data collection, process and error handling, and data normalization</li>\n<li style=\"\">Provide thought leadership on data science to Product and Engineering Teams with best practices</li>\n<li style=\"\">Collaborate with Marketplace Operations and Data Teams to identify and resolve issues using data science and machine learning methodologies</li></ul>\n<ul style=\"\">\n</ul>\n<p><strong>Candidate Profile:</strong></p>\n<ul style=\"\">\n<li style=\"\">Curious  - you ask questions and are eager to learn.</li>\n<li style=\"\">Analytical mindset -  you are able to structure and process data and draw insightful conclusions from it.</li>\n<li style=\"\">Systematic thinker - you can balance big picture strategy with details, you have strong execution and delivery.</li>\n<li style=\"\">Problem solver - you have solved complex problems and have the aptitude to navigate uncharted waters.</li>\n<li style=\"\">Team player - you have a collaborative mindset, the ability to work with cross-functional teams, and build positive relationships with individuals across the organization.</li>\n<li style=\"\">Growth driven - you are willing to learn new tools and technologies to work effectively in a rapid growth environment with changing needs and requirements.</li>\n<li style=\"\">Self motivated - you work independently and take initiative.</li>\n</ul>\n<p><strong>Candidate Experience:</strong></p>\n<ul style=\"\">\n<li style=\"\">2+ years experience in a data scientist role, preferably working on a recommender system</li>\n<li style=\"\">2+ years of professional experience synthesizing insights from data using Python and SQL</li>\n<li style=\"\">2+ years experience with Machine Learning Frameworks (Tensorflow and/or PyTorch) and their real world applications</li>\n<li style=\"\">Experience working with AWS or GCP preferred</li></ul>\n<ul style=\"\">\n</ul>\n<p><strong>Summary of Benefits:</strong></p>\n<ul style=\"\">\n<li style=\"\">Stock options</li>\n<li style=\"\">Unlimited Vacation (PTO)</li>\n<li style=\"\">401k with company match</li>\n<li style=\"\">Health, dental, vision, and life insurance</li>\n<li style=\"\">12 weeks of paid parental leave</li>\n<li style=\"\">Fully remote/work from home role</li>\n<li style=\"\">Growth opportunities</li>\n<li style=\"\">Gym membership/wellness stipend</li>\n<li style=\"\">Equipment provided</li>\n</ul>\n<p>The salary range for this position is $100k - $120k annually.</p>\n<img src=\"https://remotive.com/job/track/1542975/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1545056,"url":"https://remotive.com/remote-jobs/data/data-engineer-1545056","title":"Data Engineer","company_name":"Viable Data Ltd","company_logo":"https://remotive.com/job/1545056/logo","category":"Data","tags":["consulting","looker","python","security","sql","ux","growth","management","design","agile","windows","analytics","data analysis","mentoring","NoSQL","data","Enterprise","tableau","business","ETL","warehousing","people","SDLC","culture","data warehousing","R","streaming","learning","data management","communication","statistics","time management","diversity","travel","digital products","training"],"job_type":"full_time","publication_date":"2023-01-10T07:39:45","candidate_required_location":"UK","salary":"","description":"<p><strong>About us</strong></p>\n<p>Viable Data is an innovative technology, data and UX consultancy, delivering excellence through our projects and providing our people with a supportive culture and opportunities for growth and continuous learning.</p>\n<p>We thrive on the challenge of working across different projects, user needs and technologies and our teams and people live this every day. Our people-first approach and culture is central to our growing success as a consultancy.</p>\n<p>We are an all-inclusive equal opportunities employer and proudly celebrate diversity. If you thrive on challenge, have a passion to learn and make a difference, and enjoy being part of a growing multidisciplinary team, look no further and start your Viable career, now.</p>\n<p><strong>About the role</strong></p>\n<p>As a Data Engineer at Viable Data, you will be at the forefront to ensure that data is in the right state and format, ready to implement data schemas and models, making sure that the data is ready and available for data mining purposes.</p>\n<p>You will be someone who can adapt quickly and easily to the flexible needs of our Central Government customers. You will join one of our high-performing consulting teams where you will play a pivotal role in designing &amp; delivering exceptional digital products and services that directly contribute to the delivery of UK policy, economic growth and security.</p>\n<p><strong>This role is largely remote with occasional business essential travel.</strong></p>\n<p><strong>Requirements</strong></p>\n<p><strong>Key responsibilities</strong></p>\n<ul style=\"\">\n<li style=\"\">Experience of pragmatic, hands-on analysis of enterprise-scale data projects across the full SDLC from design to migration, integration and live service in an Agile environment • Experience of analysis and design of solutions using one or more from: SQL and noSQL technologies, data streaming, logging and monitoring tools, BI and Data Warehousing solutions and ETL and migration technologies</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">A thorough understanding of one or more from: Master Data Management, Data Lineage analysis, Metadata Management, Data Quality assessment and management, Data Transformation and migration</li>\n<li style=\"\">Ability to apply advanced analytics and statistics techniques to business problems</li>\n<li style=\"\">Proven experience of working with large volumes of data, applying tools such as SAS, R, Python, SQL, PowerBI, Tableau, Looker</li>\n<li style=\"\">Excellent communication skills and ability to tell stories / influence with data</li>\n</ul>\n<p><strong>Skills and experience needed</strong></p>\n<ul style=\"\">\n<li style=\"\">Proven relevant industry experience.</li>\n<li style=\"\">Excellent written and verbal communication abilities - presenting findings and related design/business recommendations and insights clearly that stakeholders can understand and use. Able to communicate with stakeholders at all levels.</li>\n<li style=\"\">Proven analysis skills - experience of various data analysis methods at enterprise scale</li>\n<li style=\"\">People skills – empathetic, great listener and have a natural curiosity to understand people, their motivations and thought processes.</li>\n</ul>\n<ul style=\"\">\n<li style=\"\">Experience and understanding of a range of User Centred Design practices</li>\n<li style=\"\">Organisation, time management and collaboration skills</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p><strong>Why work with us?</strong></p>\n<p>As well as providing a great place to work that has an amazing culture and the opportunity to work on excellent projects where you will really make a difference, we have a whole host of additional employee benefits.</p>\n<p>Our benefits package includes:</p>\n<ul style=\"\">\n<li style=\"\">25 days leave</li>\n<li style=\"\">5 days dedicated training allowance, with individual budget</li>\n<li style=\"\">Mentoring system, with 6-month review cycles</li>\n<li style=\"\">Flexible hours and supportive of remote working</li>\n<li style=\"\">5% pension company contributions</li>\n<li style=\"\">Annual bonus based on company performance</li>\n<li style=\"\">Choice of company laptop (Macbook, Windows) </li>\n</ul>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1545056/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546497,"url":"https://remotive.com/remote-jobs/data/data-collection-management-1546497","title":"Data collection/Management","company_name":"Jumanji Studio","company_logo":"https://remotive.com/job/1546497/logo","category":"Data","tags":["big data","finance","management","design","strategy","mentoring","data","people","startup","IT","themes","support","architecture "],"job_type":"internship","publication_date":"2023-01-09T21:39:54","candidate_required_location":"Europe","salary":"","description":"<p><a class=\"external\" href=\"https://www.jumanji.studio/\" rel=\"nofollow\">Jumanji Studio</a>, one of the first startup studios focusing solely on positive impact, is looking for <strong>t</strong><strong>alented fellows</strong> to support its partners in developing the studio and its startups.</p>\n<p><strong>The company </strong></p>\n<p>Jumanji Studio is a startup studio founded by experienced entrepreneurs and investors in the impact space with the goal to bring the best of entrepreneurship against environmental issues.</p>\n<p>We believe that the ecological transition needs to happen with new players and solutions.</p>\n<p>We empower driven entrepreneurs in a synergic way to build and grow businesses with strong impact potential in the fields of circular economy and impact ecosystems.</p>\n<p>As a startup studio we design solutions from scratch, finance and grow them into independent startups with their own team that we carefully build with extraordinary entrepreneurs.</p>\n<p>Since 2019, we’ve launched 7 startups, brought in 10 entrepreneurs and 70 experts, sold our 1st startup, and raised a cumulative EUR 4m across our studio startups.</p>\n<p><strong>The Jumanji Fellowship</strong> is an opportunity we have specifically designed for driven, eco-conscious individuals starting out their career, starting afresh in this field, or who want to contribute but do not know in what way.</p>\n<p><strong>What we have to offer in a 2-3 month (or less) relationship</strong></p>\n<p>An extremely rich and dynamic environment with an opportunity to witness how a startup is launched. The chance to weigh on the strategy of the studio or one of our startups. The time to deep dive into one or two sustainability-related issues and themes.</p>\n<p><strong>What we will expect from you</strong></p>\n<p>A two-three months mission is rich if it is focused. We will agree with you on one or two missions based on your experience, your interest, and our needs prior to the time you start the program. If you only have some hours a week available that's fine.</p>\n<p>We have 2 new startup projects:</p>\n<p>Gaia connect : Mentoring \"impact digital platform\"</p>\n<p>Nozama : Decarbonize the goods delivery market</p>\n<p><strong>So we have new missions for Fellows</strong></p>\n<ul style=\"\">\n<li style=\"\">Gaia Connect -&gt; Can you suggest us a data/tech architecture for:</li>\n</ul>\n<p>1) Token Economy - how to create/set it up <br>2) Matching people (via algorithm and big data)</p>\n<ul style=\"\">\n<li style=\"\">Nozama :</li>\n</ul>\n<p>1) Carbon footprint : Can you suggest data and algorithm</p>\n<p>2) How data makes home appliances more circular ?</p>\n<p><strong>Requirements</strong></p>\n<p><strong>Jumanji is looking for two things in the people we work with </strong></p>\n<p>You need to come with sheer optimism, a positive energy, a persevering courage, and an open mindset.</p>\n<p>We want to work with people who have a real ambition for the planet. If you see yourself as dedicating all your skills for a positive change, then we’ll show you it’s possible.</p>\n<p><strong>What we’ll expect from you</strong></p>\n<p>A two/three-month mission is rich if it’s focused. We’ll agree with you on 1 or 2 missions that make sense based on your experience, your interest, and our needs closer to the time you start. You’ll be your own boss from there.</p>\n<p><strong>Benefits</strong></p>\n<p>You work when you want:</p>\n<p>- Full-time = for 2 months or more</p>\n<p>- Part-time = if you want to work some hours per week, that's possible</p>\n<p>Location = Flexible, part of our team is fully remote in Europe. We don’t care, you work from anywhere.</p>\n<p>Unpaid internship</p>\n<p>Free access to The Spaceship Academy : <a class=\"external\" href=\"https://www.thespaceship.org/\" rel=\"nofollow\">https://www.thespaceship.org/</a></p>\n<p>Coworking space available in Paris or Biarritz</p>\n<img src=\"https://remotive.com/job/track/1546497/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546120,"url":"https://remotive.com/remote-jobs/data/head-of-data-operations-1546120","title":"Head of Data Operations","company_name":"Viridios","company_logo":"https://remotive.com/job/1546120/logo","category":"Data","tags":["data science","excel","finance","python","sql","management","operations","ai","project management","Engineering","product","NoSQL","data","recruiting","creative","English","business","warehouse","leadership","metrics","events","development","domain","reporting","IT","problem-solving","themes","computer science","communication","support","equities","risk","software"],"job_type":"full_time","publication_date":"2023-01-08T19:39:54","candidate_required_location":"UK","salary":"","description":"<p><strong>Head of Data Operations</strong></p>\n<p>Viridios AI is at the forefront of solutions for the climate and sustainability markets. We have developed AI-based fair valuation and risk management models that solves a major problem in value transparency and is quickly becoming the market reference for fair prices of carbon credits (offsets), from forestry and agriculture to renewable energy and energy efficiency activities worldwide. Our company and product have recently been recognized as <a href=\"https://www.environmental-finance.com/content/awards/voluntary-carbon-market-rankings-2022/\" rel=\"nofollow\">Best Market Innovation</a> by Environmental Finance, one of the major publications in the fast growing carbon markets space.</p>\n<p>There is much to do when it comes to applying technology in doing right by the planet and its inhabitants, and we are always looking for highly talented individuals to join us in this journey.</p>\n<p>We are now recruiting for a Head of Data Operations to join a highly qualified team with domain expertise and years of experience in markets and technology. The typical candidate works with a major market data provider, a bank or an asset manager dealing with market data in various asset classes (equities, fixed income, commodities, etc) as well as various other datasets such as reference data, etc. This is your opportunity to grow into and contribute to some of the most prominent and important themes of our age: climate, sustainability and technology.</p>\n<ul style=\"\">\n<li style=\"\">This is a permanent position</li>\n<li style=\"\">You will report to the CEO</li>\n<li style=\"\">Candidates based in the UK or Continental Europe</li>\n<li style=\"\">You will be working remote</li>\n</ul>\n<p><strong>What We Offer</strong></p>\n<ul style=\"\">\n<li style=\"\">Competitive base compensation</li>\n<li style=\"\">Annual cash bonus</li>\n<li style=\"\">Employee stock allocated upfront with tremendous upside</li>\n<li style=\"\">A vibrant and creative work environment</li>\n<li style=\"\">Exposure to one of the most exciting sectors today</li>\n</ul>\n<p><strong>Responsibilities</strong></p>\n<ul style=\"\">\n<li style=\"\">Lead the data operations team (5 currently, 8 budgeted) comprising of market data and carbon project data operations</li>\n<li style=\"\">Maintain and build all data sourcing, validation and publication processes</li>\n<li style=\"\">Ensure that all data operations delivery processes are fully operational and reliable</li>\n<li style=\"\">Expand data sourcing operations in the carbon markets through the establishment of new commercial relationships with partners</li>\n<li style=\"\">Represent the company at events and conferences</li>\n<li style=\"\">Contribute to the company's credibility through thought leadership on carbon markets data</li>\n<li style=\"\">Contribute to regular publication of newsletters on carbon markets</li>\n<li style=\"\">Perform daily market data and weekly carbon project data publication sign off</li>\n<li style=\"\">Work closely with market data team on daily data preparation, validation and calibration for Golden Source data warehouse</li>\n<li style=\"\">Work closely with carbon project data team on weekly data preparation, validation and calibration for Golden Source data warehouse</li>\n<li style=\"\">Monitor and maintain the integrity and validity of the data being sourced, processed and published</li>\n<li style=\"\">Work alongside the data science team on datasets preparation to be used in model development</li>\n<li style=\"\">Work closely with market data team on maintaining and calibrating model data inputs and parameters</li>\n<li style=\"\">Lead the designing, building and maintenance of reports and data dashboards used to derive insights from data</li>\n<li style=\"\">Validate and support data models, data-mining methodologies, and reporting of metrics to stakeholders</li>\n</ul>\n<p><strong>Required</strong></p>\n<ul style=\"\">\n<li style=\"\">Bachelor's degree in business, finance or in a technical area (e.g., computer science, engineering, physics, mathematics, etc)</li>\n<li style=\"\">Deep understanding and hands-on experience with data operations in financial markets (market data, reference data, etc)</li>\n<li style=\"\">Experience working with data products and financial data platforms (Bloomberg, ICE, etc)</li>\n<li style=\"\">Professional experience in financial markets with banks, asset managers, market data providers and platforms, etc</li>\n<li style=\"\">Excellent attention to detail and organizational skills</li>\n<li style=\"\">Strong time and project management skills</li>\n<li style=\"\">Fast learner, capable of quickly gaining domain expertise in the highly complex climate and sustainability markets</li>\n<li style=\"\">Clear analytical and problem-solving skills with the ability to envision and propose new and creative ways to solutions</li>\n<li style=\"\">Passion for technology and data, and issues related to climate and sustainability markets</li>\n<li style=\"\">Ability to work well with teams in a collaborative way</li>\n<li style=\"\">Exceptional business and technical communication in English, verbal and written</li>\n<li style=\"\">Proficiency in Excel and other data business tools</li>\n</ul>\n<p><strong>Desired</strong></p>\n<ul style=\"\">\n<li style=\"\">Ability to run Python code (not necessarily build Python software)</li>\n<li style=\"\">Ability to run in SQL and NoSQL (Mongo) queries</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1546120/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546353,"url":"https://remotive.com/remote-jobs/data/senior-data-engineer-1546353","title":"Senior Data Engineer","company_name":"yoldacom","company_logo":"https://remotive.com/job/1546353/logo","category":"Data","tags":["apache","api","AWS","backend","cloud","data science","docker","git","java","kubernetes","python","scala","sql","management","operations","design","programming","B2B","research","Engineering","product","languages","NoSQL","data","JS","spark","English","software development","business","infrastructure","node","ETL","google cloud","data engineering","culture","SOLID","events","data pipelines","database","development","IT","streaming","math","serverless","applications","Apache Spark","communication","support","architecture ","insurance","programs","webinars","software","BigQuery","training"],"job_type":"full_time","publication_date":"2023-01-08T03:39:15","candidate_required_location":"Turkey","salary":"","description":"<p>As a “Digital Freight Forwarder”, Yolda.com aims to improve and optimize logistics operations, increase transparency during the logistics process and lead digitalization efforts in the sector with the technologies and solutions developed in-house. Our mission is to become the leading B2B freight forwarding company in the region with smart management of our large carrier network of logistics companies and freelance truck drivers.</p>\n<p>Yolda.com, founded in March 2020, has raised 8m USD funding in total so far from reputable local and international investors such as Speedinvest and Collective Spark as well as from global prominent angel investors. Yolda.com is currently looking for motivated talents who are passionate to disrupt the logistics sector which has been delivered in the same conventional way for centuries.</p>\n<p>As a Senior Data Engineer, you will be developing data-intensive pipelines and applications and you will design all development cycles of services for data products.</p>\n<p><strong><u>Responsibilities</u></strong></p>\n<ul style=\"\">\n<li style=\"\">Understanding logistics business and the data at massive scale behind it.</li>\n<li style=\"\">You will help to build a data platform to enable other teams to self service high quality data while performing data operations to support their day-to-day actions.</li>\n<li style=\"\">You'll support designing and creating all aspects of our ever-growing set of external and internal data pipelines, understand the problems, and tie them back to data engineering solutions</li>\n<li style=\"\">You will not only develop a pipeline but also you develop end to end services (like api,backend) as a data product</li>\n<li style=\"\">You will support to develop secure, reliable, scalable, sustainable ML/DL based data products and build infrastructure and development services for Dataops and MLops processes</li>\n<li style=\"\">Work closely with Platform, Data Science and Backend teams, as well as product and tech teams.</li>\n</ul>\n<p><strong><u> </u></strong></p>\n<p><strong><u>Qualifications</u></strong></p>\n<ul style=\"\">\n<li style=\"\">At least 3 years of professional experience as a Software/Data Engineer, and hold a degree in a quantitative field (CS, Engineer, Math, Physics, … ),</li>\n<li style=\"\">Hands-on experience with data technologies on cloud providers AWS or other cloud providers like Google Cloud etc.</li>\n<li style=\"\">Good communication in English,</li>\n<li style=\"\">Strong object-oriented design and software development skills like( clean code, solid, design patterns, etc),</li>\n<li style=\"\">Experience with Python is a must, also other programming languages like java, node js, and scala are also considerable,</li>\n<li style=\"\">Experience with ETL/ELT, batch, and streaming data processing pipelines,</li>\n<li style=\"\">Strong SQL experience and tuning/optimize query to optimize data load, materialization, and transformation times,</li>\n<li style=\"\">Experience with containerization technologies like Docker. Understanding orchestration tools for container like Kubernetes is a plus,</li>\n<li style=\"\">Experience SQL and NoSQL database/datastore technologies and know the differences and architectures behind them,</li>\n<li style=\"\">Experience and understanding of distributed data warehouses like Redshift and Google Bigquery,</li>\n<li style=\"\">Experience and understanding of distributed data processing frameworks like Apache spark, Apache Flink</li>\n<li style=\"\">Experience and understanding of data workflow orchestration frameworks like Apache airflow, dagster, prefect etc.</li>\n<li style=\"\">Experience and understanding of data file/storage format like parquet, avro etc.</li>\n<li style=\"\">Experience and ability to design data model on OLAP systems and real-time analytic system,</li>\n<li style=\"\">Experience code version systems like Git,</li>\n<li style=\"\">Open to new technologies and do POC. Willingness to do research and able to gather information to find out and apply best practices</li>\n</ul>\n<p> </p>\n<p><strong><u>Why You'll Love Working at Yolda.com</u></strong></p>\n<p>Join our team, join our dream: logistics and technology!</p>\n<p>Yolda.com is growing fast and allows our team members to share their unique perspectives, solve new challenges, and own their careers.</p>\n<p>Our company culture and work environment continue to flourish digitally with business updates, well-being programs, hackathons, virtual coffee catch-ups, webinars, and more.</p>\n<ul style=\"\">\n<li style=\"\">Working with modern tech stack and serverless cloud architecture</li>\n<li style=\"\">Chance to take responsibility from the first day, grow your skills and learn continuously</li>\n<li style=\"\">Competitive private health insurance coverage</li>\n<li style=\"\">Training and development opportunities</li>\n<li style=\"\">Work from home, office, or hybrid model</li>\n<li style=\"\">Best equipment for tech geniuses: MacBook, monitor and more</li>\n<li style=\"\">Team Events &amp; happy hours</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1546353/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547306,"url":"https://remotive.com/remote-jobs/data/01-gett-data-engineer-1547306","title":"01 Gett: Data Engineer","company_name":"Adaptiq","company_logo":"https://remotive.com/job/1547306/logo","category":"Data","tags":["AWS","big data","business intelligence","devops","docker","excel","golang","kubernetes","mobile","python","management","automation","b2c","Engineering","mobility","product","CI/CD","analytics","knowledge","data","spark","software development","business","infrastructure","terraform","ETL","warehouse","warehousing","data engineering","data pipelines","data warehousing","development","reporting","IT","marketplace","organization","applications","data-driven","microservices","support","production","server","software"],"job_type":"full_time","publication_date":"2023-01-07T01:39:57","candidate_required_location":"Poland","salary":"","description":"<p>Gett was established 12 years ago, as a ride-hailing solution, and since then has expanded its activity globally, across Europe and the United States.<br>Nowadays, Gett is a Ground Transportation Solution with the mission to organize all the best mobility providers in one global platform - optimizing the entire experience from booking and riding to invoicing and analytics, to save businesses time and money. We work with a third of the Fortune 500 companies and have over 17K active business customers across the world. </p>\n<p>The GTM - the Ground transportation management,  is a worldwide 1.4 trillion market involving Drivers, Riders, Suppliers, and Businesses, and a secured product platform and the marketplace are crucial for successful operation.</p>\n<p>Gett RnD is a top-notch engineering organization that develops a microservices-based system, high-scale ready, fulfilling strict availability and reliability requirements (as a B2C and a B2B2C platform) and managing significant traffic load.<br>Our system is developed mostly using Golang, runs in AWS, and involves ML at the applicable areas, to provide the best transportation solution for our customers, and maximizes Gett's performance.</p>\n<p><strong>Background: </strong></p>\n<p>Gett is a Ground Transportation Solution with the mission to organize all the best mobility providers in one global platform - optimizing the entire experience from booking and riding to invoicing and analytics, to save businesses time and money. We work with a third of the Fortune 500 companies and have over 17K active business customers across the world. </p>\n<p>We are looking for an<strong> Automation Engineer</strong> who will excel in our RnD team.</p>\n<p>We work in a fast-paced environment. Our systems are composed of 2 mobile applications and 180+ microservices that are deployed to production dozens of times a day, live in production with a high standard of system availability 99.99%. Therefore we need to keep very high automation coverage in our systems.</p>\n<p><strong>Gett </strong>is the place where you come to when you need to be on the move with confidence, regardless if you are a member of the general public, a business customer, a driver or a partner. We provide the best possible service our customers can get, where it matters the most. And you can make our team stronger than ever!</p>\n<p>Gett's Data team is looking for a talented Data Engineer to join us.</p>\n<p>The Data Engineer will be a key member of the data team, at the core of a data-driven company, developing scalable, robust data pipelines, data models, and to provide business intelligence.</p>\n<p>Come and work in an evolving, challenging environment with a variety of data sources, technologies, and stakeholders, to deliver the best solutions to support the business and provide operational excellence.</p>\n<p><strong>Responsibilities:</strong></p>\n<ul style=\"\">\n<li style=\"\">Building the next generation of the Data Warehouse, moving from old and legacy models into more robust.</li>\n<li style=\"\">Building new ETL pipelines and bugfix old one.</li>\n<li style=\"\"> Improve data quality and ingestion; identify root cause of data issues and provide resolution ensuring accuracy and trust in everything we build.</li>\n<li style=\"\">Ensure that the local data needs are taken into account by the global BI team.</li>\n<li style=\"\">Debug reports or automatic Python scripts and ensure the reporting server infrastructure is connecting correctly to our main data sources.</li>\n<li style=\"\">Contribute to pieces of analysis to inform business decisions.</li>\n</ul>\n<p><strong>Requirements:</strong></p>\n<ul style=\"\">\n<li style=\"\">Minimum 2 years of experience in software development/data engineering/business intelligence - <strong>A must</strong>.</li>\n<li style=\"\">Strong experience in data modeling, ETL development, and data warehousing - <strong>A must</strong>.</li>\n<li style=\"\">Experience with Python - <strong>A must</strong>.</li>\n<li style=\"\">Big data technologies (Spark , Hive, Spark, Presto, Airflow) - <strong>An advantage</strong>.</li>\n<li style=\"\">Experience working with AWS big data technologies (S3, EC2, EKS) - <strong>An advantage</strong>.</li>\n<li style=\"\">Knowledge in containerized environments (Docker, Kubernetes) - <strong>An advantage</strong>.</li>\n<li style=\"\">Knowledge of infrastructure and DevOps (CI/CD, Terraform) - <strong>An advantage</strong>.</li>\n</ul>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1547306/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1547478,"url":"https://remotive.com/remote-jobs/data/data-test-engineer-1547478","title":"Data & Test Engineer","company_name":"HiveMind Network","company_logo":"https://remotive.com/job/1547478/logo","category":"Data","tags":["azure","devops","git","go","python","scrum","sql","agile","product","analytics","languages","data","English","business","selenium","ETL","warehouse","leadership","domain","reporting","kanban","testing","Azure Devops","travel","insurance","server","data migration"],"job_type":"contract","publication_date":"2023-01-06T17:39:28","candidate_required_location":"Europe","salary":"","description":"<p><strong>JOB Title:  </strong>                           <strong>Data Engineer in Test</strong></p>\n<p><strong>Department/Business Unit: </strong>    <strong>Test to join our Data &amp; Analytics team</strong></p>\n<p><u><strong>ORGANISATION AND SCOPE</strong></u></p>\n<p>Our client, provides liability insurance for around 9% of world shipping, with premium income of almost $300m.</p>\n<p><strong><u>Role Purpose</u></strong></p>\n<p>The new leadership team is investing in a product centric, agile business model. We have three domain aligned Product teams, who deliver technology products for the benefit of internal users, our members and brokers. This role will be part of our Claims product team, they work hand in hand with our global claims function to ensure we provide excellent service to our members when they need us the most. The team is a cross-functional agile delivery team, all members of the team are expected to be T-shaped working to deliver value for our club and members as fast as possible.</p>\n<p><strong>This role is focused on testing but we are looking for</strong></p>\n<p><strong>Role: Data Engineer in Test</strong></p>\n<p><strong><u>Main Tasks/Key Accountabilities/Responsibilities:</u></strong></p>\n<p><strong>Required</strong></p>\n<p>·         Data focused test engineer with strong SQL skills / capabilities.</p>\n<p>·         Experience working with SQL Server, Power BI, SSRS.</p>\n<p>·         Will be responsible for testing peers code changes &amp; reconciliation of data.</p>\n<p>·         Test planning / preparation, execution and reporting of results.</p>\n<p><strong>Desirable</strong></p>\n<p>·         Experience with automated testing frameworks e.g. Selenium.</p>\n<p>·         Experience with source control versioning systems e.g. GIT.</p>\n<p>·         Experience working on large ETL / data warehouse projects.</p>\n<p>·         Azure DevOps.</p>\n<p>·         Python.</p>\n<p>·         Working to agile methodologies e.g. Scrum/Kanban.</p>\n<p>·         Experience in the insurance sector, also highly desirable.</p>\n<p>SQL, data reconciliations, Python, reasonable technical but with background in testing. Data reconciliation is what they will predominantly be doing (as a result of data migration work). Potentially digging in reports (most will go back to devs)</p>\n<p>This role is a fully remote opportunity, with occasional travel to client site/s </p>\n<p>Applicants <u><strong>must have the Right to Work</strong></u> in the UK or EU to be considered </p>\n<p>Excellent English verbal &amp; written skills is a Must</p>\n<p>Any additional European  languages is an advantage</p>\n<img src=\"https://remotive.com/job/track/1547478/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1546201,"url":"https://remotive.com/remote-jobs/data/data-warehouse-engineer-1546201","title":"Data Warehouse Engineer","company_name":"In All Media Inc","company_logo":"https://remotive.com/job/1546201/logo","category":"Data","tags":["AWS","python","sql","data","English","software development","ETL","warehouse","hiring","Snowflake","database","development","media","communication","software"],"job_type":"full_time","publication_date":"2023-01-05T23:39:41","candidate_required_location":"Argentina","salary":"","description":"<p>We are hiring!</p>\n<p>Here at In All Media, a Software Development Company based in Austin, TX, we are looking for the best talent to join our company and at this time we are currently looking for a Sr. Data Warehouse Engineer to join our team.</p>\n<p> </p>\n<p>The candidate must be proficient in:</p>\n<p>● Strong experience with SQL.<br>● Experience with AWS ETL.<br>● Experience with ETL methodologies.<br>● Preferred Snowflake Database.<br>● Excellent oral and written communication skills in English.<br><br>Nice to Have:<br><br>- Python</p>\n<p>Are you up for this challenge?</p>\n<p><br>This is a Full-time, 100% remote position with payments in USD.</p>\n<p>If you find this information interesting please let me know.</p>\n<p> </p>\n<p>Apply now!</p>\n<img src=\"https://remotive.com/job/track/1546201/blank.gif?source=public_api\" alt=\"\"/>"}]}