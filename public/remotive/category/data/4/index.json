{"job_count":99,"total_pages":5,"jobs_per_page":20,"prev":"https://eriandev.github.io/api/remotive/3","next":"https://eriandev.github.io/api/remotive/5","results":[{"id":1503053,"url":"https://remotive.com/remote-jobs/data/election-data-researcher-1503053","title":"Election Data Researcher","company_name":"Ballotpedia","company_logo":"https://remotive.com/job/1503053/logo","category":"Data","tags":["go","mobile","email","research","data","creative","web","front","people","reporting","IT","audit","insurance","training"],"job_type":"full_time","publication_date":"2022-12-04T01:40:00","candidate_required_location":"USA","salary":"","description":"<p>Ballotpedia is seeking to hire a full-time, 100% remote Election Data Researcher.</p>\n<p>Reporting to Ballotpedia’s Director of Research, the Election Data Researcher will be responsible for conducting research and monitoring sources, primarily on the Web, to generate and maintain a comprehensive election date calendar, including elections from the federal and state level all the way down to the smallest cities and school districts. The position will also be responsible for executing complex research protocols about a variety of other political topics.</p>\n<p>As an Election Data Researcher, you will grow to develop a good understanding of local election administration processes and know how to appropriately research, categorize, and summarize varying systems to fit the structure required to generate Ballotpedia’s election calendar.</p>\n<p>This is a great position for a skilled researcher who is passionate about the opportunity to help expand fact-based, neutral election coverage in the United States for American voters, especially at the local level.</p>\n<p><strong>Responsibilities</strong></p>\n<p>As an Election Data Researcher, you will:</p>\n<ul>\n<li>Research reliable elections information sources and logic for Ballotpedia’s automated election date crawler technology.</li>\n<li>Monitor and process the results of the automated crawler to generate and maintain Ballotpedia’s election calendar.</li>\n<li>Participate in other Research department activities, including:\n<ul>\n<li>Conducting election laws research and research on other pertinent political topics</li>\n<li>Executing detailed protocols for miscellaneous research projects</li>\n<li>Helping to develop, write, and audit detailed research protocols for miscellaneous projects</li>\n</ul>\n</li>\n</ul>\n<p><strong>Qualifications and Characteristics</strong></p>\n<p>An ideal Election Data Researcher will:</p>\n<ul>\n<li>Have exceptional attention to detail and an ability to understand complex processes and consistently follow complex instructions without errors over a large number of iterations.</li>\n<li>Have excellent research skills. They can follow general guidelines to locate appropriate online and direct outreach sources and record information in an organized, concise manner to answer detailed questions.</li>\n<li>Have sharp critical thinking skills and are able to understand the varied structures of a large number of sources and apply more general categories and logical statements to those structures.</li>\n<li>Enjoy organizing their own lives and the world around them through elegant structures. They maintain orderly habits and perceive external disorder as an opportunity to innovate and improve.</li>\n<li>Enjoy receiving and implementing critical feedback for constant improvement.</li>\n<li>Are able to accurately and concisely summarize complex concepts, difficult text, and detailed structures.</li>\n<li>Have a passion for elections, election and voter information, and politics, with a commitment to Ballotpedia’s mission to remain</li>\n<li>They are adept at using utilities such as Google Chrome, Docs and Sheets, or similar tools to navigate, find, and record information from the Internet.</li>\n</ul>\n<p><strong>Environment</strong></p>\n<p>The Election Data Researcher will work remotely from their home location. All Ballotpedia staff work remotely. To join Ballotpedia, you must have a computer with Internet access.</p>\n<p>Ballotpedia has a flexible work environment, BP Flex, in which every employee enjoys unlimited vacation and flexibility in scheduling. Each employee will be oriented to the principles of Ballotpedia’s flexible environment during new employee training.</p>\n<p><strong>Compensation</strong></p>\n<p>The starting pay range for the Election Data Researcher is $40,000-$50,000/year commensurate with experience.</p>\n<p>In addition to salary, Ballotpedia offers an annual benefits stipend equivalent to $8,000 that is paid out in equal increments in each paycheck once an employee becomes benefits eligible. The stipend may be used to pay for a full benefits package, including health, vision, and dental insurance; retirement accounts; and more. If benefits are not elected, the stipend is taxed as regular income and added to salary.</p>\n<p><strong>To Apply</strong></p>\n<p>To apply, visit the Ballotpedia job opportunities page and fill out the form.</p>\n<p>Please attach the following in PDF format:</p>\n<ul>\n<li>résumé</li>\n<li>cover letter detailing your interest in Ballotpedia’s mission, this position and your salary expectations</li>\n</ul>\n<p>Please ensure that either your résumé or your cover letter include your current address.</p>\n<p><strong>About Ballotpedia</strong></p>\n<p><a class=\"external\" href=\"http://www.ballotpedia.org\" rel=\"nofollow\">Ballotpedia</a> is a collaborative team of fast learners and creative problem solvers who are eager to work hard to make the world a better place. We believe the world will be a better place if every citizen has access to information to make informed decisions about their vote in every election in which they are eligible to vote: primary, general, and special elections; federal, state, and local offices.</p>\n<p>We work diligently to present the available information about elections, candidates, judges, ballot measures, policies, and more in a way that enables our readers to vote with confidence and to act as engaged citizens outside of the polling booth.</p>\n<p>Ballotpedia readers, like Ballotpedia staff, are special people.</p>\n<p>When we launched in 2007, we did not go out of our way to seek new readers. Starting with our small team of visionary idealists, nerds, and aspiring political journalists, we just wrote the best unbiased online articles we could, especially about ballot measures. Readers found those articles in droves. It turns out there was an unclaimed audience out there—people who wanted straightforward facts about political issues, and were willing to read at length instead of just scanning the headlines.</p>\n<p>“If you build it, they will come:'' our readers came to our neutral oasis in growing numbers; we’ve had many millions of lifetime pageviews, we reached nearly half of all voters in 2020, and, in the month surrounding the November 2020 election, we were the 77th most-visited website in the U.S.</p>\n<p>We’ve come to realize that we need to meet our readers where they are. In doing so, over the past five years, we’ve grown our email newsletter program from infancy to include more than 1,000,000 opt-in subscribers with more than a dozen newsletters to choose from. We are working in numerous ways to help put our neutral information in front of people at the times when they most need it, including on mobile phones while you’re standing in the voting booth. We firmly believe that our readers, and the mindset we help them cultivate, are essential in a world where too many others are fighting to get us all addicted to sensational posts and the irrational decisions they foster.</p>\n<p>If this is a mission you’d be willing to work hard to achieve, and if this is a team you’d be willing to work hard with—JOIN US.</p>\n<img src=\"https://remotive.com/job/track/1503053/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1506049,"url":"https://remotive.com/remote-jobs/data/data-engineer-external-1506049","title":"Data Engineer-External","company_name":"Cover Whale","company_logo":"https://remotive.com/job/1506049/logo","category":"Data","tags":["api","AWS","devops","hadoop","linux","python","sql","management","operations","research","product management","Engineering","product","analytics","deployment","data","troubleshooting","spark","business","ETL","leadership","debugging","APIs","writing","learning","law","communication","architecture ","insurance"],"job_type":"full_time","publication_date":"2022-12-02T23:40:09","candidate_required_location":"USA","salary":"","description":"<p><strong>What We’re Looking For:</strong></p><p>Cover Whale is searching for a Data Engineer to join our rapidly growing Data team. This position will provide an excellent opportunity to impact multiple business areas. At Cover Whale, we rely on data to drive our systems and solutions. We are seeking an experienced data engineer to continue to help us revolutionize the InsureTech space. </p><p><strong>What You’ll Do:</strong></p><ul> <li>Primary focus will be on building out our ETL processes.</li> <li>Communicate highly complex data structures to organizational leaders.</li> <li>Provide technical expertise, thought leadership, and architectural guidance to our Data and Engineering teams.</li> <li>Collaborate with Product Management, internal stakeholders, and external vendors to continually improve deployment and operations.</li> <li>Foster a continuous learning environment through continuously improving processes, procedures, and approaches.</li> <li>Work with cross-functional Data teams to develop, manage, and implement products and technology roadmaps in alignment with long-term strategies.</li> <li>Create proof-of-concept and pilot technology demonstrations to stakeholders surrounding microservice architecture and service meshes.</li> </ul><p><strong>Requirements</strong></p><ul> <li>Three or more years of experience with Python and SQL</li> <li>Located in the US</li> <li>Linux expertise</li> <li>Familiarity with the AWS ecosystem, specifically API Gateway, Kinesis, Athena, RDS, and Aurora</li> <li>Experience building ETL pipelines for analytics and internal operations </li> <li>Experience building internal APIs and integrating with external APIs</li> <li>Effective communication skills, especially for explaining technical concepts to nontechnical business leaders.</li> <li>Desire to work on a dynamic, research-oriented team.</li> <li>Experience with distributed application concepts and DevOps tooling</li> <li>Excellent writing and communication skills</li> <li>Troubleshooting and debugging ability</li> </ul><p><br></p><p>Nice to have:</p><ul> <li>2 or more years of experience with Hadoop, Spark and Airflow</li> <li>Experience with DAGs.</li> </ul><p><strong>Benefits</strong></p><ul> <li>Competitive Pay</li> <li>Medical/Dental/Vision</li> <li>Short/Long Term Disability</li> <li>Employer Paid Life Insurance and AD&amp;D</li> <li>Matching 401k Plan</li> <li>Flexible Vacation Policy</li> <li>Generous Parental Leave Program</li> <li>Employee Assistance Program</li> </ul><p><em>We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.</em></p><img src=\"https://remotive.com/job/track/1506049/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1506050,"url":"https://remotive.com/remote-jobs/data/data-engineer-internal-1506050","title":"Data Engineer-Internal","company_name":"Cover Whale","company_logo":"https://remotive.com/job/1506050/logo","category":"Data","tags":["api","AWS","devops","hadoop","linux","python","sql","management","operations","research","product management","Engineering","product","analytics","deployment","data","troubleshooting","spark","business","ETL","leadership","debugging","APIs","writing","learning","law","communication","architecture ","insurance"],"job_type":"full_time","publication_date":"2022-12-02T23:40:07","candidate_required_location":"USA","salary":"","description":"<p><strong>What We’re Looking For:</strong></p>\n<p>Cover Whale is searching for a Data Engineer to join our rapidly growing Data team. This position will provide an excellent opportunity to impact multiple business areas. At Cover Whale, we rely on data to drive our systems and solutions. We are seeking an experienced data engineer to continue to help us revolutionize the InsureTech space.</p>\n<p><strong>What You’ll Do:</strong></p>\n<ul>\n<li>Primary focus will be on building out our ETL processes.</li>\n<li>Communicate highly complex data structures to organizational leaders.</li>\n<li>Provide technical expertise, thought leadership, and architectural guidance to our Data and Engineering teams.</li>\n<li>Collaborate with Product Management, internal stakeholders, and external vendors to continually improve deployment and operations.</li>\n<li>Foster a continuous learning environment through continuously improving processes, procedures, and approaches.</li>\n<li>Work with cross-functional Data teams to develop, manage, and implement products and technology roadmaps in alignment with long-term strategies.</li>\n<li>Create proof-of-concept and pilot technology demonstrations to stakeholders surrounding microservice architecture and service meshes.</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Three or more years of experience with Python and SQL</li>\n<li>Located in the US</li>\n<li>Linux expertise</li>\n<li>Familiarity with the AWS ecosystem, specifically API Gateway, Kinesis, Athena, RDS, and Aurora</li>\n<li>Experience building ETL pipelines for analytics and internal operations</li>\n<li>Experience building internal APIs and integrating with external APIs</li>\n<li>Effective communication skills, especially for explaining technical concepts to nontechnical business leaders.</li>\n<li>Desire to work on a dynamic, research-oriented team.</li>\n<li>Experience with distributed application concepts and DevOps tooling</li>\n<li>Excellent writing and communication skills</li>\n<li>Troubleshooting and debugging ability</li>\n</ul>\n<p> </p>\n<p>Nice to have:</p>\n<ul>\n<li>2 or more years of experience with Hadoop, Spark and Airflow</li>\n<li>Experience with DAGs.</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Competitive Pay</li>\n<li>Medical/Dental/Vision</li>\n<li>Short/Long Term Disability</li>\n<li>Employer Paid Life Insurance and AD&amp;D</li>\n<li>Matching 401k Plan</li>\n<li>Flexible Vacation Policy</li>\n<li>Generous Parental Leave Program</li>\n<li>Employee Assistance Program</li>\n</ul>\n<p><em>We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.</em></p>\n<img src=\"https://remotive.com/job/track/1506050/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1502715,"url":"https://remotive.com/remote-jobs/data/data-engineer-i-1502715","title":"Data Engineer I","company_name":"Mediavine","company_logo":"https://remotive.com/job/1502715/logo","category":"Data","tags":["AWS","cloud","devops","looker","python","react","security","sql","management","operations","content","Engineering","product","analytics","advertising","knowledge","data","web","business","infrastructure","warehouse","people","metabase","websites","data engineering","Snowflake","culture","data pipelines","IT","writing","learning","coding","organization","plugins","support","diversity","production","travel","insurance"],"job_type":"full_time","publication_date":"2022-12-01T23:39:23","candidate_required_location":"USA","salary":"","description":"<p>Mediavine is seeking a Data Engineer to join our engineering team. We are looking for someone who enjoys solving interesting problems and wants to work with a small team of talented engineers on a product used by thousands of publishers. Applicants must be based in the United States.</p>\n<div class=\"h3\">About Mediavine</div>\n<p>Mediavine is a fast-growing advertising management company representing nearly 10,000 websites in the food, lifestyle, DIY, and entertainment space. Founded by content creators, for content creators, Mediavine is a Top 20 Comscore property, exclusively reaching over 125 million monthly unique visitors. With best-in-class technology and a commitment to traffic quality and brand safety, we ensure optimal performance for our creators.</p>\n<div class=\"h3\">Mission &amp; Culture</div>\n<p>We help content creators build sustainable businesses. From educational tools and cutting-edge plugins to ad technology that maximizes earnings without slowing down your site, our motivation is to ensure their brand and business grow in every respect.</p>\n<p>We are striving to build an inclusive and diverse team of highly talented individuals that reflects the industries we serve and the world we live in. We are committed to creating a culture where everyone feels welcome. We are looking for individuals that will challenge us to continuously evolve and make Mediavine the employer of choice for people of all backgrounds. We strongly encourage minorities and individuals from underrepresented groups in technology to apply for this position.</p>\n<p>Diversity and inclusion aren't platitudes to us; we take them seriously. Have a look at <a class=\"external\" href=\"https://www.mediavine.com/our-team/\" rel=\"nofollow\">our team</a> and read through our <a class=\"external\" href=\"https://www.mediavine.com/blog/\" rel=\"nofollow\">blog posts</a> to learn more about our values and discover if Mediavine is the place for you!</p>\n<p><strong>Position Title &amp; Overview</strong></p>\n<p>The Data &amp; Analytics team consists of data analysts, data engineers and analytics engineers working to build the most effective platform and tools to help uncover opportunities and make decisions with data here at Mediavine. We partner with Product, Support, Ad Operations and other teams within the Engineering department to understand behavior, develop accurate predictors and build solutions that provide the best internal and external experience possible.</p>\n<p>A Data Engineer at Mediavine will help build and maintain our data infrastructure. Building scalable data pipelines, managing transformation processes, and ensuring data quality and security at all steps along the way. This will include writing and maintaining code in Python and SQL, developing on AWS, and using third-party tools like Rundeck, Metabase, and others to round out the environment.</p>\n<p>Our current data engineering toolkit consists of custom Python data pipelines, AWS infrastructure including Kinesis pipelines, Rundeck scheduling, dbt for transformation and Snowflake as our data warehouse platform..</p>\n<p><strong>Essential Responsibilities</strong></p>\n<ul>\n<li>Maintain and support data pipelines that make data available for analytic and application use cases</li>\n<li>Follow established best practices in creating new pipelines</li>\n<li>React to data quality notifications, working with users and other developers to communicate the issue and resolve</li>\n<li>Grow in technical knowledge and expand your ability to contribute to the team</li>\n<li>Support data analysts and analytics engineers ability to meet the needs of the organization</li>\n<li>Participate in code reviews, understanding coding standards, ensuring test coverage and being aware of best practices</li>\n<li>Build or implement tooling around data quality as needed</li>\n<li>Provide support when data issues are discovered by users or other team members</li>\n<li>Work with data analysts and analytics engineers to standardize transformation logic in the dbt layer for consistency and ease of exploration by end users</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<p><strong>Location:</strong></p>\n<ul>\n<li>Applicants must be based in the United States</li>\n</ul>\n<p><strong>You Have:</strong></p>\n<ul>\n<li>1+ years of experience in a data role</li>\n<li>Experience with Python (Understands libraries, classes, functions)</li>\n<li>Proficient SQL skills (CTEs, window functions)</li>\n<li>An understanding of data modeling concepts</li>\n<li>Experience checking in code to production with source control, pull reviews, approvals, etc.</li>\n<li>Experience working with DevOps to deploy, scale and monitor data infrastructure</li>\n<li>Scheduler experience either traditional or DAG based</li>\n<li>Comfortable working with cloud data warehouses (Big Query, Snowflake, Redshift)</li>\n</ul>\n<p><strong>Nice to haves:</strong></p>\n<ul>\n<li>Experience with web analysis such as creating data structure that support product funnels, user behavior, and decision path analysis</li>\n<li>Experience with dbt</li>\n<li>Experience with orchestration tools particularly across different technologies and stacks</li>\n<li>The ability to make your teammates laugh (it wouldn’t hurt if you were fun to work with is what I’m saying)</li>\n<li>Familiarity with event tracking systems (NewRelic, Snowplow, etc)</li>\n<li>Experience with one or more major BI tools (Domo, Looker, PowerBI, etc.)</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Remote work environment</li>\n<li>Travel opportunities (remember those!?)</li>\n<li>Comprehensive benefits including 401k, Health, Dental, and Vision insurance</li>\n<li>Learning allowance</li>\n<li>Generous Vacation/Time off policies</li>\n<li>Additional side benefits such as home-office upgrades, tuition reimbursement, paid gym memberships and wellness retreats, upgraded flights, cool swag and more</li>\n<li>Company match charitable donations</li>\n</ul>\n<p>Mediavine is an Equal Opportunity Employer</p>\n<img src=\"https://remotive.com/job/track/1502715/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1494845,"url":"https://remotive.com/remote-jobs/data/data-insights-analyst-1494845","title":"Data Insights Analyst","company_name":"Outsourced Doers","company_logo":"https://remotive.com/job/1494845/logo","category":"Data","tags":["analyst","customer support","finance","marketing","microsoft","virtual assistant","growth","management","project management","research","product","market research","advertising","data analysis","digital marketing","data","business","culture","metrics","reporting","microsoft office","applications","communication","support","programs","software","training"],"job_type":"full_time","publication_date":"2022-12-01T23:39:21","candidate_required_location":"Philippines","salary":"","description":"<p><strong>About Us</strong></p>\n<p>Outsourced Doers is the world's fastest-growing virtual assistant company for online entrepreneurs.  Outsourced Doers match trained marketing Virtual Assistants (who we call Doers) with busy, time-poor online entrepreneurs (who we call Founders). With over 1,000 Doers and Founders from over 50 countries, we're helping Founders globally to work less and achieve more.</p>\n<p><strong>About the Role</strong></p>\n<p>We are currently searching for a Data Insights Analyst to join our marketing team. The primary purpose of the Data Insights Analyst is to leverage business performance by providing up-to-date analysis on consumers, brands, and categories to appropriate internal and external stakeholders. </p>\n<p>Role responsibilities range in nature and complexity, with key components including:</p>\n<ul>\n<li>Undertaking research projects involving detailed analysis and assessment of growth opportunities with the ability to distill key takeaways for the team. </li>\n<li>Work across omnichannel platforms to provide data analysis and insights into the business' advertising solutions. </li>\n<li>Complete ad hoc data requests from various stakeholders exposed to marketing, finance, customer support, and product areas. </li>\n<li>Take ownership of reporting key business and marketing metrics. </li>\n<li>Collaborate with growth team members to test and assess the efficacy of emerging growth channels. </li>\n</ul>\n<p><strong>About You</strong></p>\n<p>In addition to the ability to thrive in a fast-paced environment, balance multiple priorities, work under pressure and meet strict deadlines; we are seeking applications from candidates with the following skills and characteristics:</p>\n<ul>\n<li>A natural sense of curiosity and an urge to understand “why.” </li>\n<li>Highly analytical with experience combining and analysing large datasets from multiple data sources. </li>\n<li>A drive and ability to build something great. </li>\n<li>A team player with excellent communication skills. </li>\n<li>Ability to pick up new tools quickly. </li>\n</ul>\n<p><strong>What You've Done:</strong></p>\n<p>The following experience is required (or, in some cases, desired) for this role:</p>\n<ul>\n<li>A degree in Marketing /Communications or similar</li>\n<li>3+ years experience in a similar position</li>\n<li>Understanding of research software, Microsoft Office programs, and market research skills. </li>\n<li>Excellent project management skills with the ability to organise and prioritise. </li>\n</ul>\n<p><strong>What Outsourced Doers offers:</strong></p>\n<ul>\n<li>A chance to work within a fast-growth tech company.</li>\n<li>A positive work environment, where you are encouraged and supported to flourish and achieve success.</li>\n<li>Full-time home-based position with full government benefits including 13th Month Pay</li>\n<li>HMO upon regularization</li>\n<li>Bonus schemes, reward &amp; recognition programs, and monthly team celebrations</li>\n<li>Great company culture &amp; Work-life balance</li>\n<li>Monthly team celebrations</li>\n<li>Free and ongoing training in Digital Marketing</li>\n<li>You'll get to work with an intelligent, hard-working, and vibrant team</li>\n<li>Lots of support and motivation to be the best you can be</li>\n</ul>\n<p> </p>\n<p>If you are interested in applying for this position, just hit the “Apply” button below.</p>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1494845/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1494061,"url":"https://remotive.com/remote-jobs/data/senior-data-scientist-1494061","title":"Senior Data Scientist","company_name":"Sunscrapers Sp. z o.o.","company_logo":"https://remotive.com/job/1494061/logo","category":"Data","tags":["api","AWS","azure","cloud","consulting","data science","developer","devops","docker","machine learning","python","scrum","sql","video","management","networking","design","programming","Engineering","packaging","data analysis","knowledge","rest","data","troubleshooting","customer service","creative","English","REST API","business","infrastructure","NLP","data visualization","ETL","data engineering","Snowflake","recruitment","jenkins","data pipelines","APIs","IT","kanban","investment","software engineering","NumPy","learning","natural language processing","organization","problem-solving","computer science","data-driven","statistics","Azure Devops","support","software"],"job_type":"full_time","publication_date":"2022-11-30T19:40:23","candidate_required_location":"Poland","salary":"","description":"<p><strong>Few words about the project<br><br></strong><strong>We’re looking for a Senior Data Scientist to join our team in Warsaw or remotely. You will join our client, one of the world’s biggest private investment companies, located in the USA. The organization is specialized in the world’s consulting services for real estate, venture capital, investments and credits.<br><br></strong>As a Senior Data Scientist, you’ll support data analysis workflows and data engineering efforts at the US-based private investment firm. You’ll work directly with other data scientists and data analysts to enable data-driven decision business processes. You’ll also cooperate with the data engineering team to design and implement common code for the data science team. <br><br>You’ll deliver solutions using:<br><br>Technologies: Python, SQL, Pandas, NumPy, nltk, scikit-learn, seaborn, etc<br>Tools: Jupyter Notebook, Snowflake, DBT, Docker, Azure DevOps, Octopus Deploy &amp; Jenkins<br>Cloud: AWS (EC2, S3, Athena), Box<br>Best Practices: Continuous Integration, Code Reviews, Scrum/Kanban, Python packaging<br><br>The ideal candidate will be well organized, eager to constantly improve and learn, driven and, most of all - a team player!<br><br>The recruitment process is well organized - it’s one video meeting, that lasts about 1,5-2hours, and contains: 30 minutes of a talk with a Manager (algorithmic and data-science related technical questions), 30 minutes of talk with the Data Analytic (cultural fit interview), 30 minutes of talk with the Senior Software Developer (programming questions). <br><br>Then you will receive the decision. <br><br>There is a plan to work at least 4 hours a day overlap with the USA East Coast timezone, so your work should be organized in hours like 10:00-18:00 or 11:00-19:00 PL timezone.<br><br></p>\n<p><strong>You will be responsible for:</strong></p>\n<ul>\n<li>Extracting actionable insights from broad, open-ended questions to influence investment decisions</li>\n<li>Developing common data analysis workflows using NLP (sentiment analysis), Geospatial analysis and customer segmentation methods</li>\n<li>Designing a common library for other data scientists that includes storage connectors, proxy authentication, secrets management, standard data visualization methods, and more</li>\n<li>Designing and implementing ML/DL models for text and customer segmentation data</li>\n<li>Designing and building AWS infrastructure together with the Data Engineering team</li>\n<li>Developing data technology stack including API services and ETL pipelines,</li>\n<li>Designing datasets and schemes for consistency and easy access</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>At least 5 years of professional experience in data-related roles or software engineering</li>\n<li>Undergraduate or graduate degree in Computer Science, Engineering, Mathematics, or similar</li>\n<li>Excellent command of spoken and written English, at least C1</li>\n<li>Expertise in Python and SQL</li>\n<li>Proficiency in statistics and machine learning, as well as Python libraries like Pandas, NumPy, matplotlib, seaborn, scikit-learn, Keras, etc</li>\n<li>Excellent understanding of natural language processing (NLP)</li>\n<li>Good understanding of geospatial analysis and data formats</li>\n<li>Experience with AWS EC2, S3 and Athena</li>\n<li>Ability to use Docker and create Dockerfiles</li>\n<li>Ability to take an ambiguous analysis question and run with it independently</li>\n<li>Creative problem-solving skills</li>\n<li>Great customer service and troubleshooting skills<br><br><strong>Nice to have:<br></strong></li>\n<li>Experience in designing and implementing REST API services</li>\n<li>Experience in building ETL processes and data pipelines with platforms like Airflow or AWS services</li>\n<li>Familiarity with Azure DevOps stack</li>\n<li>Knowledge of Google Maps, Open Street Map or TomTom APIs</li>\n<li>Experience with ArcGis ecosystem</li>\n<li>Experience in operating within a secure networking environment, like a corporate proxy</li>\n<li>Perfectly, if you have one month of notice period, or you are available ASAP, but we can also wait for you longer.</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p><strong>What do we offer?</strong></p>\n<ul>\n<li>Flexible working hours and remote work possibility</li>\n<li>Multisport card</li>\n<li>Private medical care</li>\n<li>In-house workshops and tech talks</li>\n<li>Free access to the best tools and softwares to develop your skills and work effectively</li>\n<li>Comfortable office in central Warsaw equipped with all the necessary tools for comfortable work (Macbook Pro, external screen, ergonomic chairs) - if working on site</li>\n</ul>\n<p>Sounds like a perfect place for you? Don’t hesitate to click apply and submit your application today!</p>\n<p><br>Check our place: <a class=\"external\" href=\"https://www.facebook.com/sunscrapers\" rel=\"nofollow\">fb</a> /<a class=\"external\" href=\"https://www.instagram.com/sunscrapers\" rel=\"nofollow\">instagram</a></p>\n<img src=\"https://remotive.com/job/track/1494061/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1496685,"url":"https://remotive.com/remote-jobs/data/data-engineer-1496685","title":"Data Engineer","company_name":"Anant Corporation","company_logo":"https://remotive.com/job/1496685/logo","category":"Data","tags":["AWS","azure","cassandra","cloud","docker","java","kubernetes","python","scala","management","operations","design","project management","jira","Engineering","documentation","product","knowledge","data","troubleshooting","Enterprise","spark","business","infrastructure","terraform","GCP","google cloud","people","clusters","data engineering","development","debugging","ansible","learning","law","k8s","coding","computer science","grafana","github","communication","time management","support","software","training"],"job_type":"contract","publication_date":"2022-11-29T17:40:33","candidate_required_location":"USA","salary":"","description":"<div class=\"h1\">Description</div>\n<p>This is a remote position.</p>\n<div style=\"margin: 0px; padding: 0px;\">\n<div class=\"highlighter-context page view\" id=\"content\" style=\"margin: 0px; padding: 0px; clear: none !important; position: static !important;\">\n<div class=\"_1bsb1osq _19pkidpf _2hwx1wug _otyridpf _18u01wug\" style=\"margin: 0px auto; padding: 0px; width: 1446px;\">\n<div class=\"wiki-content css-b7ln87 e4p5jys0\" id=\"main-content\" style=\"margin: 0px; padding: 0px;\">\n<div class=\"renderer-overrides\" style=\"margin: 0px; padding: 0px;\">\n<div class=\"ak-renderer-wrapper css-2c6ch1\" style=\"margin: 0px; padding: 0px; position: relative; width: 1446px;\">\n<div class=\"css-1jgf91b\" style=\"margin: 0px auto; padding: 0px 32px; max-width: 760px; white-space: pre-wrap;\">\n<div class=\"ak-renderer-document\" style=\"margin: 0px; padding: 0px;\">\n<div class=\"h4\" id=\"Overview\" style=\"margin: 0px; padding: 0px; font-style: inherit; line-height: 1.428; font-weight: 600; letter-spacing: -0.003em; text-transform: none;\"><strong>Overview</strong></div>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Anant is a destination employer for high-performing, diverse, global talent. Our Data Engineers support the development, operation, and maintenance of real-time data processing. They oversee and deliver the success of client and internal projects. The Data Engineer will not only support our internal team, but will also participate in client project work including design of novel systems, debugging performance degradations and read/write latencies, audits, monitoring, and health checks. An ideal Data Engineering candidate will have experience supporting rollout of migration tooling through client environments by troubleshooting GKE, Airflow, Dataproc, DataStax Enterprise, and DataStax Astra. Other candidates will gain experience using these tools.</p>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">We are looking for a Data Engineer to join our team immediately. We look for the best and brightest and those willing to learn.</p>\n<hr style=\"border: none; margin: 1.714em 0px; height: 2px; border-radius: 1px; clear: both;\">\n<div class=\"h4\" id=\"Responsibilities\" style=\"margin: 1.357em 0px 0px; padding: 0px; font-style: inherit; line-height: 1.428; font-weight: 600; letter-spacing: -0.003em; text-transform: none;\"><strong>Responsibilities</strong></div>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Work with multiple teams and multiple projects (e.g., application, infrastructure, cloud, etc.) to</p>\n<ul class=\"ak-ul\" style=\"margin: 4px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: circle;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Complete requests (adding new or decommissioning existing clusters)</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Debug and resolve issues</p>\n</li>\n</ul>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Utilize project management software (e.g., Jira) to log time and resolve tickets</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Create and update SOP’s, Runbooks, issue reports, and other documentation as required</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Consult on client projects, maintain client confidentiality and protect client operations by keeping information confidential </p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Contribute to team effort by using effective communication skills, being a self-starter, and taking responsibility for deliverables</p>\n</li>\n</ul>\n<hr style=\"border: none; margin: 1.714em 0px; height: 2px; border-radius: 1px; clear: both;\">\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><strong>Required Qualifications</strong></p>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Certifications in Spark</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">5+ years of relevant software design and development or certifications in Cassandra / DSE</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">5+ years of relevant software design and development or certifications in Google Cloud Platform (GCP)</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">At least ONE of the following:</p>\n<ul class=\"ak-ul\" style=\"margin: 4px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: circle;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">3+ years engineering in Kubernetes-based environments as well as variants thereof (e.g., GKE)</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">5+ years of relevant software design and development in Cassandra (Astra)</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">2+ years of relevant software design and development including Airflow</p>\n</li>\n</ul>\n</li>\n</ul>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><strong>Additional Qualifications</strong></p>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Certifications in Spark, Cassandra, Terraform, and/or Cloud Platform Services like AWS, GCP, or Azure</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">2+ years of relevant software design and development including the below as well as source control apps such as Bitbucket, Github, etc.</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">3+ years of relevant experience in Ansible, Docker, Prometheus, Grafana, Helm</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">5+ years of relevant software design and development in Terraform, Spark, Dataproc, Cassandra (including DSE, Astra, and other variants), and Google Cloud Platform</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">BS degree in Computer Science or related technical field involving coding, or equivalent practical experience</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Ability to troubleshoot, debug and optimize code</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Ability to identify and automate routine tasks</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Incident management and root cause analysis</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Strong organizational, time management, and detail skills.</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Strong communication and interpersonal skills, able to comfortably and pleasantly deal with a variety of people</p>\n</li>\n</ul>\n<hr style=\"border: none; margin: 1.714em 0px; height: 2px; border-radius: 1px; clear: both;\">\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><strong>Hard Skills</strong></p>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Troubleshoot and support rollout of tooling and services that use Airflow (on K8s), Spark (managed), DataStax Enterprise, and DataStax Astra,</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Create, troubleshoot, and refactor Python DAGs,</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Create and deploy infrastructure as code via Ansible and Terraform,</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Demonstrate familiarity with creating and destroying resources on GCP, including GCP monitoring dashboards,</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Demonstrate an aptitude for RCA and troubleshooting code and systems integration issues, and</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Familiarity with Scala, Python, and Java.</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Conduct rapid POC Development and be able to transfer knowledge to others</p>\n</li>\n</ul>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><strong>Soft Skills</strong></p>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Demonstrate a passion for excellence in work product and customer delivery</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Create and deliver live and recorded demos for customers and internal stakeholders</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Familiarity with the enterprise data platform ecosystem</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Continuous learning mindset</p>\n</li>\n</ul>\n<hr style=\"border: none; margin: 1.714em 0px; height: 2px; border-radius: 1px; clear: both;\">\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><strong>Working at Anant</strong></p>\n<ul class=\"ak-ul\" style=\"margin: 10px 0px 0px; padding: 0px 0px 0px 24px; list-style-type: disc;\">\n<li>\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Anant performs business around the clock, but some availability during during US Eastern Time business hours is important.</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Anant is a 100% remote workplace.</p>\n</li>\n<li style=\"margin-top: 4px;\">\n<p style=\"margin: 0px; padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Anant is currently looking to hire part time, with future full-time work available.</p>\n</li>\n</ul>\n<hr style=\"border: none; margin: 1.714em 0px; height: 2px; border-radius: 1px; clear: both;\">\n<div class=\"h2\" id=\"About-Anant\" style=\"margin: 1.8em 0px 0px; padding: 0px; font-style: inherit; line-height: 1.2; font-weight: 500; letter-spacing: -0.008em; text-transform: none; border-bottom-color: #cccccc;\">About Anant</div>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\">Anant is working to become the authoritative market leader in business platforms. Most technology leaders have a hard time retaining the experts to help them build and manage global data platforms because of the high costs of specialized talent. We created a training program for client teams and a network of trained specialists on our framework who are available on a full, part, or on a project by project basis. </p>\n<p style=\"padding: 0px; line-height: 1.714; font-weight: normal; letter-spacing: -0.005em;\"><em>Anant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.</em></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"css-1baxzsz e3p9ckn0\" id=\"comment-container\" style=\"margin: 0px; padding: 0px; width: 50px; left: 1153px; top: 192px; max-height: 50px;\"> </div>\n</div>\n</div>\n</div>\n<div class=\"_19pkys9h _2hwx1wug _otyr1ylp _18u01wug _1bsb1osq _p12fukw8\" style=\"margin: 5pc auto 40px; padding: 0px; max-width: 760px; width: 760px;\">\n<div style=\"margin: 0px; padding: 0px;\">\n<div class=\"css-iucoak-container\" style=\"padding: 0px; position: relative; \">\n<div class=\"labels__control css-1vk57ay-control\" style=\"margin: 0px; padding: 0px; background-color: white; border-radius: 3px; cursor: default; min-height: 40px; position: relative; outline: 0px !important; border: 2px solid white;\">\n<div class=\"labels__value-container labels__value-container--is-multi css-f9obad\" style=\"margin: 0px; padding: 4px; position: relative; overflow: hidden;\">\n<div class=\"css-yr9yzn\" style=\"margin: 2px; padding: 2px 0px; visibility: visible;\">\n<div class=\"labels__input\" style=\"margin: 0px; padding: 0px; display: inline-block;\">\n<div style=\"margin: 0px; padding: 0px; top: 0px; left: 0px; visibility: hidden; height: 0px; overflow: scroll; white-space: pre; font-weight: 400; font-style: normal; letter-spacing: normal; text-transform: none;\"> </div>\n</div>\n</div>\n<div class=\"_syaz9sh9\" style=\"margin: 0px; padding: 0px; color: #6b778c;\">\n<div class=\"_1e0c1txw _4cvr1h6o\" style=\"margin: 0px; padding: 0px;\"> </div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div> </div>\n<p> </p>\n<div class=\"h1\">Skills</div>\n<p>Overview Anant is a destination employer for high-performing, diverse, global talent. Our Data Engineers support the development, operation, and maintenance of real-time data processing. They oversee and deliver the success of client and internal projects. The Data Engineer will not only support our internal team, but will also participate in client project work including design of novel systems, debugging performance degradations and read/write latencies, audits, monitoring, and health checks. An ideal Data Engineering candidate will have experience supporting rollout of migration tooling through client environments by troubleshooting GKE, Airflow, Dataproc, DataStax Enterprise, and DataStax Astra. Other candidates will gain experience using these tools. We are looking for a Data Engineer to join our team immediately. We look for the best and brightest and those willing to learn. Responsibilities Work with multiple teams and multiple projects (e.g., application, infrastructure, cloud, etc.) to Complete requests (adding new or decommissioning existing clusters) Debug and resolve issues Utilize project management software (e.g., Jira) to log time and resolve tickets Create and update SOP’s, Runbooks, issue reports, and other documentation as required Consult on client projects, maintain client confidentiality and protect client operations by keeping information confidential Contribute to team effort by using effective communication skills, being a self-starter, and taking responsibility for deliverables Required Qualifications Certifications in Spark 5+ years of relevant software design and development or certifications in Cassandra / DSE 5+ years of relevant software design and development or certifications in Google Cloud Platform (GCP) At least ONE of the following: 3+ years engineering in Kubernetes-based environments as well as variants thereof (e.g., GKE) 5+ years of relevant software design and development in Cassandra (Astra) 2+ years of relevant software design and development including Airflow Additional Qualifications Certifications in Spark, Cassandra, Terraform, and/or Cloud Platform Services like AWS, GCP, or Azure 2+ years of relevant software design and development including the below as well as source control apps such as Bitbucket, Github, etc. 3+ years of relevant experience in Ansible, Docker, Prometheus, Grafana, Helm 5+ years of relevant software design and development in Terraform, Spark, Dataproc, Cassandra (including DSE, Astra, and other variants), and Google Cloud Platform BS degree in Computer Science or related technical field involving coding, or equivalent practical experience Ability to troubleshoot, debug and optimize code Ability to identify and automate routine tasks Incident management and root cause analysis Strong organizational, time management, and detail skills. Strong communication and interpersonal skills, able to comfortably and pleasantly deal with a variety of people Hard Skills Troubleshoot and support rollout of tooling and services that use Airflow (on K8s), Spark (managed), DataStax Enterprise, and DataStax Astra, Create, troubleshoot, and refactor Python DAGs, Create and deploy infrastructure as code via Ansible and Terraform, Demonstrate familiarity with creating and destroying resources on GCP, including GCP monitoring dashboards, Demonstrate an aptitude for RCA and troubleshooting code and systems integration issues, and Familiarity with Scala, Python, and Java. Conduct rapid POC Development and be able to transfer knowledge to others Soft Skills Demonstrate a passion for excellence in work product and customer delivery Create and deliver live and recorded demos for customers and internal stakeholders Familiarity with the enterprise data platform ecosystem Continuous learning mindset Working at Anant Anant performs business around the clock, but some availability during during US Eastern Time business hours is important. Anant is a 100% remote workplace. Anant is currently looking to hire part time, with future full-time work available. About Anant Anant is working to become the authoritative market leader in business platforms. Most technology leaders have a hard time retaining the experts to help them build and manage global data platforms because of the high costs of specialized talent. We created a training program for client teams and a network of trained specialists on our framework who are available on a full, part, or on a project by project basis. Anant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.</p>\n<div class=\"h1\">Experience</div>\n<p>5+ years</p>\n<img src=\"https://remotive.com/job/track/1496685/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1498734,"url":"https://remotive.com/remote-jobs/data/analytics-engineer-1498734","title":"Analytics Engineer","company_name":"Prismic","company_logo":"https://remotive.com/job/1498734/logo","category":"Data","tags":["analyst","AWS","marketing","python","saas","sales","sql","growth","customer success","research","Engineering","product","analytics","communications","data","creative","English","business","infrastructure","warehouse","leadership","amplitude","Snowflake","culture","events","data pipelines","IT","hubspot","learning","coding","prismic","communication","revenue","support","architecture "],"job_type":"full_time","publication_date":"2022-11-29T15:39:24","candidate_required_location":"Europe, Africa","salary":"","description":"<div><span style=\"\">Prismic is a rapidly growing website builder and platform. We use data to determine the direction of the business and need help from a creative and flexible analytics engineer (you will be our first analytics engineer and will report to our head of Engineering).</span></div>\n<div> </div>\n<div><span style=\"\">You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth.</span></div>\n<div> </div>\n<div><span style=\"\">Prismic has already built a Customer Data Platform (using </span><a class=\"postings-link\" href=\"http://segment.com\" rel=\"nofollow\" style=\"\">segment.com</a><span style=\"\">), and we're ready to expand and move to a full fledged data warehouse architecture (including dbt, snowflake and more). </span><span style=\"\">You will collaborate with our platform team to build data pipelines and warehouse architecture, to process data and to build and deploy infrastructure that supports all of our data needs.</span></div>\n<div><span style=\"\">We have a strong desire to gravitate our architecture toward the state of the art, and will rely on you to help us get there.</span></div>\n<div> </div>\n<div><strong style=\"\">What will you be doing?🔧</strong></div>\n<div><span style=\"\">Your insights will help us improve our technical stack and also combine effectively with Usability Research. Your business savviness will be fueled by automated data models and confirmed through dashboard communications to keep us all aware of the status of our data and avoiding compromises in data quality.</span></div>\n<div><span style=\"\">Growth will be based on pinpointing with confidence our challenges and opportunities:</span></div>\n<div><span style=\"\">– </span><strong style=\"\">Marketing:</strong><span style=\"\"> Helping in identifying the right audience, the most effective channel to communicate our promise, and properly onboard our prospect into our product. Evaluate the impact of marketing initiatives on conversion and word of mouth.</span></div>\n<div><span style=\"\">– </span><strong style=\"\">Revenue:</strong><span style=\"\"> help lead growth hypotheses and sales decisions by detecting decision makers, and communicate macro trends and patterns to drive total customer success</span></div>\n<div><span style=\"\">– </span><strong style=\"\">Product:</strong><span style=\"\"> helping our outcome-oriented product team to set their goals, evaluate the delivered value, improve user satisfaction, reduce churn, improve usage and upsell.</span></div>\n<div><span style=\"\"> </span></div>\n<div><span style=\"\">You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth.</span></div>\n<div> </div>\n<div><span style=\"\">You’re a master communicator who wants broad technical and business exposure. You’ll help to enable our business teams, our most important stakeholders, to understand and satisfy their own needs through analytics. In turn, this will help support our customers and their growing set of needs, and thus help us to grow and run our business. Your fresh ideas will be warmly welcomed.</span></div>\n<div> </div>\n<div><strong style=\"\">Are you the one? 🧠</strong></div>\n<div>– 3+ years of experience as a data analyst, analytics engineer or data engineer, mastery of data libraries</div>\n<div>– Coding (Python; SQL)</div>\n<div>– Customer data (dbt)</div>\n<div>– Leadership (rapid and autonomous assumption of new topics or tools among many teams in a new frontier)</div>\n<div>– Communication (understanding and reflection of business initiatives, including transforming needs into insights)</div>\n<div>– Data visualisation (analysis, synthesis, critical thinking, presentation, storytelling)</div>\n<div> </div>\n<div>It would be super cool (but not required) if you had experience with SaaS solutions like Segment, Amplitude, Hubspot, Google Tag Manager, and also AWS Services like Athena, Step Functions or even Lambda.</div>\n<div>If you have a tester’s mindset, all the better. A dream candidate would be a strong contributor and have all of these.</div>\n<div><strong style=\"\">What are the perks? 🎉</strong></div>\n<div>– Latest Macbook;</div>\n<div>– A budget for you to equip your home-office setup;</div>\n<div>– English classes for all levels;</div>\n<div>– Solving challenging problems, while building cutting-edge technology;</div>\n<div>– Working in a super culturally-diverse team, with fun and curious folks.</div>\n<div>(also other benefits, that may depend on the country you’re based in)</div>\n<div> </div>\n<div>When you come to the office, indulge!</div>\n<div>– Healthy snacks and drinks;</div>\n<div>– Yoga classes 3x/week.</div>\n<div> </div>\n<div><strong style=\"\">Afraid of missing out if you’re remote? 🌍  Worry not!</strong></div>\n<div>You get the chance to visit us every once in a while and spend some days at the office, in Paris;</div>\n<div>We have virtual initiatives and events, for us to stay connected with each other and be able to have the precious water-cooler conversation.</div>\n<div>We also have regular global meetings, where every team member is free to raise their hand and discuss any topic with the whole company - we do our best to nurture a relaxed and informal atmosphere, where you can have the conditions to feel supported, thrive at your job and keep learning.</div>\n<div>So, no matter where you are, it’s important for us to make you a part of that culture.</div>\n<img src=\"https://remotive.com/job/track/1498734/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1496602,"url":"https://remotive.com/remote-jobs/data/sr-azure-data-engineer-1496602","title":"Sr. Azure Data Engineer","company_name":"AETOS","company_logo":"https://remotive.com/job/1496602/logo","category":"Data","tags":["azure","cloud","machine learning","microsoft","sql","management","design","agile","project management","factory","Engineering","documentation","analytics","data","Enterprise","tableau","software development","business","data visualization","warehouse","development","reporting","IT","implementation","learning","data management","testing","computer science","Azure Data Lake","cloud native","information technology","architecture ","software","data migration"],"job_type":"contract","publication_date":"2022-11-28T13:39:59","candidate_required_location":"USA","salary":"","description":"<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>AETOS LLC is a Minority Owned CVE Certified Service Disabled Veteran Owned Small Business (SDVOSB) providing information technology solutions focused on building a business that is customer-centered and performance-oriented. At Aetos, we specialize in developing IT solutions to optimize functionality and efficiencies for government and commercial clients to meet their business needs.</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p>Our ideal candidate will have a proven track record in leading and delivering Azure Data Analytics solutions with Enterprise level organizations. We are seeking someone who can enable advance analytic capabilities preparing a data lake by ingesting raw data from authoritative sources using defined patterns and curating the same to publish data products, using cloud native tools. You will be highly proficient working with business stakeholders and directing project teams and will have direct experience of a range of BI Tools and Platforms.</p>\n<p>Candidate will have at least 2 years of Azure experience and a minimum of 7 years’ total experience. A proven track record designing &amp; developing enterprise level data platforms. You will manage your own as well as others’ performance to deliver high quality, highly performant solutions to our customer.</p>\n<p>You will be responsible for the design of solutions which will include:</p>\n<ul>\n<li>Solution design using Microsoft Azure services and related tools.</li>\n<li>Design of enterprise data models and Data solutions.</li>\n<li>Specification of ELT (Extract, load and transform) pipelines, data integration and data migration design, with low code no code tools.</li>\n<li>Design &amp; implementation of Master data management solutions.</li>\n<li>Specification of Data Quality Management methodology and supporting technology tools.</li>\n<li>Working within a project management/agile delivery methodology in a leading role as part of a wider team.</li>\n<li>Deal with other stakeholders/end users in the software development lifecycle – PMs, BAs, testing etc.</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p>Required Skills and Experience</p>\n<ul>\n<li>Bachelor's Degree in computer science, or other engineering or technical discipline is required.</li>\n<li>10 years of experience</li>\n<li>Direct experience of solution shaping and architecture development during planning &amp; delivery including excellent documentation skills.</li>\n<li>Strong evidence of Data modeling, mapping data flows and data design.</li>\n<li>ELT experience.</li>\n<li>Hands-on experience solutioning and implementing analytical capabilities using the Azure Data Analytics platform including, Azure Data Factory, Azure Logic Apps, Azure Functions, Azure Storage, Azure SQL Data Warehouse/Synapse, Azure Data Lake.</li>\n<li>Experience in the design of reporting &amp; data visualization solutions such as Power BI or Tableau.</li>\n<li>Experience with Master Data Management &amp; Data Quality tools.</li>\n<li>Experience designing and implementing machine learning solutions as part of high-volume data ingestion and transformation pipelines.</li>\n<li>Microsoft Azure Data Platform certification ideal (DP-200, DP201)</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<p>All your information will be kept confidential according to EEO guidelines.</p>\n<img src=\"https://remotive.com/job/track/1496602/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1498121,"url":"https://remotive.com/remote-jobs/data/data-engineer-python-1498121","title":"Data Engineer (Python)","company_name":"Whiz LATAM","company_logo":"https://remotive.com/job/1498121/logo","category":"Data","tags":["api","cloud","docker","elasticsearch","git","kubernetes","php","python","react","stats","ui","http","programming","CI/CD","rest","data","flask","JS","Redis","web","business","infrastructure","NLP","angular ","Snowflake","development","debugging","APIs","writing","REST APIs","grafana","OpenShift","Orchestrator "],"job_type":"full_time","publication_date":"2022-11-28T05:39:43","candidate_required_location":"Colombia","salary":"","description":"<p>We are looking for a Senior Data Engineer with experience working with complex systems, managing and deploying. Expert level Python programming and debugging skills. Familiarity with REST APIs, Cloud Infrastructure, CI/CD, Git. familiarity with UI development, frameworks (React/Angular, Flask, PHP, JS, etc.).</p>\n<p><strong>Skills required to contribute:</strong></p>\n<p><strong>Primary Skills :</strong></p>\n<ul>\n<li>Python (for writing business logic),</li>\n<li>Flask (API framework behind mind meld) ,</li>\n<li>AIO http (Python based async web framework),</li>\n<li>OpenShift CAE (Red hat-based Kubernetes platform),</li>\n<li>Redis (for Caching), Snowflake (for storing data),</li>\n</ul>\n<p><strong>Secondary Skills :</strong></p>\n<ul>\n<li>RASA (NLP framework),</li>\n<li>Docker (container orchestrator),</li>\n<li>Elasticsearch (for telemetry),</li>\n<li>Grafana (for displaying stats),</li>\n<li>Prometheus (for monitoring services)</li>\n<li>Experience - 4 + Years in relevant technologies.</li>\n</ul>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1498121/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1497351,"url":"https://remotive.com/remote-jobs/data/military-analytics-quantitative-analyst-1497351","title":"Military Analytics - Quantitative Analyst","company_name":"Fors Marsh","company_logo":"https://remotive.com/job/1497351/logo","category":"Data","tags":["analyst","excel","microsoft","security","strategy","research","community","market research","analytics","data analysis","communications","data","people","partnerships","technical support","culture","development","reporting","IT","R","writing","microsoft office","organization","computer science","statistics","support","diversity","programs","software","training"],"job_type":"full_time","publication_date":"2022-11-26T15:39:50","candidate_required_location":"USA","salary":"","description":"<p>At Fors Marsh, we combine the power of science and strategy to improve people's lives. Each day, we work with institutions and organizations that seek to disrupt markets, understand and influence behavior, drive action on a national scale, and create positive impact. Our approach extends far beyond our client portfolio—as a certified B Corporation and a 2020 Greenbook Top 50 Market Research Company, we make a difference in our community through corporate-sponsored employee volunteer programs and pro bono partnerships with values-aligned nonprofits. Most importantly, as a 2019-2022 Top Workplace, we are committed to putting people first and foster a culture that reflects that commitment. We are proud to be an equal opportunity employer, and we celebrate diversity and inclusivity as the foundation of a healthy, successful, and innovative work environment. Join us, and together we can work to ensure a better tomorrow.<br></p>\n<p>Fors Marsh is seeking an intelligent and motivated early career researcher needed to work as part of our Military Analytics research team.  <em>Our Military Analytics team bridges the gap between traditional social science and data science, leveraging innovative analytic tools for research committed to improving the health and well-being of Service members and DoD personnel.</em> This individual's primary responsibility will be conducting and reporting upon analyses of survey, behavioral/archival, and geographic data. This job is best suited for someone who enjoys integrating and analyzing data, synthesizing market research into actionable recommendations, and who is comfortable working collaboratively with team members and clients. </p>\n<p><strong><em>Responsibilities include:</em></strong></p>\n<ul>\n<li>Analyzing market research data,      including data from large-scale tracking surveys as well as geographic, behavioral,      and administrative data. </li>\n<li>Supporting all aspects of      the research process, including survey creation, data cleaning, data      analysis, and reporting.</li>\n<li>Conducting market      segmentation analyses and evaluating drivers of attitudes and behaviors. </li>\n<li>Working      to aggregate, organize, and explore large, complex quantitative data sets      through a variety of techniques.</li>\n<li>Analyzing      data and interpreting results from descriptive and inferential analyses to      identify patterns and solutions. </li>\n<li>Writing written reports and      professional briefings that summarize research findings to non-technical      audiences.</li>\n<li>Providing technical- and      non-technical support to project teams </li>\n<li>Upholding the highest      standards of quality control for yourself and others.</li>\n</ul>\n<p><strong><em>Qualifications: </em></strong></p>\n<ul>\n<li>Bachelor's degree in social      science, statistics, economics, computer science, humanities or a related      field.  </li>\n<li>Strong verbal and written      communications skills.</li>\n<li>Ability to work effectively      independently, and as a team member.</li>\n<li>Moderate level of      proficiency in at least one statistical analysis software package (R      and/or Stata preferred), including syntax-based analyses and data      manipulation (e.g., collapsing, merging).</li>\n<li>Experience working      with existing datasets and integrating from multiple sources</li>\n<li>Proficiency with Microsoft Office®      products (e.g., Word, PowerPoint, and Excel®)</li>\n<li>Strong quantitative ability      and a keen eye for detail and accuracy.</li>\n<li>Applicants may be subject to      a low-level government security investigation and must meet eligibility      criteria for access to sensitive information.</li>\n<li>US Citizenship Required</li>\n</ul>\n<p><strong><em></em></strong></p><p><strong>We Offer:</strong></p>\n<ul><li>Ability to make an impact on people's lives, both internal and external to the organization.</li><li>Top-tier health, dental, vision, and long and short-term disability coverage all covered at 100% for employee coverage.</li><li>Remote work.</li><li>Our company culture, which values balance and allows each employee to take leave as they require it to balance the responsibilities of both their work and home lives without worrying about depleting their available leave hours. </li><li>We provide a floating holiday bank so you can celebrate the days you value.</li><li>Generous matching retirement contributions and no vesting period starting the third month of employment.</li><li>Dedicated training and development budgets to expand your expertise and grow your skill set.</li><li>You can volunteer your way with paid time off.</li><li>You can participate in Fors Marsh staff-led affinity groups.</li></ul><ul><li>\n</li></ul>\n<img src=\"https://remotive.com/job/track/1497351/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1497204,"url":"https://remotive.com/remote-jobs/data/data-science-engineer-1497204","title":"Data Science Engineer","company_name":"Wurl","company_logo":"https://remotive.com/job/1497204/logo","category":"Data","tags":["AWS","cloud","data science","git","machine learning","marketing","mobile","python","saas","sql","video","growth","design","programming","databases","content","B2B","Engineering","product","advertising","knowledge","TensorFlow","data","spark","creative","tableau","infrastructure","tax","data visualization","data engineering","Snowflake","culture","data pipelines","IT","streaming","learning","serverless","organization","networks","testing","computer science","communication","statistics","support","production","Pytorch","mental health","software"],"job_type":"full_time","publication_date":"2022-11-25T19:39:28","candidate_required_location":"USA","salary":"","description":"<p><strong>About Wurl, LLC.</strong></p>\n<p>Wurl is a global streaming network. Our B2B services provide streamers, content companies, and advertisers with a powerful, integrated network to distribute and monetize streaming television reaching hundreds of million of connected televisions in over 50 countries.  This year Wurl was acquired by AppLovin (Nasdaq: APP), an industry-leading mobile marketing ad tech company, bringing together the technology and innovation of the mobile and television industries.  With the merger, Wurl employees enjoy the best of both worlds: the dynamic environment of a 160+ person start-up and the stability of a high-growth public tech company.  </p>\n<p>Wurl is a fully-remote company that has been recognized for the second year in a row as a <a href=\"%22https:/fortune.com/best-small-workplaces-bay-area/2022/wurl/%22\" rel=\"nofollow\">Great Place to Work</a>.  Wurl invests in providing a culture that fosters passion, drives excellence, and encourages collaboration to drive innovation. We hire the world’s best to build a bunch of cool stuff on an interface fully integrated with their own from streaming, advertising and software technology to continue to help us disrupt the way the world watches television. </p>\n<p> </p>\n<p><strong>Data Science Engineer </strong></p>\n<p>Wurl is seeking a Data Engineer with knowledge of data science. For this role, you will design and implement technical solutions from the ground up for our Data Science platform. Wurl collects data from a range of OTT video streaming ecosystem components. We digest it, analyze it, and build a wide range of Data Science pipelines to support our products. The Data Science engineer reports to the manager of the Data Science team and interacts with Product, Solution Architects, data engineering, and various other functions across the organization.</p>\n<p><strong>What You'll Do</strong></p>\n<ul>\n<li>Work alongside Data Scientists for building duplicatable and high-scale Data Science pipelines</li>\n<li>Collaborate with the data engineering and ML teams to construct data pipelines to implement machine learning models into Wurl’s production framework</li>\n<li>Build highly secured, scalable, and reliable cloud-native pipelines that run 24x7</li>\n<li>Write complex SQL queries with the objective of minimizing the processing effort and time of the data science team’s data pipelines</li>\n<li>Collaborate with the data science team to build data models and prediction models </li>\n<li>Create probability, statistics, predictive modeling, machine learning, or other quantitative methodologies to solve real-world TV delivery and advertisement problems</li>\n</ul>\n<p><strong>Qualifications</strong></p>\n<ul>\n<li>Master’s degree in Computer Science, Mathematics, Physics or related field plus 4 years of relevant experience </li>\n<li>Expert programming skills with Python and SQL </li>\n<li>Expertise in Spark/PySpark </li>\n<li>Experience with SaaS offerings: AWS preferred. Containerization, serverless processes, microservice architectures, etc. </li>\n<li>Strong mathematical background and knowledge including but not limited to statistics, predictive modeling, linear algebra, machine learning </li>\n<li>Experience building ML models using frameworks such as TensorFlow, PyTorch, SparkML, scikit-learn</li>\n<li>Knowledge of Snowflake, Databricks, Git, and  MLFlow</li>\n<li>Understanding of complex networks (mathematical structures)</li>\n<li>Data pre-processing, visualization, and data cleansing experience </li>\n<li>Experience dealing with big datasets and databases </li>\n<li>Effective communication skills </li>\n<li>Works well in a team and independently </li>\n<li>Soft skills: creative, innovative, open to receiving and giving constructive criticism, open to discussions, trustworthy and reliable </li>\n<li>Proven record of being an outstanding problem-solver </li>\n</ul>\n<p><em>A Plus if You Have</em></p>\n<ul>\n<li>\n<ul>\n<li>Advanced proficiency with data visualization tools (such as Tableau, Power BI, Domo) </li>\n<li>Streaming video delivery experience and video formats</li>\n<li>Advertising infrastructure experience</li>\n</ul>\n</li>\n</ul>\n<p><strong>What We Offer</strong></p>\n<ul>\n<li>Competitive Salary</li>\n<li>Strong Medical, Dental and Vision Benefits, 90% paid by Wurl </li>\n<li>Remote First Policy </li>\n<li>Flexible Time Off </li>\n<li>12 US Holidays </li>\n<li>401(k) Matching</li>\n<li>Pre-Tax Savings Plans, HSA &amp; FSA</li>\n<li>Ginger, Aaptiv and Headspace Subscriptions for Mental and Physical Wellness</li>\n<li>OneMedical Subscription for 24/7 Convenient Medical Care</li>\n<li>Paid Maternity and Parental Leave for All Family Additions</li>\n<li>Discounted PetPlan </li>\n<li>Easy at Home Access to Covid Testing with empowerDX </li>\n<li>$1k Work From Home Stipend to Set Up Your Home Office </li>\n</ul>\n<p> </p>\n<p>Few companies allow you to thrive like you will at Wurl. You will have the opportunity to collaborate with the industry’s brightest minds and most innovative thinkers. You will enjoy ongoing mentorship, team collaboration and you will understand what we mean by ‘human connection”.  You will be proud to say you're a part of the company revolutionizing TV.</p>\n<p>At Wurl, we value work-life harmony and believe that family and mental health should always come first.  Our team is fiercely passionate and contagiously enthusiastic about what we are building.  While we are seeking those who know our industry, there is no perfect candidate and we want to encourage you to apply even if you do not meet all requirements. </p>\n<img src=\"https://remotive.com/job/track/1497204/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1498921,"url":"https://remotive.com/remote-jobs/data/data-analyst-1498921","title":"Data Analyst","company_name":"Health IQ","company_logo":"https://remotive.com/job/1498921/logo","category":"Data","tags":["analyst","big data","data science","excel","finance","legal","marketing","sales","sql","growth","operations","strategy","Engineering","customer experience","analytics","languages","knowledge","data","business","data visualization","STEM","leadership","SDLC","culture","metrics","development","reporting","startup","IT","R","coding","presentations","support","insurance","interaction","programs"],"job_type":"full_time","publication_date":"2022-11-25T13:40:25","candidate_required_location":"USA","salary":"","description":"<div class='\"content-intro\"'>\n<p>At Health IQ, our vision is to ensure that the 1.5B seniors live their golden years better than the previous generations. We believe in rewarding the health conscious through savings, literacy, and educational tools.</p>\n<p>We are a diverse and innovative group of individuals who thrive on big data and proven results. Our approach has enabled us to grow from roughly 200 to 900+ employees over the last year and we expect continued growth and opportunities. If you believe that being health conscious can improve lives and want to make a tangible difference through your work, then you’ll love what we’re doing at Health IQ – apply and join the team!</p>\n</div>\n<p><strong>Medicare Advantage Data Analyst</strong></p>\n<p>Health IQ is seeking out a data analyst to empower informed decision making around our Medicare Advantage business strategy.  Reporting to the Lead Medicare Actuary, this role will involve analytical work and model building to turn data into stories and actionable business recommendations.  If you are a high performer with a blend of technical skills and critical thinking looking for a fast-paced, high-growth opportunity, then this is for you!</p>\n<p><strong>What you will be doing:</strong></p>\n<p>Understanding the drivers around why a Medicare Advantage customer may be unhappy with their plan is a Trillion dollar question.  This role will leverage Health IQ’s unique data assets to build models and dashboards to become an expert in answering this question at a deeper level than exists today. </p>\n<p>The first step is to build a strong foundation around our customer persistency &amp; satisfaction metrics by developing dashboards to study patterns.  Use your curiosity to ask what drove the results and utilize your analytical skills to answer those questions.  Once you have developed a foundation, deep dive into the data to understand underlying root causes that would result in a customer leaving a plan.  Use these newly gained insights to develop models to predict future performance and share ideas to positively impact our business outcomes throughout the customer lifecycle.</p>\n<p><strong>Essential Duties and Responsibilities</strong></p>\n<ul>\n<li>Utilize Health IQ’s unique data to support feature engineering to identify new factors that influence a consumer’s decision to leave vs stay with a Medicare Advantage plan.  This will include working with data from our Precision Medicare plan recommendation algorithms, health records, sales funnel metrics and other unique data sets.  </li>\n<li>Develop, own and maintain our dashboards and models around persistency and customer satisfaction.  Proactively develop new dashboards to ensure we have proper insights to drive strategic decisions.</li>\n<li>Enhance customer lifetime value models by adding unique factors that more accurately predict persistency.  Develop reports that compare actual to expected results over time.  </li>\n<li>Receive policy status data from insurance carriers and our finance team.  Cleanse data and perform quality checks prior to feeding into models.</li>\n<li>Develop models to understand agent level value creation, taking into account sales funnel data and customer persistency to develop a holistic view of an agent’s contribution to company success.</li>\n<li>Provide data visualization support and ideas for the development of presentations to inform senior leadership, pitch ideas and influence strategy inside and outside the company.  There will be regular opportunities for you to provide thought leadership to influence business strategy to company executives.</li>\n<li>Work closely with Health IQ’s President &amp; Chief Business Officer, Chief Actuary, Chief Medical Director, and SVP of Medicare  with a unique opportunity to build business acum from senior executives.</li>\n<li>You will have regular Interaction with all areas that influence the customer experience and track data including sales agents, marketing, engineering, operations, data science, legal, and finance.  It will be essential for you to have a pulse on their feedback to add qualitative insights to better understand your quantitative analysis.</li>\n</ul>\n<p><strong>What we’re looking for:</strong></p>\n<ul>\n<li>2+ years of experience in a data analytics, actuarial, financial analyst or similar role.  Experience in Medicare  is a plus.</li>\n<li>A curious mindset and motivated to learn new topics on the fly.</li>\n<li>Strong background in working with analytics and model building in Excel. </li>\n<li>Experience with coding languages such as SQL, R, </li>\n<li>Building out code libraries, following SDLC standards</li>\n<li>Knowledge of data gathering, cleaning, transforming, and visualization techniques.</li>\n<li>Comfortable juggling multiple tasks/deadlines simultaneously.</li>\n<li>Self-motivator with good judgment and a strong focus on details who wants to develop their strategic thinking.</li>\n<li>Able to work successfully both independently and collaboratively in a team environment.</li>\n<li>Takes ownerships of deliverables to see them to completion with high quality; not afraid to ask questions for clarification and guidance when needed.</li>\n<li>Well organized with good habits to document workflow.</li>\n<li>Excited to work in a fast paced, high growth startup environment.</li>\n</ul>\n<p>Health IQ can not sponsor work visas, including OPT STEM at this time.</p>\n<p>#LI-REMOTE</p>\n<div class='\"content-conclusion\"'>\n<p>To make the world a healthier place, we started in our backyard. We created a health-conscious environment that allows each of our employees to reach their personal health goals. Below are a few of the employee-led programs that make working at Health IQ truly unique. </p>\n<ul>\n<li><strong>Career Growth</strong></li>\n</ul>\n<p>As a rapidly growing company, new opportunities for growth and development continue to become available. We believe in promoting from within, and look to reward high performing employees with new opportunities. </p>\n<ul>\n<li><strong>Celebration</strong></li>\n</ul>\n<p>We believe the key is to celebrate those who have improved their health rather than cajole those who haven’t. We look for employees who take this positive and optimistic view in their work lives.</p>\n<ul>\n<li><strong>Service to Seniors</strong></li>\n</ul>\n<p>Our whole mission and vision is to serve seniors to improve their health. We want employees who believe true happiness comes from being in service to others. We call these employees Health Heroes.</p>\n<ul>\n<li><strong>Personal Responsibility</strong></li>\n</ul>\n<p>We believe that only you can make the decision to improve your own health and no one else can do this for you. We look for employees that tend to do the same. </p>\n<ul>\n<li><strong>Excellent benefits</strong></li>\n</ul>\n<p>Competitive rates for our employees' costs toward medical, dental and vision insurance. We offer a 401K, and pay 100% of your life insurance benefit option! We also offer various Flexible Spending Account (FSA) benefits to meet you and/or your families needs. Only full-time employees are eligible for benefits.</p>\n<ul>\n<li><strong>Join a Remote-first Culture</strong></li>\n</ul>\n<p>Our flexible, totally remote environment allows us to hire top talent throughout the U.S. The world has changed, and we’ve learned that being in an office is no longer the best way for our employees and our company to thrive.</p>\n</div>\n<img src=\"https://remotive.com/job/track/1498921/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1498727,"url":"https://remotive.com/remote-jobs/data/data-manager-1498727","title":"Data Manager","company_name":"Makeship","company_logo":"https://remotive.com/job/1498727/logo","category":"Data","tags":["api","AWS","cloud","docker","kafka","kubernetes","marketing","postgresql","security","shopify","growth","design","databases","content","strategy","Engineering","community","product","analytics","google analytics","data","gaming","creative","business","infrastructure","ETL","privacy","people","data engineering","KPIs","culture","architect","data pipelines","development","APIs","reporting","startup","IT","content creation","hubspot","learning","organization","communication","cloud native","revenue","architecture ","relational databases","production","facebook","mental health","BigQuery"],"job_type":"full_time","publication_date":"2022-11-24T23:39:23","candidate_required_location":"Canada","salary":"","description":"<div class=\"h3\">About the Company</div>\n<p>Makeship exists to empower influencers, creators, and brands of all sizes to develop and launch limited edition products that matter to their fans. Leveraging our design, manufacturing, and marketing expertise, we work with our partners to bring their product to life through our community-powered crowd-funding platform. Each product is given a window of 21 days to be funded by the community before we produce and ship to fans worldwide. We put our brand behind every product and guarantee quality and ethical sourcing. We're profitable, have grown the team from 2 to 70 people in 4 years, and we’re growing at an average annual growth rate of 200%+.</p>\n<div class=\"h3\">About the Role</div>\n<p>As an early member of the Data Team, you’ll play a huge role developing a scalable data strategy and building the team that executes it. Data is one of our most important assets, and your team will enable better decision-making for all teams across the company. Every day, you’ll collaborate cross-functionally, learn more about the content creation space, and watch your work make a measurable impact.</p>\n<p>We want this to be the best work experience of your life, so we’ll pay you well, offer great benefits, and invest deeply in your personal growth.</p>\n<div class=\"h3\">Why this Role?</div>\n<ol>\n<li><strong>Have a massive impact on the company.</strong> As the head of our data team, there will be plenty of opportunity for you to lead and implement technical projects. Your contributions will be felt right away, and will affect how we store and interpret data for years to come!</li>\n<li><strong>Develop and architect significant changes.</strong> You will have the freedom to be creative and architect/develop data solutions for business problems. This will challenge you to think about your design and bring your own ideas to life.</li>\n<li><strong>Join us at an epic time.</strong> We’re a profitable and growing startup with millions in revenue. We’ve bootstrapped the company from 2 to 70 employees in 4 years. Join us and experience exponential personal and career growth!</li>\n</ol>\n<div class=\"h3\">So, what will you do at Makeship as a Data Manager?</div>\n<ul>\n<li>Lead a team responsible for data engineering and analysis for key business problems</li>\n<li>Create quarterly plans and operationalize them in lean sprints for the data team</li>\n<li>Examine existing pools of data to identify gaps and opportunities, and propose changes</li>\n<li>Identify risks to data privacy and security and implement processes to prevent breach or loss</li>\n<li>Develop company wide data strategy and architecture to keep up with Makeship’s growth</li>\n<li>Foster a culture of data-curious decision-making across our growing organization</li>\n<li>Collaborate with Product, Engineering, and other departments from prototype to production</li>\n<li>Implement frameworks and processes to ensure data pipelines and reporting are accurate</li>\n<li>Break down complex analyses into digestible insights for founders and executives</li>\n</ul>\n<div class=\"h3\">This might be for you if you have…</div>\n<ul>\n<li>At least 3 years of relevant work experience in data engineering and/or analysis</li>\n<li>At least 2 years of managing teams that report directly to you</li>\n<li>Strong business and technical intuitions, with an ability to quickly learn new technologies</li>\n<li>An ability to break down complex questions into a clear methodology</li>\n<li>Ample experience with KPIs and reporting to executive stakeholders</li>\n<li>Interest in the content creation space: art, animation, gaming, and entertainment!</li>\n<li>Proven experience in building databases, warehouses, pipelines, visualizations, and/or ETL</li>\n<li>A strong understanding of relational databases, data storage, and data manipulation</li>\n<li>A strong ability wrangle data and find answers complex real-world questions</li>\n<li>Experience with cloud native infrastructure (AWS, Docker, Kubernetes, etc.)</li>\n<li>Experience with BI tools like Google Data Studio, Power BI, etc</li>\n<li>Excellent communication with both technical and non-technical stakeholders</li>\n<li>An ability to gather information and requirements yourself, in a fast-paced environment</li>\n</ul>\n<div class=\"h3\">Bonus points if you have....</div>\n<ul>\n<li>Worked in a fast-paced startup or similar environment</li>\n<li>API expertise for Google Analytics, Facebook, Twitter, etc.</li>\n<li>Worked with data from Shopify, Hubspot, or Airtable APIs.</li>\n<li>Experience with our technology stack (PostgreSQL, BigQuery, Kafka, AWS, GCS)</li>\n<li>Prior experience building and scaling ML solutions</li>\n</ul>\n<div class=\"h3\">Benefits &amp; Perks</div>\n<ul>\n<li>Work remotely anywhere in Canada and/or access any of our hubs</li>\n<li>Health and dental benefits 100% employer-paid</li>\n<li>3 weeks of paid vacation</li>\n<li>1 week of paid time off during the holidays</li>\n<li>2 mental health and wellness days</li>\n<li>Paid time off on your birthday</li>\n<li>Monthly phone allowance</li>\n<li>$400 home office setup allowance</li>\n<li>Pregnancy and parental leave top-up program</li>\n<li>Learning and development opportunities</li>\n<li>Employee referral program</li>\n</ul>\n<p>Makeship is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.</p>\n<img src=\"https://remotive.com/job/track/1498727/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1497459,"url":"https://remotive.com/remote-jobs/data/web-analytics-specialist-1497459","title":"Web Analytics Specialist","company_name":"Elevar","company_logo":"https://remotive.com/job/1497459/logo","category":"Data","tags":["ecommerce","sales","shopify","growth","management","documentation","product","analytics","knowledge","google analytics","data","troubleshooting","web","business","account management","onboarding","culture","development","reporting","startup","web analytics","IT","implementation","learning","organization","communication","support","insurance","server","training"],"job_type":"full_time","publication_date":"2022-11-24T11:39:32","candidate_required_location":"USA","salary":"","description":"<p>Elevar is used daily by thousands of Shopify brands all across the world to help ensure they have an accurate data foundation they can trust and scale their business with. We simplify the complex world of tagging and event tracking.</p><p>A Web Analytics Specialist at Elevar is expected to learn on the fly with new solutions that Elevar delivers, adapt to changes in our industry (like iOS14 and server side tagging!), and help maintain our expertise in onsite tagging and data collection. Your ideas and expertise are critical in our growth!</p><p>The person who fills this role should enjoy working with Google Analytics, Google Tag Manager and of course - data. You will be responsible for tagging implementation projects, onboarding new customers to Elevar, troubleshooting complex tracking issues, and ensuring customers are maximizing their value out of Elevar.</p><p><strong>Why Work Here?</strong></p><ul> <li>We’re a young, ambitious company who prides ourselves on learning and solving complex challenges in the world of data collection</li> <li>You want to learn new skills and have a voice in our product roadmap</li> <li>Opportunity to have a big impact on our growth (we've more than 2x'd every year since 2019) and advanced your career (opportunities to grow vertically in your expertise or across other roles in company)</li> <li>Transparent and open organization</li> <li>Since you work so hard, no questions asked unlimited PTO for mental breaks and relaxation</li> <li>We promote a flexible work culture for everyone, including the option to pick the time that work best for you</li> </ul><p><strong>Our Company Values</strong></p><ul> <li>Accountability: Being accountable to our customers, teammates, and ourselves is part of the core of Elevar.</li> <li>Detail Oriented: Careless mistakes and rushed oversight can be expensive. Measure twice, cut once.</li> <li>Positive Energy: We believe in making our work fun and being a lighthouse of positive energy for customers.</li> <li>Healthy Life: If health is exercising, reading, spending time with family, or traveling - make time for it. Unplug and recharge. Stay balanced.</li> <li>Keep it Real: We believe keeping it real is the best way to communicate. Express your feelings, respectfully.</li> <li>GSD: Our work is our pride. Getting stuff done is progress in the face of perfection.</li> </ul><p><strong>What To Expect:</strong></p><ul> <li>70% acting as a web analytics specialist on a dedicated team overseeing the onboarding, implementation, and ongoing support of Elevar for an assigned set of customers.</li> <li>20% expanding your analytics skills, tracking knowledge, and Elevar product expertise, and then implementing these solutions across customers.</li> <li>10% helping with our self-serve customer base tagging questions, and being a mentor to the support team by helping with internal training and documentation</li> </ul><p><strong>Requirements</strong></p><ul> <li>Own the relationship of an assigned set of customers as part of your core team of specialists, and be the primary point of contact and voice within Elevar for analytics or tagging requests.</li> <li>Onboarding and activate customers onto Elevar's tracking platform</li> <li>Build and maintain strong, long-lasting relationships with your customers by understanding their tracking goals and pain points in order to deliver solutions that help improve their business.</li> <li>Execute Google Analytics &amp; GTM audits and implement recommended changes across client accounts.</li> <li>Provide backup support and assistance to other analysts.</li> <li>Be ready and excited to learn and expand your knowledge in eCommerce data tracking. Elevar is on the cutting edge of tracking and a leading voice in the industry, and we are looking for someone who is eager to learn from our experienced team.</li> </ul><p><strong>What You'll Need</strong></p><ul> <li>Self-motivated and proactive mindset.</li> <li>3+ years experience in a customer-facing success role (Support, Success, Account Management, or Sales).</li> <li>Exceptional multi-tasking and context-switching capabilities</li> <li>Strong collaboration and communication skills</li> <li>Measurement, reporting, and other data analytics skills</li> <li>Experience working in a startup environment</li> <li>The desire for committing, over-delivering, and following up with customers to make sure they’re successful</li> </ul><p><strong>Benefits</strong></p><ul> <li>Competitive salary, 100% health/dental/vision insurance for US employees, and 401K option</li> <li>Annual company retreat, and other home office perks such as a $2,500 stipend for new employees to use towards their home office that you get to keep</li> <li>We invest in your development with a $1,000 per year professional development stipend for conferences, courses, or anything that may help you grow</li> </ul><img src=\"https://remotive.com/job/track/1497459/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1487021,"url":"https://remotive.com/remote-jobs/data/data-governance-manager-1487021","title":"Data Governance Manager","company_name":"Fastly","company_logo":"https://remotive.com/job/1487021/logo","category":"Data","tags":["cloud","finance","security","open source","management","agile","jira","Engineering","documentation","product","information security","compliance","data","Enterprise","GRC","creative","software development","business","privacy","people","culture","development","IT","implementation","law","organization","applications","confluence","github","communication","data governance","CISSP","support","diversity","audit","risk","insurance","programs","mental health","software"],"job_type":"full_time","publication_date":"2022-11-22T13:40:39","candidate_required_location":"USA","salary":"","description":"<div class='\"content-intro\"'>\n<p>Fastly helps people stay better connected with the things they love. Fastly’s edge cloud platform enables customers to create great digital experiences quickly, securely, and reliably by processing, serving, and securing our customers’ applications as close to their end-users as possible — at the edge of the Internet. The platform is designed to take advantage of the modern internet, to be programmable, and to support agile software development. Fastly’s customers include many of the world’s most prominent companies, including Vimeo, Pinterest, The New York Times, and GitHub.</p>\n<p>We're building a more trustworthy Internet. Come join us.</p>\n</div>\n<p><strong>Data Governance Manager</strong></p>\n<p>We are looking for a Data Governance Manager to help evolve and mature Fastly’s data governance program. In this role, you will partner with stakeholders across the organization to identify our key data assets and promote good data stewardship, helping the company understand and maintain appropriate data protection, privacy, and handling measures. You will empower teams to incorporate data-focused security considerations, regulatory requirements, and customer obligations into their systems and workflows in straightforward, repeatable, auditable ways. </p>\n<p>This position reports to the Senior Director of Compliance within the Security organization. </p>\n<p><strong>What You'll Do</strong></p>\n<ul>\n<li>Build and evolve our enterprise-wide data governance program, spanning data lifecycle management in our customer-facing platform, as well as our internal systems and data stores</li>\n<li>Partner with stakeholders across the business to catalog key data assets and understand how this data traverses our systems, environments, and processes</li>\n<li>Centralize and harmonize data protection, privacy, retention, and handling requirements from Security, Compliance, Law, Finance, Engineering, and other departments into a cohesive data governance framework</li>\n<li>Drive implementation and management of operational aspects of the data governance program, including data protection impact assessments, data mappings, and data considerations in our product documentation</li>\n<li>Develop and publish self-service, playbook, and guidance material to help others more easily meet data governance considerations tied to their job responsibilities</li>\n<li>Facilitate completion of audit procedures and responses to customer inquiries pertaining to data governance and privacy topics</li>\n</ul>\n<p><strong>What We're Looking For</strong></p>\n<ul>\n<li>Several years of relevant work experience in establishing, maintaining, and/or assessing data governance and privacy programs </li>\n<li>Tenured experience supporting data governance programs or needs at a modern cloud service provider or similar organization</li>\n<li>Demonstrated experience building or supporting data governance programs from an early stage of maturity</li>\n<li>Ongoing awareness of industry and regulatory trends in data governance domains, including best practices and tools</li>\n<li>Proven ability to work with technical contacts and interpret technical concepts while establishing or executing data governance processes</li>\n<li>Demonstrated proficiency in prioritizing and completing multiple concurrent projects and tasks</li>\n<li>Strong communication and interpersonal skills, both written and verbal</li>\n</ul>\n<p><strong>We value a variety of voices, so this is not a laundry list. It would be an added bonus if you have experience in ANY of these:</strong></p>\n<ul>\n<li>Data privacy-focused certifications, CIPT in particular, strongly preferred</li>\n<li>Experience with Atlassian products (Confluence, Jira) for managing project work and maintaining process documentation</li>\n<li>Experience using GRC tools to maintain controls documentation mapped to relevant regulations, industry standards, or risk areas</li>\n<li>IT audit or information security certifications (e.g., CISA, CISM, CISSP)</li>\n</ul>\n<p>The estimated salary range for this position is $113,000 to $170,000. Starting salary may vary based on permissible, non-discriminatory factors such as experience, skills, qualifications, and location. This role may be eligible to participate in Fastly’s equity and discretionary bonus programs.</p>\n<p><strong>Benefits</strong></p>\n<p>We care about you. Fastly works hard to create a positive environment for our employees, and we think your life outside of work is important too. We support our teams with great benefits that start on the first day of your employment with Fastly. Curious about our offerings? </p>\n<ul>\n<li>We offer a comprehensive benefits package including medical, dental, and vision insurance. Family planning, mental health support along with Employee Assistance Program, Insurance (Life, Disability, and Accident), company paid holidays, paid time off and paid sick leave are there to help support our employees. We also offer 401(k) (including company match) and an Employee Stock Purchase Program.</li>\n</ul>\n<p>Fastly reserves the right to amend or modify for any reasons in accordance with applicable law.</p>\n<div class='\"content-conclusion\"'>\n<p><strong>Why Fastly?</strong></p>\n<ul>\n<li>\n<p><strong>We have a huge impact.</strong> Fastly is a small company with a big reach. Not only do<a class='\"external-link\"' href=\"%22https:/www.fastly.com/customers%22\" rel=\"nofollow\" target='\"_blank\"'> our customers</a> have a tremendous user base, but we also support a growing number of<a class='\"external-link\"' href=\"%22https:/www.fastly.com/open-source/%22\" rel=\"nofollow\" target='\"_blank\"'> open source projects and initiatives</a>. Outside of code, employees are encouraged to share causes close to their heart with others so we can help lend a supportive hand.</p>\n</li>\n<li>\n<p><strong>We love distributed teams.</strong> Fastly’s home-base is in San Francisco, but we have multiple offices and employees sprinkled around the globe. In fact, 50% of our employees work outside of SF! An international remote culture is in our DNA.</p>\n</li>\n<li>\n<p><strong>We care about you.</strong> Fastly works hard to create a positive environment for our employees, and we think your life outside of work is important too. We support our teams with great benefits like up to 20 weeks of paid parental leave, options for free medical/dental/vision plans, and an open vacation program that enables our folks to take the time they need to recharge (some benefits may vary by location).</p>\n</li>\n<li>\n<p><strong>We value diversity.</strong> Growing and maintaining our inclusive and diverse team matters to us. We are committed to being a company where our employees feel comfortable bringing their authentic selves to work and have the ability to be successful -- every day.</p>\n</li>\n<li>\n<p><strong>We are passionate.</strong> Fastly is chock full of passionate people and we’re not ‘one size fits all’. Fastly employs authors, pilots, skiers, parents (of humans and animals), makeup geeks, coffee connoisseurs, and more. We love employees for who they are and what they are passionate about.</p>\n</li>\n</ul>\n<p>We’re always looking for humble, sharp, and creative folks to join the Fastly team. If you think you might be a fit, please apply!</p>\n<p> </p>\n<p><em>Fastly is committed to ensuring equal employment opportunity and to providing employees with a safe and welcoming work environment free of discrimination and harassment.  </em></p>\n<p><em>Employment decisions at Fastly are based on business needs, job requirements and individual qualifications, without regard to race, color, religion, gender, gender identity, gender expression, sexual orientation, national origin, family or parental status, disability*, age, veteran status, or any other status protected by the laws or regulations in the locations where we operate. Fastly encourages applicants from all backgrounds.</em></p>\n<p><em>*Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. A reasonable accommodation is a change in the way things are normally done which will ensure an equal employment opportunity without imposing undue hardship on Fastly. Please inform us if you need assistance completing any forms or to otherwise participate in the application process.</em></p>\n<p><em>Fastly collects and processes personal data submitted by job applicants in accordance with our<a class='\"external-link\"' href=\"%22https:/www.fastly.com/privacy%22\" rel=\"nofollow\" target='\"_blank\"'> Privacy Policy</a>. Please see our<a class='\"external-link\"' href=\"%22https:/www.fastly.com/privacy-job-applicants%22\" rel=\"nofollow\" target='\"_blank\"'> privacy notice for job applicants</a>.</em></p>\n</div>\n<img src=\"https://remotive.com/job/track/1487021/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1484518,"url":"https://remotive.com/remote-jobs/data/senior-data-engineer-1484518","title":"Senior Data Engineer","company_name":"RevUnit","company_logo":"https://remotive.com/job/1484518/logo","category":"Data","tags":["apache","api","AWS","azure","cloud","devops","docker","machine learning","python","security","sql","management","design","programming","databases","factory","Engineering","analytics","languages","data analysis","knowledge","rest","data","spark","infrastructure","GCP","warehouse","warehousing","leadership","data engineering","culture","SOLID","data pipelines","database","data warehousing","development","IT","R","learning","coding","applications","Azure Data Lake","Apache Spark","data governance","support","architecture "],"job_type":"full_time","publication_date":"2022-11-21T11:40:00","candidate_required_location":"USA","salary":"","description":"<p><strong>Join us in creating better futures through bold decisions. </strong></p>\n<p>We’re a data technology studio that focuses on helping our clients create operational change (faster) with their data. We’ve worked inside some of the world’s largest companies: Walmart, Zappos, Tyson, Chick-fil-A, H-E-B, and many more.</p>\n<p>Our mission of creating better futures isn’t something we just seek for clients, but for ourselves as well. We are proud to be a collective of high-performers that champion necessary change when we see it. We strive to model new (better) ways of working within our own company — taking a people‐first approach to everything we do.</p>\n<p>We’ve been named a Best Place to Work for four years and made Entrepreneur’s list of “Top Company Culture” winners. We’re also proud to have made the Inc. 5000 list of America’s Fastest‐Growing Private Companies for four years in a row (2017, 2018, 2019, 2020).</p>\n<p> </p>\n<div class=\"h3\">About the Role:</div>\n<p>The Sr Data Engineer role requires both great technical skills as well as a consultative and leadership based approach to work and teams. In this role you can expect to be engaged in strategic planning of architecture and systems with an eye for rapid development and performance, as well as demonstrating technical skills while creating well thought out data pipelines and repositories, particularly in the context of warehousing and analytics.</p>\n<p>It is imperative that you have a solid understanding of database architectures, being able to identify technology fit for client solutions. Solid fundamentals in relational and non relational design are critical. You will be working closely with teams having varying levels of experience with data systems, both internal RevUnit teams as well as client teams, and will need to be able to model best practices. Being a good communicator and team player is important to your success in the role.</p>\n<p>You will have opportunities to help support machine learning and be involved in defining and building data pipelines on these projects. Knowledge in this space is not essential, but being interested and willing to learn how your craft fits into the larger picture is. We value folks who are passionate about what they do, are ready to offer a hand when needed, and are happy to share their knowledge with the rest of the team. We are looking for someone who has an interest in creating their own destiny by helping grow our data engineering practice.</p>\n<p> </p>\n<div class=\"h3\">Key Responsibilities:</div>\n<p><em>What you’ll be doing (mostly)</em></p>\n<p> </p>\n<ul>\n<li>Work as an Azure cloud data engineer, an individual contributor, and a team player</li>\n<li>Analyze, design, and determine coding, programming, and integration activities required based on specific objectives</li>\n<li>Manage data pipeline jobs failure issues</li>\n<li>Python jobs via Docker container and optimize it for better performance</li>\n<li>Develop processes, techniques, and tools to analyze and monitor platform performance</li>\n<li>Strong working knowledge in Azure Data Warehouse and Lakehouse formations</li>\n<li>Experience in managing databases and objects</li>\n<li>Experience Azure Data Lake Storage with Azure Synapse</li>\n<li>Develop Azure Data Factory/Synapse pipelines and experience with Azure SQL Pools, Apache Spark</li>\n<li>Identify, troubleshoot and resolve issues related to slow / failed jobs</li>\n<li>Support ingestion pipelines from data engineering standpoint</li>\n<li>Experience with SQL (Queries, Functions, Stored Procedures) and Python languages</li>\n<li>Participation in the design of data models for reports</li>\n<li>Experience with Azure Functions and API integration management</li>\n<li>Support architecture for Azure Event Grid and Hub</li>\n<li>Understanding of Identity Management, Security, Data Governance</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Desire to live into the RevUnit values of: Do what’s right; be fearless; a little better all the time; I’ve got your back, you got mine; and celebrate the wins</li>\n<li>4+ years experience with:\n<ul>\n<li>Data modeling and architecture experience</li>\n<li>Azure Data Factory</li>\n<li>Azure Data Lake (ADLS2) Technologies</li>\n<li>Python, R, or similar technologies</li>\n<li>Cloud platform experience with data on AWS, Azure, or GCP</li>\n<li>Database performance tuning and query optimization</li>\n<li>Data transformation patterns</li>\n<li>Data analysis, discovery,</li>\n<li>Relational and non-relational database principles and design</li>\n</ul>\n</li>\n<li>Understanding of how data engineering fits within DevOps systems and processes</li>\n<li>Demonstrable experience working with cross-functional application engineering teams</li>\n<li>Demonstrable experience working with infrastructure supporting data storage, data warehousing, data for interactive applications , analytics applications, etc.</li>\n<li>Demonstrable experience working on teams and conveying technical topics to both technical and non-technical audiences</li>\n<li>Ability to think one step ahead and act strategically</li>\n<li>A strong aptitude and interest in independent continuous learning, staying up to date on relevant technology, trends and practices.</li>\n</ul>\n<p><strong>Nice to haves:</strong></p>\n<ul>\n<li>GCP certification</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>RevUnit pays 100% of your individual premiums for Medical, Dental, Vision, and both Short and Long-Term Disability</li>\n<li>Basic Life and AD&amp;D</li>\n<li>Health Savings Account (HSA) option</li>\n<li>401k matching program</li>\n<li>Employee Assistance Program (EAP)</li>\n<li>Unlimited paid time off</li>\n<li>8 Paid holidays</li>\n<li>Paid parental leave</li>\n<li>All Hands Meetings (All-Company. 2x per year. Focus on skill development, team building, and celebration.)</li>\n<li>Company laptop, monitor, and accessories</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1484518/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1488794,"url":"https://remotive.com/remote-jobs/data/data-researcher-annotator-healthcare-1488794","title":"Data Researcher & Annotator - Healthcare","company_name":"John Snow Labs","company_logo":"https://remotive.com/job/1488794/logo","category":"Data","tags":["data science","developer","devops","ai","content","research","Engineering","analytics","healthcare","data","Enterprise","spark","NLP","events","release","database","domain","IT","writing","statistics","software"],"job_type":"contract","publication_date":"2022-11-20T01:39:57","candidate_required_location":"USA","salary":"","description":"<br><br><div class=\"h3\">Company Description</div><p>John Snow Labs is an award-winning AI and NLP company, accelerating progress in data science by providing state-of-the-art software, data, and models. Founded in 2015, it helps healthcare and life science companies build, deploy, and operate AI products and services. John Snow Labs is the winner of the 2018 AI Solution Provider of the Year Award, the 2019 AI Platform of the Year Award, the 2019 International Data Science Foundation Technology award, and the 2020 AI Excellence Award.</p><p>John Snow Labs is the developer of Spark NLP - the world’s most widely used NLP library in the enterprise - and is the world’s leading provider of state-of-the-art clinical NLP software, powering some of the world’s largest healthcare &amp; pharma companies. John Snow Labs is a global team of specialists, of which 31% hold a Ph.D. or M.D. and 75% hold at least a Master’s degree in disciplines covering data science, medicine, software engineering, pharmacy, DevOps and SecOps.</p><br><br><div class=\"h3\">Job Description</div><p>We are looking for a US-Based Rockstar data researcher in the healthcare space, who has the clinical and academic background to find &amp; annotate useful data sets. The core aspect of this role is the annotation of clinical notes &amp; other free-text documents - in order to make it easier for software, analytics &amp; data science teams to train natural language processing models.<br><br>Key responsibilities:<br>* Label and annotate clinical notes and other healthcare documents for symptoms, diagnoses, procedures, drugs, allergies, adverse events, vital signs, and lab results<br>* Extract multiple useful data sets from files, publications, and other sources<br>* Write clearly to explain the content, values and schema of each data set<br>* Collaborate with project &amp; release managers to prioritize which data sets to research &amp; annotate<br>* Communicate gaps in annotation guidelines, edge cases, and suggestions for improvement of the data research and annotation project for the whole team.</p><br><br><div class=\"h3\">Qualifications</div><p>Qualifications:<br><br>* Based and located in the United States<br>* Proven healthcare domain expertise - preferably as a clinician, although clinical coders and health data researchers are also welcome to apply<br>* Strong attention to detail and understanding of detail clinical, operational, and financial healthcare concepts<br>* Familiarity with the home health industry is preferred<br>* An advanced degree such as a PhD, MD or similar professional or academic experience is preferred<br>* Concrete &amp; proven experience in data research, in areas such as data curation, database modeling / querying, statistics, data science or academic research.<br>* If you are hired and contribute data to our repository, your name, photo &amp; short bio will appear as a contributor on our website - please do not apply if this is problematic.<br>* A commitment for 40 hours/week is required<br>* Only individual freelancers please - no agencies, teams, or companies<br>* This can potentially be a long-term relationship - we are looking to significantly grow our team - and may grow to include other writing or research assignments.<br>If you are interested, please apply with a cover letter that includes the words \"John Snow Labs\" and explains why you are the right person for this role.</p><br><br><div class=\"h3\">Additional Information</div><ul><li><p>We are a fully virtual company, collaborating across 22 countries</p></li><li><p>Looking for U.S. based applicants on this role.</p></li><li><p>This role requires the availability of at least 30 hours per week. </p></li></ul><img src=\"https://remotive.com/job/track/1488794/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1489929,"url":"https://remotive.com/remote-jobs/data/data-engineer-manager-1489929","title":"Data Engineer Manager","company_name":"Seedtag","company_logo":"https://remotive.com/job/1489929/logo","category":"Data","tags":["ADS","amazon","apache","cloud","devops","kafka","kubernetes","linux","machine learning","mongoDB","python","scala","sql","growth","management","design","databases","content","Engineering","product","languages","advertising","bash","p2p","computer vision","data","spark","web","English","ETL","google cloud","privacy","data engineering","culture","SOLID","events","development","Spanish","writing","learning","fundraising","natural language processing","computer science","communication","statistics","microservices","Digital advertising","support","diversity","production","travel","risk","insurance","interaction","software"],"job_type":"full_time","publication_date":"2022-11-18T09:43:06","candidate_required_location":"Spain","salary":"","description":"<p>We are looking for a talented<strong> Data Engineer Manager</strong> to help us change the world of digital advertising together.</p>\n<p><strong>WHO WE ARE</strong></p>\n<p>At Seedtag our goal is to lead the change in the advertising industry, because we believe that effective advertising should not be at odds with users' privacy.</p>\n<p>By combining Natural Language Processing and Computer Vision our proprietary, Machine Learning-based technology provides a human-like understanding of the content of the web that finds the best context for each ad while providing unparalleled risk-mitigation capabilities that protect advertisers from showing their ads on pages that could be damaging for their brand. All of this, without relying on cookies or any other tracking mechanisms.</p>\n<p>Every day, our teams develop new services that reach over 200 million users worldwide with fast response times to ensure that we deliver the best user experience. We're fully committed to the DevOps culture, where we provide the platform that our Software Developers and Data Scientists use to manage over 100 different microservices, pushing dozens of changes to production every day. All of this is built on top of Kubernetes in Google Cloud Platform and Amazon Web Services.</p>\n<p>If you are interested in joining one of the fastest growing startups in Europe and work on massive scalability challenges, this is the place for you.</p>\n<p><strong>KEY FIGURES</strong></p>\n<p>2014 · Founded by two ex-Googlers</p>\n<p>2018 · 16M total turnover &amp; Internationalization &amp; Getting growth</p>\n<p>2021 · Fundraising round of 40M€ &amp; +10 countries &amp; +250 Seedtaggers</p>\n<p>2022 · Fundraising round of 250M€ + expansion into the U.S market + 400 Seedtagers </p>\n<p><strong>ABOUT YOU</strong></p>\n<p>Your key responsibilities will be:</p>\n<ul>\n<li>To keep the relationship with the team members via 1:1, and performance reviews. Career planification, doubt resolution, conflict management, etc.</li>\n<li>To recruit data engineer expert, both for direct report and for side teams </li>\n<li>To have a perfect vision on the data lake structure at use company-wide.</li>\n<li>To ensure Strategic decision-making: helping the team and stakeholders towards a perfect usage of our data-lake/data-mesh services and connected pipelines.. </li>\n<li>To be in touch with pair Data-Managers and Product-Managers to align Data Engineering priorities and design new features.</li>\n<li>To support the data-vision alignment within the company, cross-relation with other data teams, communication of the progress of the team upon its products.</li>\n<li>To detect and remove team's blockers. Those can be technical blocks (interaction with systems), or management blocks/pain points (lack of control points with other data teams).</li>\n<li>To  develop and deploy production-oriented data software.</li>\n</ul>\n<p>We're looking for someone who:</p>\n<ul>\n<li>Have at least 4 years of solid experience in data Engineering  and at least 2 years in a management role</li>\n<li>Have a degree in computer science, engineering, statistics, mathematics, physics or another degree with a strong quantitative component</li>\n<li>Have ample experience with Data Engineering tools such as Apache Beam, Spark, Flink or Kafka.</li>\n<li>Is comfortable with object-oriented languages, such as Python or Scala, and you are fluent in working with a Linux terminal and writing basic bash scripts.</li>\n<li>have experience orchestrating ETL processes using systems such as Apache Airflow, and managing databases like SQL, Hive or MongoDB.</li>\n<li>Have experience building data-lake and data-mesh infrastructures as a service from scratch</li>\n<li>Know how to scale-up teams and manage projects with different stakeholders.</li>\n</ul>\n<p><strong>WHAT WE OFFER</strong></p>\n<ul>\n<li>Key moment to join Seedtag in terms of growth and opportunities</li>\n<li>High-performance tier salary bands excellent compensation</li>\n<li>One Seedtag: Work for a month from any of our open offices with travel and stay paid if you're a top performer (think of Brazil, Mexico..., </li>\n<li>⛰ An unlimited remote working environment, where you can choose to work from home indefinitely or attend our Madrid headquarters whenever you want, where you will find a great workplace location with food, snacks, great coffee, and much more.</li>\n<li>Paid travels to our HQ in Madrid to work p2p with your squad members</li>\n<li>Macbook Pro M1</li>\n<li>⌛ Flexible schedule to balance work and personal life</li>\n<li>Build your home office with a budget of up to 1K€ (external screen, chair, table...)</li>\n<li>A harassment-free, supportive and safe environment to ensure the healthiest and friendliest professional experience fostering diversity at all levels.</li>\n<li>Optional company-paid English and/or Spanish courses.</li>\n<li>Access to learning opportunities (learning &amp; development budget)</li>\n<li>We love what we do, but we also love having fun. We have many team activities you can join and enjoy with your colleagues! A Yearly offsite with all the company, team offsites, and Christmas events...</li>\n<li>Access to a flexible benefits plan with restaurant, transportation, and kindergarten tickets and discounts on medical insurance</li>\n</ul>\n<p> </p>\n<p> Are you ready to join the Seedtag adventure? Then send us your CV!</p>\n<p> </p>\n<img src=\"https://remotive.com/job/track/1489929/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1488795,"url":"https://remotive.com/remote-jobs/data/healthcare-data-scientist-1488795","title":"Healthcare Data Scientist","company_name":"John Snow Labs","company_logo":"https://remotive.com/job/1488795/logo","category":"Data","tags":["big data","data science","developer","devops","machine learning","python","ai","Engineering","healthcare","data analysis","Bioinformatics","knowledge","deep learning","TensorFlow","data","Enterprise","spark","business","NLP","IT","learning","applications","communication","agency","production","software","training"],"job_type":"contract","publication_date":"2022-11-17T19:39:20","candidate_required_location":"Worldwide","salary":"","description":"<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>John Snow Labs is an award-winning AI and NLP company, accelerating progress in data science by providing state-of-the-art software, data, and models. Founded in 2015, it helps healthcare and life science companies build, deploy, and operate AI products and services. John Snow Labs is the winner of the 2018 AI Solution Provider of the Year Award, the 2019 AI Platform of the Year Award, the 2019 International Data Science Foundation Technology award, and the 2020 AI Excellence Award.</p>\n<p>John Snow Labs is the developer of Spark NLP - the world’s most widely used NLP library in the enterprise - and is the world’s leading provider of state-of-the-art clinical NLP software, powering some of the world’s largest healthcare &amp; pharma companies. John Snow Labs is a global team of specialists, of which 33% hold a Ph.D. or M.D. and 75% hold at least a Master’s degree in disciplines covering data science, medicine, software engineering, pharmacy, DevOps and SecOps.</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p>We are looking for a superstar data scientist, who is familiar and experienced with applying machine learning and deep learning in the area of healthcare. This role requires proven hands-on experience training and optimizing models, building production-ready inference pipelines in Python, performing exploratory data analysis &amp; enrichment, and validating models for issues like bias, overfitting, and concept drift.</p>\n<p>Since we primarily work in healthcare and life science, background in medicine, pharma, bioinformatics, or biostatistics is highly beneficial. A PhD degree in a relevant field is preferred.</p>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p>The primary responsibilities will be working as part of a team in customer-facing projects - building models and machine learning, deep learning, natural language processing, and time series forecasting pipelines that address specific business needs. Working knowledge of Python and TensorFlow are a must; experience with Spark, Spark NLP, and other technology stacks is a big plus. The customer facing aspect of this role also requires strong oral &amp; written communication skills.<br><br>We are looking for experts who are looking for long-term freelancing contracts, and wish to work on cutting-edge problems, learn and grow. This role for individuals who can commit at least 30 hours per week to this project. We are not able to consider agency or team applications.<br><br>This is a career opportunity that will enable you to expand your knowledge and experience of different tools and techniques, work within a team of big data and data science experts, and make a positive impact with your work. If you quality and are interested, please include the words 'John Snow Labs' in your cover letter and explain why you are the best fit for this role.</p>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<ul>\n<li>We are a fully virtual company, collaborating across 26 countries.</li>\n<li>Open to candidates worldwide - work remotely from anywhere.</li>\n<li>This is a contract opportunity, not a full-time employment role.</li>\n<li>This role requires the availability of at least 30 hours per week.</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1488795/blank.gif?source=public_api\" alt=\"\"/>"}]}