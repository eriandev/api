{"job_count":100,"total_pages":10,"jobs_per_page":10,"prev":"https://eriandev.github.io/api/remotive/2","next":"https://eriandev.github.io/api/remotive/4","results":[{"id":1532723,"url":"https://remotive.com/remote-jobs/data/data-integration-engineer-1532723","title":"Data Integration Engineer","company_name":"Boldr","company_logo":"https://remotive.com/job/1532723/logo","category":"Data","tags":["api","consulting","graphql","html","javascript","php","python","sql","management","operations","http","design","programming","product engineering","project management","research","Engineering","product","data analysis","communications","rest","data","postgres","troubleshooting","web","software development","business","ETL","Snowflake","culture","database","development","APIs","JSON","implementation","software engineering","data management","networks","computer science","xml","communication","support","software"],"job_type":"full_time","publication_date":"2023-01-01T19:39:27","candidate_required_location":"Mexico","salary":"","description":"<p>Our client is on a mission to build smart, inspired, and useful products for faculty and academic communities. By building an engine for faculty activity, decisions, and data, they have become the first mover in defining and owning the category of faculty-focused technology that cultivates goal-oriented collaboration around academic decision-making.</p>\n<p>Our client operates the first holistic faculty information system to support the full lifecycle of faculty work, from job seeking to review, tenure, sabbatical, committee work, research, and beyond. Offering colleges and universities increased clarity and insight into faculty data to help achieve their strategic initiatives, they believe that advancing the faculty will advance the institution. They have crafted a fun, collegial, dynamic culture that celebrates team and individual success almost daily. Their lean team of super-smart, super-hard working, local and remote colleagues, collaborate closely to produce a valuable service for an industry they’re passionate about. They genuinely like working with each other and with their clients.</p>\n<p>The Technical Services Data Integration Engineer is a member of our client's Professional Services Team who is responsible for the successful implementation and continued success of their clients. In this role, you will primarily be responsible for managing the ins and outs of complex data-related software and supporting clients’ data-related issues. In addition, you will be helping clients align to, implement, and optimize data management schemes and practices in adherence to their standardized methods. You will also be responsible for assisting with the design and implementation of an ETL solution to standardize, optimize and scale their data ingestion capabilities. As you familiarize yourself with the software you will help to build and expand their ETL solution, interacting with product engineering to help define API use cases and the team’s requirements. There will be continued opportunities to migrate clients from the legacy system to the new tool. As you gain experience, consulting will be a key aspect of this role.</p>\n<ul style=\"\">\n<li style=\"\">Understand and execute complex client data operations and troubleshooting within a PHP application</li>\n<li style=\"\">Help to build a data load system using an ETL platform (Matillion) with existing APIs and new constructs</li>\n<li style=\"\">Work collaboratively with clients to understand, adhere to, and adopt data integration methodologies &amp; formatting</li>\n<li style=\"\">Possess a client-centered mindset around delivery &amp; communications, focused on client delight and success</li>\n<li style=\"\">Implement data extraction &amp; insertion procedures</li>\n<li style=\"\">Work effectively with our internal and external clients to ensure timely delivery of implementation and ongoing tasks</li>\n<li style=\"\">Build and foster strong relationships with all levels of technical and non-technical staff at client institutions</li>\n<li style=\"\">Identify, recognize, and proactively act on opportunities for improvement in order to advance business process goals</li>\n<li style=\"\">Ability to identify challenges, accept and implement change, and quickly adapt to dynamic situations</li>\n<li style=\"\">Possess strong verbal and written communication skills.</li>\n</ul>\n<p> </p>\n<p><strong>Requirements</strong></p>\n<p>Requirements:</p>\n<ul style=\"\">\n<li style=\"\">Bachelor's degree or higher in Computer Science or a related field</li>\n<li style=\"\">Significant experience delivering ETL data load services</li>\n<li style=\"\">2-5 years of professional software development experience</li>\n<li style=\"\">2-5 years of relational database and SQL experience, ideally on Postgres and Snowflake</li>\n<li style=\"\">Advanced programming in any language and associated technologies including Python, SQL, PHP, JSON, HTML, JavaScript, XML, GraphQL</li>\n<li style=\"\">Understanding of fundamental object-oriented software engineering, including data structures and programming constructs</li>\n<li style=\"\">Substantive experience with SAML-based SSO, including various SPs and IDPs</li>\n<li style=\"\">Advanced understanding of internet protocols, networks, APIs, and related technologies: HTTP, REST, and SOAP web services</li>\n</ul>\n<p>Preferred:</p>\n<ul style=\"\">\n<li style=\"\">Excellent customer communication and project management skills</li>\n<li style=\"\">3-5 years of customer-facing experience</li>\n<li style=\"\">Experience building tools for data analysis</li>\n<li style=\"\">ETL platform experience (Matillion preferred), SQL and Python experience</li>\n<li style=\"\">Experience with PHP and connectivity to database</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p>Benefits + Salary</p>\n<img src=\"https://remotive.com/job/track/1532723/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1533071,"url":"https://remotive.com/remote-jobs/data/data-scientist-1533071","title":"Data Scientist","company_name":"CybelAngel","company_logo":"https://remotive.com/job/1533071/logo","category":"Data","tags":["analyst","data science","docker","go","kubernetes","machine learning","music","python","recruiter","security","management","design","programming","databases","project management","Engineering","product","games","knowledge","deployment","data","creative","English","business","terraform","GCP","hiring","people","data engineering","cybersecurity","culture","gitlab","release","development","IT","learning"," team lead","organization","production","software","BigQuery","datadog"],"job_type":"full_time","publication_date":"2023-01-01T01:39:38","candidate_required_location":"Europe","salary":"","description":"<p><strong>Our job everyday is to protect the data and critical assets of businesses world-wide by discovering hidden vulnerabilities… before the bad guys do!</strong></p>\n<p>At <strong>CybelAngel</strong>, we see beyond perimeters to protect businesses from the most critical cybersecurity threats. Fortune 500 Global to mid-size companies world-wide, trust CybelAngel’s global team of approximately 200 team members to protect their businesses from digital threats. With a combination of advanced machine learning, cyber analysis expertise, and a powerful suite of software solutions, CybelAngel detects and resolves our clients potential threats, long before they can fall into the hands of cyber criminals.</p>\n<p>Our capabilities expand every day to uncover new risks, detect more threats, protect more clients, and create new possibilities for our employees.</p>\n<p>With offices in Boston, Paris, and London, CybelAngel’s global footprint allows for a thriving hybrid, office and remote-work environment. We are looking for exceptional ‘go-getters’ who share our ambitious vision, innovative culture, high commitment to ethics, and enthusiasm for being the best possible place to work!</p>\n<p>Our values:</p>\n<ul style=\"\">\n<li style=\"\"><strong>Be Bold</strong></li>\n<li style=\"\"><strong>Be Curious</strong></li>\n<li style=\"\"><strong>Stronger Together</strong></li>\n</ul>\n<p> </p>\n<p><strong>The Job</strong></p>\n<p>We’re looking for our future Data Scientist.</p>\n<p>We process billions of documents every day to extract leaks of relevant data about our customers.</p>\n<p>Introducing intelligence at the various levels of our processing pipeline is therefore a crucial issue for CybelAngel. Our Data Science team’s mission is to make our filtering algorithms as intelligent as possible, in order to optimize and facilitate the processing of security incidents.</p>\n<p><strong>Your responsibilities</strong></p>\n<p>Your mission will be to handle project management and to realize projects from end-to-end: from data exploration and state of the art, to production release and monitoring.</p>\n<p>This mission will imply:</p>\n<ul style=\"\">\n<li style=\"\">Work hand-in-hand with our cybersecurity analysts and product managers to define and maintain the objectives of model performance;</li>\n<li style=\"\">Collect data, explore, read the state of the art, document, benchmark, develop and deploy. What for? Categorize, score, extract sensitive information from text !</li>\n<li style=\"\">Conceive, plan and prioritize ongoing projects;</li>\n<li style=\"\">Do technology watch and be a force of proposal on new technologies or methods.</li>\n</ul>\n<p><strong>Data Team</strong></p>\n<p>Our Product &amp; Engineering organization = 55 passionate people, in 12 specialised teams.</p>\n<p>Three of these teams are entirely focused on data: we have a data engineering team, a data analyst team, and a data science team. They enable the company to leverage data by correctly storing, interpreting and understanding patterns out of it.</p>\n<p>That job position is open in the third team: the data science team. The data science team includes both machine learning engineers and data scientists.</p>\n<p><strong>Our (current) stack</strong></p>\n<ul style=\"\">\n<li style=\"\">Language: Python</li>\n<li style=\"\">Databases: BigQuery, BigTable</li>\n<li style=\"\">Librairies: pandas, scikit-learn, XgBoost, seaborn, plotly, spacy, nltk</li>\n<li style=\"\">MLOps: Gitlab CI, Docker, Kubernetes, Terraform, Airflow, MLFlow, kedro</li>\n<li style=\"\">Development environment: JupyterHub</li>\n<li style=\"\">Other: GCP, Datadog, Dataflow, PubSub</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<p><strong>Your preferred experience</strong></p>\n<ul style=\"\">\n<li style=\"\">Be curious, passionate and with a great team spirit</li>\n<li style=\"\">Will to learn, and ability to share their knowledge</li>\n<li style=\"\">2 to 5 years of work experience in building end-to-end ML system(s), from collecting the product need to the deployment in production</li>\n<li style=\"\">Creative spirit who likes to solve data science problems by discussing its ideas with other's</li>\n<li style=\"\">Ability to handle a project, with business need understanding and rigor</li>\n</ul>\n<p><em>If you do not meet the requirements but you think you are a great fit, you are welcome to apply and explain why !</em></p>\n<p> </p>\n<p><strong>Benefits</strong></p>\n<p><strong>Our Product &amp; Engineering Culture</strong></p>\n<p>🗃️ Small teams &amp; short iterations</p>\n<p>🤝 Culture of sharing, pair and mod programming, when it makes sense</p>\n<p>👩‍🎨 Quality time dedicated to technical design</p>\n<p>🧙‍♂️Half the software engineers have over 10 years of experience</p>\n<p>🎒 Voyager Program to change team temporarily and discover how they work #becurious</p>\n<p>✌️ Cooldown week dedicated to learning and experimenting</p>\n<p>🤼 Whole team buildings each semester #strongertogether</p>\n<p>🧠 Career path &amp; trainings #bebold</p>\n<p>📍 <strong>Remote options from everywhere in Europe</strong> (but you can come to our amazing office near Parc Monceau whenever you want, and it's paid by the company up to once a month)</p>\n<p><strong>Our Benefits</strong></p>\n<p>💰 Salary range: 50-60k euros based on your level of seniority and competencies you will demonstrate during the hiring process</p>\n<p>🏦 5% bonus, based on company and individual performances</p>\n<p>💸 Stock options for every employee</p>\n<p>🍱 Debit card for paying for lunch, with company contribution.</p>\n<p>💛 Very friendly and benevolent atmosphere with parties (CEO is an ex-DJ), sport sessions, board games nights, music band…</p>\n<p>👊🏻 DE&amp;I group</p>\n<p>🌍 Green team</p>\n<p>🥓 Free English Courses</p>\n<p>🏋🏾‍♀️ Class Pass credits for your gym sessions</p>\n<p>90% of our People recommend CybelAngel</p>\n<p>92% are happy with the work life balance at CybelAngel</p>\n<div class=\"h3\"> </div>\n<p><strong>Your hiring journey with us</strong></p>\n<ul style=\"\">\n<li style=\"\">30’ call with Pierre, Recruiter, to discuss about expectations from both ends</li>\n<li style=\"\">60’ call with Fabien, Senior Data Scientist and Pierre, Machine Learning Engineer, to discuss context and projects and to evaluate mission fit</li>\n<li style=\"\">45' meeting with the whole team to present the technical test (kaggle) that you prepared at home =&gt; have the chance to present your methodology and added value, followed by 30’ call with your future manager, Marie, Data Science Team Lead</li>\n<li style=\"\">30’ informal call with Thomas, the Head of Data</li>\n</ul>\n<img src=\"https://remotive.com/job/track/1533071/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1533357,"url":"https://remotive.com/remote-jobs/data/database-engineer-in-blockchain-data-analytics-company-1533357","title":"Database Engineer (In Blockchain Data Analytics Company)","company_name":"Bitquery","company_logo":"https://remotive.com/job/1533357/logo","category":"Data","tags":["docker","go","golang","java","kafka","mySQL","python","ruby","sql","blockchain","programming","analytics","knowledge","data","infrastructure","culture","metrics","database","startup","IT","organization","grafana","support","software"],"job_type":"full_time","publication_date":"2022-12-31T19:39:41","candidate_required_location":"USA","salary":"","description":"<p>We are an international company of developers of software for the analysis of decentralized data (40+ chains).</p><p>We have a distributed team, we are looking for programmers to further develop and support a data collection and processing system.</p><p><strong>Roles &amp; Responsibilities:</strong></p><ul style=\"\"> <li style=\"\">Building scalable infrastructure</li> <li style=\"\">Effective data storage</li> <li style=\"\">Data quality control, monitoring and ensuring data quality</li> <li style=\"\">Database administration</li> <li style=\"\">Message queue administration</li> <li style=\"\">Understanding blockchain data (blocks, transfers, transactions, smart contracts etc.)</li> <li style=\"\">Adding data quality checker/alert/metrics to monitoring systems</li> </ul><p><strong>Requirements</strong></p><ul style=\"\"> <li style=\"\">Knowledge of database technologies</li> <li style=\"\">High SQL language skill</li> <li style=\"\">Programming skill (Ruby or Python or Java or Golang)</li> <li style=\"\">Experience to work with data</li> <li style=\"\">The desire to understand a variety of systems and projects</li> <li style=\"\">3 years IT experience</li> </ul><p><strong>Tech Stack:</strong> Clickhouse, Mysql, Kafka, Ruby, Go, Java, Docker, Grafana, Prometheus</p><p><strong>Benefits</strong></p><ul style=\"\"> <li style=\"\">Opportunity to work &amp; collaborate with a truly global team spread across 5 countries</li> <li style=\"\">Work from anywhere in the world</li> <li style=\"\">Choose your own work hours</li> <li style=\"\">Yearly trip with Bitquery team to any remote destination</li> <li style=\"\"><strong>A promise to finish the interview processes within 1-2 weeks<br><br></strong></li> </ul><p><strong><em>Being a startup we take decisions &amp; move fairly fast, while giving candidates great experience with the interview process. We have a flat hierarchy in the organization where we empower individuals and provide an opportunity to deliver results as per his/her working style. Come and join a great culture and build Bitquery with us.</em></strong></p><img src=\"https://remotive.com/job/track/1533357/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1534068,"url":"https://remotive.com/remote-jobs/data/associate-director-analytics-consulting-tx-1534068","title":"Associate Director - Analytics Consulting (TX)","company_name":"Tiger Analytics","company_logo":"https://remotive.com/job/1534068/logo","category":"Data","tags":["big data","cloud","consulting","data science","hadoop","machine learning","python","sql","management","ai","project management","research","Engineering","market research","analytics","data","tableau","business","leadership","data engineering","senior management","team management","SOLID","development","IT","R","learning","applications","presentations"],"job_type":"full_time","publication_date":"2022-12-30T23:39:46","candidate_required_location":"USA","salary":"","description":"<p>Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning and AI. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.</p> <p>We are looking for someone with a good blend of business consulting skills and data analytics background. </p> <p><strong>Responsibilities:</strong><br></p><ul style=\"\"> <li style=\"\">Work on the latest applications of data science to solve business problems</li> <li style=\"\">Work directly with client stakeholders to translate business problems into high level analytics solution designs</li> <li style=\"\">Present analytic solutions to business audiences highlighting robustness of the solution and how it could help generate business value</li> <li style=\"\">Responsible for managing analytics projects, collaborating with client stakeholders and Tiger’s team situated globally</li> </ul><ul style=\"\"> <li style=\"\">Participate in discussions with team members to select and apply relevant analytic techniques and create actionable business insights</li> <li style=\"\">Responsible for making presentations to senior management, communicating results to business teams, and develop plans to help operationalize analytic solution</li> </ul><p><strong>Requirements</strong></p><ul style=\"\"> <li style=\"\">12 -14 years of professional work experience with at least 5 years in data analytics </li> <li style=\"\">Ability to engage with executive/VP level stakeholders from client’s team to translate business problems to high level analytics solution approach</li> <li style=\"\">Solid understanding of statistical and machine learning algorithms</li> <li style=\"\">Strong project management and team management skills and ability to work with global teams</li> <li style=\"\">Strong SQL skills and hands-on experience with analytic tools like R &amp; Python; &amp; visualization tools like Qlik or Tableau</li> <li style=\"\">Exposure to cloud platforms and big data systems such as Hadoop HDFS, Hive is a plus</li> <li style=\"\">Ability to work with IT and Data Engineering teams to help embed analytic outputs in business processes</li> <li style=\"\">Graduate in Business Analytics or MBA or equivalent work experience</li> </ul><p><strong>Benefits</strong></p><p>Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, fast-growing, challenging and entrepreneurial environment, with a high degree of individual responsibility.</p><img src=\"https://remotive.com/job/track/1534068/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1534335,"url":"https://remotive.com/remote-jobs/data/data-engineer-1534335","title":"Data Engineer","company_name":"ClearBank","company_logo":"https://remotive.com/job/1534335/logo","category":"Data","tags":["api","azure","big data","C","C#","cloud","crypto","go","java","legal","machine learning","python","scala","growth","management","design","email","automation","Engineering","analytics","healthcare","knowledge","deployment","data","spark","business","infrastructure","terraform","privacy","people","data engineering","recruitment","development","domain","reporting","IT","writing","learning","fintech","data management","financial services","integrations","testing","Azure Data Lake","immigration","architecture ","banking","production","catalyst"],"job_type":"full_time","publication_date":"2022-12-30T15:39:40","candidate_required_location":"UK","salary":"","description":"<p><strong>About us</strong></p>\n<p>ClearBank was built on the belief that banking infrastructure would no longer slow down progress. Instead, it’s the catalyst that unlocks the potential to innovate. That’s why our clients — financial institutions from fintech’s and crypto platforms, to banks and credit unions — use our API to power their banking infrastructure.</p>\n<p>But we wouldn’t be ClearBank without our people. They’re what powers our innovative technology and the reason we love what we do every day. We’re a group of spirited people who are never afraid to challenge the norm – becoming stronger, more energised, and that much better when we’re together. It’s our belief in fairness, autonomy and choice that means our people are empowered with the tools to learn, grow, and contribute to ours and our clients’ success. Interested in joining us? Read on or visit <a class=\"external\" href=\"https://clear.bank/\" rel=\"nofollow\" target=\"_blank\">our website</a> for more information.</p>\n<p><strong>About you</strong></p>\n<p>You’ll be joining the Data team as a <strong>Data Engineer</strong>. Reporting to the Team Leader, you’ll be a part of a fast-growing business that is challenging the market and doing things differently.</p>\n<p>We are rapidly expanding into a global bank and building a data team that supports this growth with a legacy free data platform which puts emphasis on frictionless integrations, automated processing, and advanced analytical capability including Machine Learning. As a Data Engineer at ClearBank you will be core to continuing the evolution of this platform, embedding data into our DNA, and enabling our customers to continue to grow at pace.</p>\n<p>Our Data team is growing fast, and as a Data Engineer you will be building a best-in-class data platform and working closely with stakeholders from teams across ClearBank and with specialists in data management, architecture, quality, and analytics. You will be key in supporting the adoption of Data Mesh principles by building the platform and capabilities that enable frictionless self-serve data ingestion, processing, and consumption as well as mind blowing insights.</p>\n<p>And you’ll be joining the #1 fastest-growing tech company in the UK, according to <a class=\"external\" href=\"https://deloitte.co.uk/fast50/winners/2021/\" rel=\"nofollow\">Deloitte Fast 50.</a></p>\n<p> </p>\n<p><strong>You will be</strong></p>\n<p>You will be passionate about data and how it can be used to innovate, generate opportunities, and transform how an organisation operates. While data engineering experience is a plus, a successful candidate will demonstrate they are focused on delivering incremental value to users and have experience delivering a platform / service that its consumers love to use in production. Keenness for personal development as well as taking ownership and accountability of the code you deliver, from design to monitoring it in production, is also key.</p>\n<p> </p>\n<p> </p>\n<p><strong>What we are looking for</strong></p>\n<p><strong>Core Skills and Experience</strong></p>\n<ul style=\"\">\n<li style=\"\">Focused on delivering <strong>incremental value to users</strong>, not just on writing code</li>\n<li style=\"\">Able to <strong>communicate effectively</strong> with both technical and non-technical stakeholders</li>\n<li style=\"\">Experience / desire to <strong>own solutions throughout their development lifecycle </strong>– from design &amp; testing to deployment &amp; monitoring</li>\n<li style=\"\"><strong>Automation mindset</strong> - be it testing, monitoring, or operational processes; we drive for as little manual intervention as possible</li>\n<li style=\"\"><strong>Infrastructure as Code</strong> (we use Terraform)</li>\n<li style=\"\"><strong>Scala, Python, C# and / or Java</strong> (we primarily use Scala and work closely with C# Engineers)</li>\n<li style=\"\"><strong>Solutions </strong>driven</li>\n<li style=\"\"><strong>Delivery </strong>focussed</li>\n<li style=\"\"><strong>Team </strong>player</li>\n</ul>\n<p><strong>Ideal, but not a showstopper</strong></p>\n<ul style=\"\">\n<li style=\"\">Experience in <strong>Data Engineering</strong></li>\n<li style=\"\"><strong>Spark, Azure Data Lake, and Azure Analytics Services</strong> (we use Databricks)</li>\n<li style=\"\">Leveraged <strong>cloud technology</strong> to deliver scalable production platforms</li>\n<li style=\"\">Appreciation for <strong>event-based architecture</strong> and how this applies to a big data platform</li>\n<li style=\"\">Experience implementing and enabling <strong>Data Mesh principles</strong></li>\n<li style=\"\"><strong>Domain knowledge</strong> in Financial Services / Banking</li>\n</ul>\n<p><strong>About what we offer </strong></p>\n<ul style=\"\">\n<li style=\"\">We’re remote-first and flexible, so work from home or visit the offices in London and Bristol</li>\n<li style=\"\">27 days annual leave per year, plus bank holidays and x 2 ‘Bigger Than ClearBank’ days</li>\n<li style=\"\">You have the option to work outside of the UK for up to 30 days per year</li>\n<li style=\"\">Regular in-person and online company-wide meetups</li>\n<li style=\"\">A flexible option to finish early on a Friday if it works for you and your team – we call this our ‘Fresh Air Fridays’</li>\n<li style=\"\">Take a couple of days per year to volunteer with your chosen charity to do something bigger than ClearBank</li>\n<li style=\"\">Private healthcare through Healix and discounted Bupa dental cover, with employee healthy living perks and discounts through YuLife</li>\n<li style=\"\">Enhanced family friendly leave</li>\n<li style=\"\">Plus, you’ll have the opportunity to join an energetic team that’s building a bank fit for the future! 🚀</li>\n</ul>\n<p> </p>\n<p> </p>\n<p><strong>The legal bit</strong></p>\n<p>By submitting your CV, you confirm that you can demonstrate you have the right to work in the UK. Regretfully we are not in a position to sponsor applicants for immigration purposes at the current time. By submitting your CV to ClearBank Limited you are providing your consent for us to use the information you provide for recruitment purposes. For more information on how we manage your data go and check out our Candidate Privacy Notice on the ClearBank website to see how we process, manage, and look after your data. You are also allowing us to communicate with you by email and telephone for recruitment purposes</p>\n<img src=\"https://remotive.com/job/track/1534335/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1534372,"url":"https://remotive.com/remote-jobs/data/senior-data-engineer-1534372","title":"Senior Data Engineer","company_name":"EasyKnock","company_logo":"https://remotive.com/job/1534372/logo","category":"Data","tags":["AWS","azure","cloud","excel","kubernetes","python","scala","security","sql","growth","management","databases","agile","project management","Engineering","product","analytics","knowledge","data","postgres","Enterprise","creative","tableau","business","infrastructure","terraform","GCP","ETL","warehouse","privacy","people","data engineering","culture","SOLID","data pipelines","development","domain","reporting","startup","data security","data management","organization","communication","support","architecture ","production","programs"],"job_type":"full_time","publication_date":"2022-12-29T23:39:23","candidate_required_location":"USA","salary":"","description":"<p><strong>About EasyKnock</strong></p> <p>EasyKnock is the country’s first home equity solutions platform. Our innovative programs give homeowners flexible, quick solutions for their financial needs. Whether paying off debt, purchasing a new home, or funding a business, EasyKnock empowers homeowners to convert their equity to cash without strict lender qualifications through our suite of sale-leaseback solutions. Customers sell their homes to us and remain as renters while working toward their goals. We’re passionate about helping American homeowners access the equity they’ve built up in their homes by giving them back liquidity, flexibility, and control.</p><p>We are looking for compassionate people who find joy in connecting others with creative solutions to access the value of their home. If you have a growth mindset, find absolute thrill in building a new business and excel in a dynamic work culture, we want to talk to you.</p><p><br></p><p><strong>About the Position</strong><br></p><p>As a Data Engineer you collect and maintain data that provide the organization with analytical capabilities in support of its mission. Reporting to VP of Engineering, you will be part of a diverse, dynamic, and agile squad that is responsible for data pipelines, data integration, data quality, data visualization, self-service analytics and data catalog for the enterprise.</p><p><br></p><p><strong>Roles &amp; Responsibilities</strong><br></p><ul style=\"\"> <li style=\"\">Quickly learn about the business domain and the associated data and analytics products that the team works on</li> <li style=\"\">Understand and take over tools that support data driven decisions and allow our teams to access and prepare data sets and reports easily and reliably.</li> <li style=\"\">Support and maintain data workflows using Airflow and RedShift</li> <li style=\"\">Working knowledge configuring databases/data warehouses to have optimal performance, reliability, and fault tolerance.</li> <li style=\"\">Thrive in a collaborative fast-paced environment where data expertise and responsibility are shared with teammates across disciplines</li> </ul><p><strong>Requirements</strong></p><ul style=\"\"> <li style=\"\">3+ years of hands-on experience enhancing and building large scale data warehouse solutions across the entire data lifecycle, from raw data to powerful insights and analytics</li> <li style=\"\">Experience in working with and optimizing existing data ingestion, cleansing, transformation, integration, and validation flows and helping to move them into production</li> <li style=\"\">Ability to quickly understand EasyKnock products, how source systems generate data, and how data is organized in the data mart</li> <li style=\"\">Strong communication skills which enable you to work with owners of source systems on better ways to capture and store transactional data</li> <li style=\"\">Fluent in Python and/or Scala</li> <li style=\"\">Experience with cloud computing platforms (e.g. GCP, AWS, Azure)</li> </ul><p><strong>Preferred Qualifications</strong></p><ul style=\"\"> <li style=\"\">4+ years Hands-on experience with Python in data engineering or application development</li> <li style=\"\">Technologist with background in data engineering and data integration with hands on experience in Airflow, Redshift, Tableau and AWS, GCP cloud platforms.</li> <li style=\"\">Solid knowledge of Cloud Infrastructure defined as code with a tool like Pulumi/Terraform.</li> <li style=\"\">Experienced working in Agile product teams.</li> <li style=\"\">Experience designing and maintaining tools that support ETL/ELT pipelines and downstream business use cases of data.</li> <li style=\"\">Knowledge of data architecture and data management best practices</li> <li style=\"\">Overall understanding of data security and privacy best practices</li> <li style=\"\">Clear project management and prioritization skills</li> <li style=\"\">Experience with managing SQL databases, particularly data administrative tasks with DDL</li> <li style=\"\">Experience in a dynamic startup-like environment.  Collaborative working style to support larger team goals and outcomes</li> </ul><p><br></p><p><strong>Tech Stack</strong></p><ul style=\"\"> <li style=\"\">Python</li> <li style=\"\">Airflow</li> <li style=\"\">AWS RedShift</li> <li style=\"\">Postgres</li> <li style=\"\">Kubernetes</li> <li style=\"\">AWS &amp; GCP</li> </ul><p><strong>Benefits</strong></p><ul style=\"\"> <li style=\"\">Remote-friendly environment</li> <li style=\"\">Competitive base salary commensurate with experience and geographic location. Range: $160,000 - $200,000</li> </ul><ul style=\"\"> <li style=\"\">Bonus eligible position</li> <li style=\"\">Full benefits and unlimited PTO</li> <li style=\"\">Generous stock options</li> <li style=\"\">401k match</li> <li style=\"\">Opportunity to be part of a fast growing company in the financial technology industry</li> <li style=\"\">A chance to work with incredible teammates who are super-bright, creative, talented, and passionate</li> </ul><img src=\"https://remotive.com/job/track/1534372/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1534897,"url":"https://remotive.com/remote-jobs/data/data-analysis-mentors-tutors-f-m-d-1534897","title":"Data Analysis Mentors/Tutors (f/m/d)","company_name":"CareerFoundry","company_logo":"https://remotive.com/job/1534897/logo","category":"Data","tags":["analyst","education","excel","python","sql","teaching","video","databases","research","product","data analysis","knowledge","mentoring","data","troubleshooting","English","tableau","business","data visualization","people","KPIs","metrics","development","reporting","IT","learning","support","relational databases","programs"],"job_type":"freelance","publication_date":"2022-12-29T23:39:21","candidate_required_location":"Northern America","salary":"","description":"<p>We created CareerFoundry to help others build their careers while maintaining personal freedom and flexibility. Our 100% online, flexible, mentor/tutor driven courses are setting the standard for globally accessible technical education. Through our online programs, expert tutors and mentors bring students from complete beginners to junior data analysts in 6 months.</p>\n<p>We are searching for experienced and passionate Junior and Senior Data Analysts to join our pool of experts. Help define the next generation of talent by educating and empowering students across the globe while working remotely and around your own schedule!</p>\n<p><strong>Your Mission:</strong></p>\n<p>Mentoring with CareerFoundry is more than teaching. It’s inspiring newcomers to the field to build, to problem solve, to think like an analyst, and to increase their value as professionals.</p>\n<p>**Based on your application and experience, we will make a decision on whether the Tutor or Mentor role is the perfect fit for you.</p>\n<p><strong>Mentor role:</strong></p>\n<p>Students need more than help and experience to master the necessary skills, they need inspiration and motivation to keep them focused along the way. You're their point of entry into a new industry, so they’ll want to hear about challenges you have overcome and what the role is really like on a day-to-day basis.</p>\n<p><strong>Tasks:</strong></p>\n<ul style=\"\">\n<li style=\"\">Reviewing your students’ work through the CareerFoundry platform on a regular basis with a view on how it would fit into an industry-ready portfolio.</li>\n<li style=\"\">Be available for 1-to-1 video calls to help prepare your students entry into their new industry.</li>\n<li style=\"\">Suggesting supplemental learning materials and personal insights in areas where students are struggling.</li>\n<li style=\"\">Teaming up with a tutor to answer more advanced queries or for a higher level of troubleshooting.</li>\n<li style=\"\">Responding to students within &lt; 48 hours.</li>\n</ul>\n<p><strong>Tutor role:</strong></p>\n<p>Tutors give vital feedback on assignments through written reviews guided by our course curriculum and rubrics. When students are struggling with understanding a key area, tutors are there to support and encourage them, sharing resources and providing insights into the industry.</p>\n<p><strong>Tasks:</strong></p>\n<ul style=\"\">\n<li style=\"\">Regularly reviewing student exercises submitted through the CareerFoundry platform.</li>\n<li style=\"\">Submission reviews and checking for a fundamental understanding of concepts.</li>\n<li style=\"\">Suggesting supplemental learning materials and personal insights in areas where students are struggling.</li>\n<li style=\"\">Working with a mentor who will advise the student specifically on career-related topics and support you as a tutor.</li>\n<li style=\"\">Responding to students within &lt; 24 hours.</li>\n</ul>\n<p><strong>**We are currently prioritizing applicants based in Northern America &amp; adjacent timezones**</strong></p>\n<p><strong>Requirements</strong></p>\n<p>To succeed, you must enjoy sharing your knowledge and be willing to work with students from beginner level onwards.</p>\n<p><strong>Mentor role:</strong></p>\n<ul style=\"\">\n<li style=\"\">5+ years experience in the field, and a demonstrable track record showcasing your work for a variety of clients and companies.</li>\n<li style=\"\">A portfolio demonstrating your skill and examples of professional projects. Professional references may be required.</li>\n<li style=\"\">Previous experience in mentorship or tutoring is preferred. You must demonstrate an understanding of how to support beginners, have time and patience and a strong desire to guide people along their career path in this field.</li>\n<li style=\"\">Knowledge of the latest development tools and trends, a broad network of experts in the field and an in-depth understanding of industry practices.</li>\n<li style=\"\">Fluent in English.</li>\n</ul>\n<p><strong>Tutor role:</strong></p>\n<ul style=\"\">\n<li style=\"\">2+ years experience in the field working as a Data Analyst.</li>\n<li style=\"\">A great portfolio.</li>\n<li style=\"\">In depth knowledge of industry best practices.</li>\n<li style=\"\">A strong desire to help others.</li>\n<li style=\"\">Fluent in English.</li>\n</ul>\n<p><strong>For both roles a knowledge of the following is required:</strong></p>\n<p>Data Processing and Querying</p>\n<ul style=\"\">\n<li style=\"\">SQL</li>\n<li style=\"\">Excel</li>\n<li style=\"\">Python (and pandas library)</li>\n<li style=\"\">Relational databases</li>\n</ul>\n<p>Data Visualization and Reporting</p>\n<ul style=\"\">\n<li style=\"\">End-to-end analysis</li>\n<li style=\"\">Tableau</li>\n<li style=\"\">Presenting data</li>\n<li style=\"\">Data visualizations and data dashboards</li>\n<li style=\"\">Power Bi (data viz tool)</li>\n<li style=\"\">Storytelling</li>\n<li style=\"\">Statistical Analysis</li>\n</ul>\n<p>Business</p>\n<ul style=\"\">\n<li style=\"\">Understanding and formulating business metrics/KPIs</li>\n<li style=\"\">Understanding how data relates to product requirements</li>\n<li style=\"\">Designing and scoping research projects and experiments</li>\n<li style=\"\">Ethics in data analysis</li>\n</ul>\n<p><strong>What’s in it for you:</strong></p>\n<ul style=\"\">\n<li style=\"\">100% Remote and flexible - work from anywhere with an internet connection, and around your schedule.</li>\n<li style=\"\">A freelance contract with a competitive rate.</li>\n<li style=\"\">Shape the industry by developing the next generation of data analysts.</li>\n<li style=\"\">Resume gold – mentoring experience is highly sought after by employers.</li>\n</ul>\n<p>CareerFoundry is an equal opportunity employer. It is our commitment that every qualified person will be evaluated according to skills regardless of age, gender identity, ethnicity, sexual orientation, disability status, or religion. We encourage in particular BiPoC, Migrants, people from under-represented communities, people who identify as queer, trans and/ or intersex, people with chronic illnesses, and people with disabilities to apply!</p>\n<p><strong>For inquiries please contact the team at talent.instructors@careerfoundry.com</strong></p>\n<p><strong>We're looking forward to hearing from you!</strong></p>\n<img src=\"https://remotive.com/job/track/1534897/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1414542,"url":"https://remotive.com/remote-jobs/data/data-engineer-manager-1414542","title":"Data Engineer Manager","company_name":"Bonfire","company_logo":"https://remotive.com/job/1414542/logo","category":"Data","tags":["AWS","C","java","mobile","python","scala","sql","design","programming","databases","automation","strategy","Engineering","languages","knowledge","data","postgres","creative","English","tableau","business","ETL","warehouse","hiring","people","partnerships","culture","data pipelines","IT","organization","testing","data-driven","support","architecture ","software"],"job_type":"contract","publication_date":"2022-12-28T21:45:46","candidate_required_location":"LATAM, European timezones","salary":"","description":"<p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong style=\"box-sizing: inherit;\"><em style=\"box-sizing: inherit;\">This contractor role is only open to candidates located in European &amp; South American time zones.</em></strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong>ABOUT THE COMPANY</strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><span style=\"box-sizing: inherit;\">Bonfire is transforming the way people buy and sell high-quality custom apparel. We are a free online platform where anyone can design, sell, and buy custom products. We’ve helped thousands of individuals, groups, and nonprofits raise money for the causes they care about, and also serve the world’s top creators as their premiere custom merch platform. We’re a passionate, creative, and data-driven team constantly pursuing our vision: to strengthen communities that inspire a kinder world. We bring this vision to life by hiring passionate, smart people who celebrate and respect others, are committed to a life of curiosity, are never satisfied with ‘good enough’, are eager to co-create the future, and who thrive through teamwork. </span><strong>Have we been looking for </strong><strong><em>you</em></strong><strong>?</strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong>ABOUT THE JOB</strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\">Our Engineering team is searching for their future <strong style=\"box-sizing: inherit;\">Data Engineer Manager</strong> – a creative, well-organized, and critical thinker who appreciates challenges and prioritizes being highly communicative and collaborative with colleagues to create solutions.</p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\">As Bonfire’s Data Engineer Manager, you will be our data aficionado, designing and building solutions to feed our data pipelines which serve information to our business analysts, and other departments to help ensure they are making sound, informed decisions. This person can expect to be significantly involved with data automation, wrangling, cleaning, and organization.</p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><span style=\"box-sizing: inherit;\">This role lies within our Engineering department and reports to the Chief Technology Officer (CTO). </span></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><span style=\"box-sizing: inherit;\">All Bonfire employees are expected to embrace the Mission and </span><em style=\"box-sizing: inherit;\">Values</em><span style=\"box-sizing: inherit;\">, we live together and apart: </span><em style=\"\">Humble Ingenuity, Trusting Partnerships, Inclusive Cooperation, Moral Courage, Healthy Dissatisfaction</em></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong><em>Bonfire is currently supporting a virtual work environment; however, this is a contract position and is only open to candidates residing in European &amp; South American time zones. </em></strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83); text-align: center;\">___________</p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong>ESSENTIAL RESPONSIBILITIES </strong>include but are not limited to:</p><ol style=\" margin-bottom: 30px; padding-top: 5px; padding-right: 20px; padding-bottom: 5px;  border-width: 1px; border-color: rgb(239, 239, 239); list-style-type: none; border-radius: 3px; counter-reset: ol-counter 0; color: rgb(61, 72, 83);\"><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px;\"><span style=\"box-sizing: inherit;\">Create and execute a departmental strategy to achieve company-wide goals</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Setup and build/maintain our DWH (Data Warehouse)</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Own all definitions, models, and dimensions in our Data department</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Provide data-access tools</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Help us choose and implement best tooling for Analysts (Tableau, PowerBI, etc)</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Work on Data Architecture – use a systematic approach to plan, create, and maintain data architectures while also keeping it aligned with business requirements.</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Ensure data integrity and optimized storing of business data</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">ETL / ELT</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Data pipeline maintenance/testing</span></li><li style=\"box-sizing: inherit;  line-height: 21px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239);\"><span style=\"box-sizing: inherit;\">Develop team and departmental OKRs</span></li></ol><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong>MINIMUM QUALIFICATIONS</strong></p><ul style=\" margin-bottom: 30px; padding-top: 5px; padding-right: 20px; padding-bottom: 5px;  border-width: 1px; border-color: rgb(239, 239, 239); list-style-type: none; border-radius: 3px; color: rgb(61, 72, 83);\"><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; \"><span style=\"box-sizing: inherit;\">High School Graduate</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Fluent English (written and spoken)</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Proficient with SQL databases (Postgres), and programming languages most applicable for the specific task (Java/Scala/C/Python)</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Experience in running and operating DWH, ideally in AWS environment</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">4+ years of experience working with Data </span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Consistent access to a reasonably distraction free home work space, with reliable access to high-speed internet and use of a smart phone/mobile device.</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Technologically savvy, with strong computer skills and the ability to embrace and adapt to changes to technology that is critical to how we work.   </span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Good working knowledge of the primary Google business, productivity and collaboration tools/software. </span></li></ul><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><strong>WHY WORK AT BONFIRE?</strong><strong> </strong></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><span style=\"box-sizing: inherit;\">When team members all around the world were asked to find three words they’d use to describe Bonfire, the most commonly shared values were: </span><strong>kind, inclusive, charitable, supportive, collaborative, and passionate. </strong><span style=\"box-sizing: inherit;\">Work here and help us guide people toward their full potential and possibility in support of a company that’s trying to infuse the world with more of those values. </span></p><p style=\"box-sizing: inherit;  margin-bottom: 24px; padding: 0px; line-height: 24px; color: rgb(61, 72, 83);\"><span style=\"box-sizing: inherit;\">In addition to leading purposeful work, you will also benefit from our team member offerings:  </span></p><ul style=\" margin-bottom: 30px; padding-top: 5px; padding-right: 20px; padding-bottom: 5px;  border-width: 1px; border-color: rgb(239, 239, 239); list-style-type: none; border-radius: 3px; color: rgb(61, 72, 83);\"><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; \"><span style=\"box-sizing: inherit;\">Competitive compensation</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Remote work environment (We are a fully distributed team!)</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Flexible scheduling  </span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">Year-round swag giveaways</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">A positive culture and dynamic team environment</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">The ability to help create a kinder planet</span></li><li style=\"box-sizing: inherit; line-height: 24px; padding: 10px 0px 10px 25px; border-top-width: 1px; border-top-color: rgb(239, 239, 239); \"><span style=\"box-sizing: inherit;\">An environment to grow your skills, learn new technologies, and to challenge yourself </span></li></ul>\n<img src=\"https://remotive.com/job/track/1414542/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1534719,"url":"https://remotive.com/remote-jobs/data/data-engineer-ii-1534719","title":"Data Engineer II","company_name":"Mediavine","company_logo":"https://remotive.com/job/1534719/logo","category":"Data","tags":["AWS","azure","cloud","devops","looker","python","security","sql","management","operations","content","Engineering","product","analytics","advertising","knowledge","data","postgres","web","business","infrastructure","warehouse","people","metabase","websites","data engineering","Snowflake","culture","data pipelines","APIs","IT","writing","learning","coding","organization","plugins","support","diversity","travel","insurance"],"job_type":"full_time","publication_date":"2022-12-28T21:40:21","candidate_required_location":"USA","salary":"","description":"<p>Mediavine is seeking an experienced Data Engineer to join our engineering team. We are looking for someone who enjoys solving interesting problems and wants to work with a small team of talented engineers on a product used by thousands of publishers. Applicants must be based in the United States.</p>\n<div class=\"h3\">About Mediavine</div>\n<p>Mediavine is a fast-growing advertising management company representing nearly 10,000 websites in the food, lifestyle, DIY, and entertainment space. Founded by content creators, for content creators, Mediavine is a Top 20 Comscore property, exclusively reaching over 125 million monthly unique visitors. With best-in-class technology and a commitment to traffic quality and brand safety, we ensure optimal performance for our creators.</p>\n<div class=\"h3\">Mission &amp; Culture</div>\n<p>We help content creators build sustainable businesses. From educational tools and cutting-edge plugins to ad technology that maximizes earnings without slowing down your site, our motivation is to ensure their brand and business grow in every respect.</p>\n<p>We are striving to build an inclusive and diverse team of highly talented individuals that reflects the industries we serve and the world we live in. We are committed to creating a culture where everyone feels welcome. We are looking for individuals that will challenge us to continuously evolve and make Mediavine the employer of choice for people of all backgrounds. We strongly encourage minorities and individuals from underrepresented groups in technology to apply for this position.</p>\n<p>Diversity and inclusion aren't platitudes to us; we take them seriously. Have a look at <a class=\"external\" href=\"https://www.mediavine.com/our-team/\" rel=\"nofollow\">our team</a> and read through our <a class=\"external\" href=\"https://www.mediavine.com/blog/\" rel=\"nofollow\">blog posts</a> to learn more about our values and discover if Mediavine is the place for you!</p>\n<div class=\"h3\">Position Title &amp; Overview</div>\n<p>The Data &amp; Analytics team consists of data analysts, data engineers and analytics engineers working to build the most effective platform and tools to help uncover opportunities and make decisions with data here at Mediavine. We partner with Product, Support, Ad Operations and other teams within the Engineering department to understand behavior, develop accurate predictors and build solutions that provide the best internal and external experience possible.</p>\n<p>A Data Engineer at Mediavine will help build and maintain our data infrastructure. Building scalable data pipelines, managing transformation processes, and ensuring data quality and security at all steps along the way. This will include writing and maintaining code in Python and SQL, developing on AWS, and selecting and using third-party tools like Rundeck, Metabase, and others to round out the environment. You will be involved in decisions around tool selection and coding standards.</p>\n<p>Our current data engineering toolkit consists of custom Python data pipelines, AWS infrastructure including Kinesis pipelines, Rundeck scheduling, dbt for transformation and Snowflake as our data warehouse platform. We are open to new tools and expect this position to be a part of deciding the direction we take.</p>\n<p><strong>Essential Responsibilities</strong></p>\n<ul style=\"\">\n<li style=\"\">Create data pipelines that make data available for analytic and application use cases</li>\n<li style=\"\">Develop self-healing, resilient processes that do not require constant care and feeding to run smoothly</li>\n<li style=\"\">Create meaningful data quality notifications with clear actions for interested parties including other internal teams and other members of the data and analytics team</li>\n<li style=\"\">Leading projects from a technical standpoint</li>\n<li style=\"\">Support data analysts and analytics engineers ability to meet the needs of the organization</li>\n<li style=\"\">Participate in code reviews, understanding coding standards, ensuring test coverage and being aware of best practices</li>\n<li style=\"\">Build or implement tooling around data quality, governance and lineage, mostly in the dbt framework but external to that as needed</li>\n<li style=\"\">Provide next level support when data issues are discovered and communicated by the data analysts</li>\n<li style=\"\">Work with data analysts and analytics engineers to standardize transformation logic in the dbt layer for consistency and ease of exploration by end users</li>\n<li style=\"\">Enable analytics engineers and data analysts by providing data modeling guidance, query optimization and aggregation advice</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<p><strong>Location: </strong></p>\n<ul style=\"\">\n<li style=\"\">Applicants must be based in the United States</li>\n</ul>\n<p><strong>You Have: </strong></p>\n<ul style=\"\">\n<li style=\"\">3+ years of experience in a data engineering role</li>\n<li style=\"\">Strong Python skills (Understand tradeoffs, optimization, etc)</li>\n<li style=\"\">Strong SQL skills (CTEs, window functions, optimization)</li>\n<li style=\"\">An understanding of how to best structure data to enable internal and external facing analytics</li>\n<li style=\"\">Experience working in cloud environments (AWS preferred, GCS, Azure)</li>\n<li style=\"\">Familiarity with calling APIs to retrieve data (Authentication flows, filters, limits, pagination)</li>\n<li style=\"\">Experience working with DevOps to deploy, scale and monitor data infrastructure</li>\n<li style=\"\">Scheduler experience either traditional or DAG based</li>\n<li style=\"\">Comfortable working with multi-TB cloud data warehouses (Big Query, Snowflake, Redshift)</li>\n<li style=\"\">Experience with other DBMS systems (Postgres in particular)</li>\n</ul>\n<p><strong>Nice to haves:</strong></p>\n<ul style=\"\">\n<li style=\"\">Experience with web analysis such as creating data structure that support product funnels, user behavior, and decision path analysis</li>\n<li style=\"\">Understanding of Snowflake external stages, file formats and snowpipe</li>\n<li style=\"\">Experience with orchestration tools particularly across different technologies and stacks</li>\n<li style=\"\">Experience with dbt</li>\n<li style=\"\">Knowledge of Ad Tech, Google Ad Manager and all of it’s fun quirks (so fun)</li>\n<li style=\"\">The ability to make your teammates laugh (it wouldn’t hurt if you were fun to work with is what I’m saying)</li>\n<li style=\"\">Familiarity with event tracking systems (NewRelic, Snowplow, etc)</li>\n<li style=\"\">Experience with one or more major BI tools (Domo, Looker, PowerBI, etc.)</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul style=\"\">\n<li style=\"\">Remote work environment</li>\n<li style=\"\">Travel opportunities (remember those!?)</li>\n<li style=\"\">Comprehensive benefits including 401k, Health, Dental, and Vision insurance</li>\n<li style=\"\">Learning allowance</li>\n<li style=\"\">Generous Vacation/Time off policies</li>\n<li style=\"\">Additional side benefits such as home-office upgrades, tuition reimbursement, paid gym memberships and wellness retreats, upgraded flights, cool swag and more</li>\n<li style=\"\">Company match charitable donations</li>\n</ul>\n<p>Mediavine is an Equal Opportunity Employer</p>\n<img src=\"https://remotive.com/job/track/1534719/blank.gif?source=public_api\" alt=\"\"/>"},{"id":1524958,"url":"https://remotive.com/remote-jobs/data/dataops-engineer-1524958","title":"DataOps Engineer","company_name":"Tatum","company_logo":"https://remotive.com/job/1524958/logo","category":"Data","tags":["backend","cloud","java","python","security","blockchain","growth","management","design","programming","Engineering","product","analytics","languages","knowledge","data","gaming","business","infrastructure","ETL","google cloud","privacy","data engineering","data pipelines","startup","IT","fintech","data management","data-driven","banking","production","software"],"job_type":"full_time","publication_date":"2022-12-27T19:39:27","candidate_required_location":"Czech Republic","salary":"","description":"<p>Do you want to learn on-chain analysis and help our customers with their revolutionary blockchain use cases? Would you like to develop a complete in-house product analytics from scratch? </p>\n<p>We are looking for a Data(Ops) Engineer who will be able to design, build and maintain strategic data management capabilities and data products for both internal and external customers using modern cloud based backends hosted in Google Cloud.</p>\n<p>Tatum is a rapidly growing startup. We have created a platform that allows developers to build the next generation of software with blockchains at the core. The platform allows integrating any of 40+ blockchains into apps or platforms in no time. The Data and Analytics team plays a crucial part in the data-driven process of designing, implementing, and maintaining the systems powering the surging demand from leaders in gaming, banking, fintech, logistics, and other industries.</p>\n<p> </p>\n<p><strong>What you will do</strong></p>\n<ul style=\"\">\n<li style=\"\">Collaborate with business and product teams to ensure straightforward accessibility and usage of internal data products\n<ul style=\"\">\n<li style=\"\">Developing internal data product - building and optimizing data pipelines to facilitate the extraction of data from multiple sources and load it into data warehouses.</li>\n<li style=\"\">Implementing data lifecycle management including quality, security and privacy</li>\n<li style=\"\">Communicating and collaborating with other data and BI team members to enhance the quality of data products</li>\n</ul>\n</li>\n<li style=\"\">Collaborate with product teams and industry experts to delivery a top of the line backend for our blockchain data solutions\n<ul style=\"\">\n<li style=\"\">Designing and delivering a ground-breaking infrastructure for our blockchain datalakes</li>\n<li style=\"\">Gaining deep knowledge and understanding of blockchain data in order to implement ETL/ELT/data pipelines</li>\n<li style=\"\">Identifying patterns and using advanced analytics to assist product teams in designing products based on blockchain data</li>\n</ul>\n</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul style=\"\">\n<li style=\"\">You have a growth mindset and no issues embracing ambiguity and seeking opportunities to challenge yourself and continuously grow your technical skills</li>\n<li style=\"\">You have professional data engineering experience in large production environments (Google Cloud is an advantage)</li>\n<li style=\"\">Knowledge of programming languages (e.g. Java and Python)</li>\n<li style=\"\">Experience with provisioning and maintaining your own data infrastructure (with focus on performance and cost optimization at scale)</li>\n<li style=\"\">Experience owning a project from concept to production, including proposal, discussion, and execution.</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul style=\"\">\n<li style=\"\">Work from anywhere - Most of our team works remotely. Nevertheless, you are also always welcome in our office in Brno</li>\n<li style=\"\">Flexible hours - Work whenever it suits your personal schedule. For most positions, we don't have any fixed hours</li>\n<li style=\"\">25 days off</li>\n</ul>\n<p>Ready to hop on our fast train to the future? Become a #Tatumer! Feel free to contact us with your resume or a link to your LinkedIn profile. We would love to show you who we are and how we do things.</p>\n<img src=\"https://remotive.com/job/track/1524958/blank.gif?source=public_api\" alt=\"\"/>"}]}